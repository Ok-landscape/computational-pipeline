\documentclass[a4paper, 11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage[makestderr]{pythontex}

\title{Multiple Regression Analysis: Model Building and Diagnostics}
\author{Computational Statistics}
\date{\today}

\begin{document}
\maketitle

\section{Introduction}
Multiple regression analysis models the relationship between a dependent variable and multiple
independent variables. This document covers ordinary least squares (OLS) estimation, hypothesis
testing for regression coefficients, model diagnostics for checking assumptions, detection and
handling of multicollinearity, influential observations analysis, and model selection techniques.
We implement comprehensive diagnostic tools to assess residual normality, homoscedasticity,
linearity, and independence assumptions.

\section{Mathematical Framework}

\subsection{Multiple Regression Model}
\begin{equation}
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_p X_p + \epsilon
\end{equation}

Matrix notation:
\begin{equation}
\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}
\end{equation}

\subsection{OLS Estimator}
\begin{equation}
\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}
\end{equation}

\subsection{Coefficient of Determination}
\begin{equation}
R^2 = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}
\end{equation}

Adjusted $R^2$:
\begin{equation}
R^2_{adj} = 1 - (1 - R^2)\frac{n-1}{n-p-1}
\end{equation}

\subsection{Variance Inflation Factor}
\begin{equation}
VIF_j = \frac{1}{1 - R_j^2}
\end{equation}

\section{Environment Setup}
\begin{pycode}
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from scipy.linalg import inv

plt.rc('text', usetex=True)
plt.rc('font', family='serif', size=10)
np.random.seed(42)

def save_plot(filename, caption=""):
    plt.savefig(filename, bbox_inches='tight', dpi=150)
    print(r'\begin{figure}[htbp]')
    print(r'\centering')
    print(r'\includegraphics[width=0.95\textwidth]{' + filename + '}')
    if caption:
        print(r'\caption{' + caption + '}')
    print(r'\end{figure}')
    plt.close()
\end{pycode}

\section{Multiple Regression Implementation}
\begin{pycode}
class MultipleRegression:
    def __init__(self):
        self.beta = None
        self.se = None
        self.t_stats = None
        self.p_values = None
        self.r_squared = None
        self.adj_r_squared = None
        self.residuals = None
        self.fitted = None
        self.mse = None

    def fit(self, X, y):
        # Add intercept
        n = len(y)
        X_design = np.column_stack([np.ones(n), X])
        p = X_design.shape[1]

        # OLS estimation
        XtX_inv = inv(X_design.T @ X_design)
        self.beta = XtX_inv @ X_design.T @ y

        # Fitted values and residuals
        self.fitted = X_design @ self.beta
        self.residuals = y - self.fitted

        # Mean squared error
        self.mse = np.sum(self.residuals**2) / (n - p)

        # Standard errors
        var_beta = self.mse * XtX_inv
        self.se = np.sqrt(np.diag(var_beta))

        # t-statistics and p-values
        self.t_stats = self.beta / self.se
        self.p_values = 2 * (1 - stats.t.cdf(np.abs(self.t_stats), n - p))

        # R-squared
        ss_res = np.sum(self.residuals**2)
        ss_tot = np.sum((y - np.mean(y))**2)
        self.r_squared = 1 - ss_res / ss_tot
        self.adj_r_squared = 1 - (1 - self.r_squared) * (n - 1) / (n - p)

        # Store for diagnostics
        self.X_design = X_design
        self.n = n
        self.p = p
        self.y = y

        return self

    def predict(self, X):
        X_design = np.column_stack([np.ones(len(X)), X])
        return X_design @ self.beta

    def get_leverage(self):
        H = self.X_design @ inv(self.X_design.T @ self.X_design) @ self.X_design.T
        return np.diag(H)

    def get_cooks_distance(self):
        leverage = self.get_leverage()
        std_resid = self.residuals / np.sqrt(self.mse * (1 - leverage))
        return (std_resid**2 / self.p) * (leverage / (1 - leverage))

    def get_vif(self, X):
        """Calculate VIF for each predictor."""
        n_pred = X.shape[1]
        vif = np.zeros(n_pred)

        for i in range(n_pred):
            # Regress Xi on all other predictors
            other_cols = [j for j in range(n_pred) if j != i]
            if len(other_cols) > 0:
                X_other = X[:, other_cols]
                model_temp = MultipleRegression().fit(X_other, X[:, i])
                vif[i] = 1 / (1 - model_temp.r_squared)
            else:
                vif[i] = 1.0

        return vif

# Generate sample data
np.random.seed(42)
n = 100

# Predictors
X1 = np.random.normal(50, 10, n)
X2 = np.random.normal(30, 5, n)
X3 = 0.5 * X1 + np.random.normal(0, 5, n)  # Correlated with X1

# Response with known coefficients
true_beta = [10, 2, -1.5, 0.8]
y = (true_beta[0] + true_beta[1]*X1 + true_beta[2]*X2 + true_beta[3]*X3 +
     np.random.normal(0, 10, n))

X = np.column_stack([X1, X2, X3])
model = MultipleRegression().fit(X, y)

# Calculate VIF
vif_values = model.get_vif(X)

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Actual vs Predicted
axes[0, 0].scatter(y, model.fitted, alpha=0.6, s=30)
min_val = min(y.min(), model.fitted.min())
max_val = max(y.max(), model.fitted.max())
axes[0, 0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)
axes[0, 0].set_xlabel('Actual Values')
axes[0, 0].set_ylabel('Predicted Values')
axes[0, 0].set_title(f'Actual vs Predicted ($R^2$ = {model.r_squared:.3f})')
axes[0, 0].grid(True, alpha=0.3)

# Coefficient plot
coef_names = ['Intercept', '$X_1$', '$X_2$', '$X_3$']
y_pos = np.arange(len(coef_names))
colors = ['green' if p < 0.05 else 'red' for p in model.p_values]

axes[0, 1].barh(y_pos, model.beta, xerr=1.96*model.se, color=colors, alpha=0.7, capsize=3)
axes[0, 1].axvline(0, color='black', linestyle='-', linewidth=1)
axes[0, 1].set_yticks(y_pos)
axes[0, 1].set_yticklabels(coef_names)
axes[0, 1].set_xlabel('Coefficient Value')
axes[0, 1].set_title('Regression Coefficients (95\% CI)')
axes[0, 1].grid(True, alpha=0.3)

# VIF plot
vif_names = ['$X_1$', '$X_2$', '$X_3$']
vif_colors = ['red' if v > 5 else 'orange' if v > 2.5 else 'green' for v in vif_values]
axes[1, 0].bar(vif_names, vif_values, color=vif_colors, alpha=0.7, edgecolor='black')
axes[1, 0].axhline(5, color='r', linestyle='--', linewidth=2, label='VIF = 5')
axes[1, 0].axhline(10, color='darkred', linestyle='--', linewidth=2, label='VIF = 10')
axes[1, 0].set_ylabel('VIF')
axes[1, 0].set_title('Variance Inflation Factors')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# Correlation matrix
corr_matrix = np.corrcoef(X.T)
im = axes[1, 1].imshow(corr_matrix, cmap='RdBu', vmin=-1, vmax=1)
axes[1, 1].set_xticks(range(3))
axes[1, 1].set_xticklabels(['$X_1$', '$X_2$', '$X_3$'])
axes[1, 1].set_yticks(range(3))
axes[1, 1].set_yticklabels(['$X_1$', '$X_2$', '$X_3$'])
for i in range(3):
    for j in range(3):
        axes[1, 1].text(j, i, f'{corr_matrix[i, j]:.2f}', ha='center', va='center')
axes[1, 1].set_title('Predictor Correlation Matrix')
plt.colorbar(im, ax=axes[1, 1])

plt.tight_layout()
save_plot('regression_fit.pdf',
          'Multiple regression model fit with coefficient estimates and multicollinearity diagnostics.')
\end{pycode}

\section{Residual Diagnostics}
\begin{pycode}
fig, axes = plt.subplots(2, 3, figsize=(14, 9))

# Residuals vs Fitted
axes[0, 0].scatter(model.fitted, model.residuals, alpha=0.6, s=30)
axes[0, 0].axhline(0, color='r', linestyle='--', linewidth=2)
# Add lowess smoothing approximation
z = np.polyfit(model.fitted, model.residuals, 3)
p_fit = np.poly1d(z)
x_smooth = np.linspace(model.fitted.min(), model.fitted.max(), 100)
axes[0, 0].plot(x_smooth, p_fit(x_smooth), 'b-', linewidth=2, alpha=0.7)
axes[0, 0].set_xlabel('Fitted Values')
axes[0, 0].set_ylabel('Residuals')
axes[0, 0].set_title('Residuals vs Fitted')
axes[0, 0].grid(True, alpha=0.3)

# Q-Q plot
stats.probplot(model.residuals, dist="norm", plot=axes[0, 1])
axes[0, 1].set_title('Normal Q-Q Plot')
axes[0, 1].grid(True, alpha=0.3)

# Scale-Location (sqrt standardized residuals)
std_resid = model.residuals / np.sqrt(model.mse)
axes[0, 2].scatter(model.fitted, np.sqrt(np.abs(std_resid)), alpha=0.6, s=30)
z = np.polyfit(model.fitted, np.sqrt(np.abs(std_resid)), 1)
p_fit = np.poly1d(z)
axes[0, 2].plot(x_smooth, p_fit(x_smooth), 'r-', linewidth=2)
axes[0, 2].set_xlabel('Fitted Values')
axes[0, 2].set_ylabel('$\sqrt{|Standardized Residuals|}$')
axes[0, 2].set_title('Scale-Location Plot')
axes[0, 2].grid(True, alpha=0.3)

# Residuals histogram
axes[1, 0].hist(model.residuals, bins=20, density=True, alpha=0.7, edgecolor='black')
x_norm = np.linspace(model.residuals.min(), model.residuals.max(), 100)
axes[1, 0].plot(x_norm, stats.norm.pdf(x_norm, 0, np.std(model.residuals)), 'r-', linewidth=2)
axes[1, 0].set_xlabel('Residuals')
axes[1, 0].set_ylabel('Density')
axes[1, 0].set_title('Residual Distribution')
axes[1, 0].grid(True, alpha=0.3)

# Residuals vs each predictor
axes[1, 1].scatter(X[:, 0], model.residuals, alpha=0.6, s=30)
axes[1, 1].axhline(0, color='r', linestyle='--', linewidth=2)
axes[1, 1].set_xlabel('$X_1$')
axes[1, 1].set_ylabel('Residuals')
axes[1, 1].set_title('Residuals vs $X_1$')
axes[1, 1].grid(True, alpha=0.3)

axes[1, 2].scatter(X[:, 1], model.residuals, alpha=0.6, s=30)
axes[1, 2].axhline(0, color='r', linestyle='--', linewidth=2)
axes[1, 2].set_xlabel('$X_2$')
axes[1, 2].set_ylabel('Residuals')
axes[1, 2].set_title('Residuals vs $X_2$')
axes[1, 2].grid(True, alpha=0.3)

plt.tight_layout()
save_plot('residual_diagnostics.pdf',
          'Residual diagnostic plots for checking regression assumptions.')

# Normality test
shapiro_stat, shapiro_p = stats.shapiro(model.residuals)

# Breusch-Pagan test approximation (residuals^2 vs fitted)
bp_corr, bp_p = stats.pearsonr(model.fitted, model.residuals**2)
\end{pycode}

\section{Influential Observations}
\begin{pycode}
# Calculate influence measures
leverage = model.get_leverage()
cooks_d = model.get_cooks_distance()
std_resid = model.residuals / np.sqrt(model.mse * (1 - leverage))

# Thresholds
leverage_threshold = 2 * model.p / model.n
cooks_threshold = 4 / model.n

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Leverage vs Standardized Residuals (Influence Plot)
axes[0, 0].scatter(leverage, std_resid, alpha=0.6, s=30)
axes[0, 0].axhline(-2, color='r', linestyle='--', alpha=0.5)
axes[0, 0].axhline(2, color='r', linestyle='--', alpha=0.5)
axes[0, 0].axvline(leverage_threshold, color='b', linestyle='--', alpha=0.5)
# Highlight influential points
influential = (np.abs(std_resid) > 2) | (leverage > leverage_threshold)
axes[0, 0].scatter(leverage[influential], std_resid[influential], color='red', s=50, marker='x')
axes[0, 0].set_xlabel('Leverage')
axes[0, 0].set_ylabel('Standardized Residuals')
axes[0, 0].set_title('Influence Plot')
axes[0, 0].grid(True, alpha=0.3)

# Cook's Distance
axes[0, 1].stem(range(n), cooks_d, linefmt='b-', markerfmt='bo', basefmt='k-')
axes[0, 1].axhline(cooks_threshold, color='r', linestyle='--', linewidth=2, label=f'Threshold = {cooks_threshold:.3f}')
high_cooks = np.where(cooks_d > cooks_threshold)[0]
for idx in high_cooks:
    axes[0, 1].annotate(str(idx), (idx, cooks_d[idx]), fontsize=8)
axes[0, 1].set_xlabel('Observation Index')
axes[0, 1].set_ylabel("Cook's Distance")
axes[0, 1].set_title("Cook's Distance")
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Leverage values
axes[1, 0].stem(range(n), leverage, linefmt='g-', markerfmt='go', basefmt='k-')
axes[1, 0].axhline(leverage_threshold, color='r', linestyle='--', linewidth=2,
                   label=f'Threshold = {leverage_threshold:.3f}')
axes[1, 0].set_xlabel('Observation Index')
axes[1, 0].set_ylabel('Leverage')
axes[1, 0].set_title('Leverage Values')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# DFBETAS for beta_1
# Approximate DFBETAS
dfbetas_1 = []
for i in range(n):
    # Leave-one-out
    mask = np.ones(n, dtype=bool)
    mask[i] = False
    model_loo = MultipleRegression().fit(X[mask], y[mask])
    dfbetas_1.append((model.beta[1] - model_loo.beta[1]) /
                     (model.se[1] * np.sqrt(1 - leverage[i]) + 1e-10))

dfbetas_1 = np.array(dfbetas_1)
dfbetas_threshold = 2 / np.sqrt(n)

axes[1, 1].stem(range(n), dfbetas_1, linefmt='purple', markerfmt='o', basefmt='k-')
axes[1, 1].axhline(dfbetas_threshold, color='r', linestyle='--', alpha=0.5)
axes[1, 1].axhline(-dfbetas_threshold, color='r', linestyle='--', alpha=0.5)
axes[1, 1].set_xlabel('Observation Index')
axes[1, 1].set_ylabel('DFBETAS')
axes[1, 1].set_title('DFBETAS for $\\beta_1$')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
save_plot('influential_observations.pdf',
          'Influential observation diagnostics including leverage and Cook\'s distance.')

n_influential = sum(cooks_d > cooks_threshold)
n_high_leverage = sum(leverage > leverage_threshold)
\end{pycode}

\section{Model Comparison and Selection}
\begin{pycode}
# Compare different models
def calculate_aic_bic(n, k, mse):
    """Calculate AIC and BIC."""
    log_likelihood = -n/2 * (np.log(2*np.pi) + np.log(mse) + 1)
    aic = 2*k - 2*log_likelihood
    bic = k*np.log(n) - 2*log_likelihood
    return aic, bic

# Fit models with different predictors
models_info = []

# Model 1: X1 only
model1 = MultipleRegression().fit(X[:, [0]], y)
aic1, bic1 = calculate_aic_bic(n, 2, model1.mse)
models_info.append(('$X_1$', model1.r_squared, model1.adj_r_squared, aic1, bic1))

# Model 2: X1 + X2
model2 = MultipleRegression().fit(X[:, [0, 1]], y)
aic2, bic2 = calculate_aic_bic(n, 3, model2.mse)
models_info.append(('$X_1, X_2$', model2.r_squared, model2.adj_r_squared, aic2, bic2))

# Model 3: All predictors
aic3, bic3 = calculate_aic_bic(n, 4, model.mse)
models_info.append(('$X_1, X_2, X_3$', model.r_squared, model.adj_r_squared, aic3, bic3))

# Model 4: X2 + X3
model4 = MultipleRegression().fit(X[:, [1, 2]], y)
aic4, bic4 = calculate_aic_bic(n, 3, model4.mse)
models_info.append(('$X_2, X_3$', model4.r_squared, model4.adj_r_squared, aic4, bic4))

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# R-squared comparison
model_names = [m[0] for m in models_info]
r_squared_vals = [m[1] for m in models_info]
adj_r_squared_vals = [m[2] for m in models_info]

x_pos = np.arange(len(model_names))
width = 0.35

axes[0, 0].bar(x_pos - width/2, r_squared_vals, width, label='$R^2$', alpha=0.7)
axes[0, 0].bar(x_pos + width/2, adj_r_squared_vals, width, label='Adj. $R^2$', alpha=0.7)
axes[0, 0].set_xticks(x_pos)
axes[0, 0].set_xticklabels(model_names, fontsize=9)
axes[0, 0].set_ylabel('$R^2$')
axes[0, 0].set_title('Model Comparison: $R^2$')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# AIC/BIC comparison
aic_vals = [m[3] for m in models_info]
bic_vals = [m[4] for m in models_info]

axes[0, 1].bar(x_pos - width/2, aic_vals, width, label='AIC', alpha=0.7)
axes[0, 1].bar(x_pos + width/2, bic_vals, width, label='BIC', alpha=0.7)
axes[0, 1].set_xticks(x_pos)
axes[0, 1].set_xticklabels(model_names, fontsize=9)
axes[0, 1].set_ylabel('Information Criterion')
axes[0, 1].set_title('Model Comparison: AIC/BIC')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Partial regression plots
# Effect of X1 controlling for X2
resid_y_on_x2 = y - MultipleRegression().fit(X[:, [1]], y).fitted
resid_x1_on_x2 = X[:, 0] - MultipleRegression().fit(X[:, [1]], X[:, 0]).fitted

axes[1, 0].scatter(resid_x1_on_x2, resid_y_on_x2, alpha=0.6, s=30)
z = np.polyfit(resid_x1_on_x2, resid_y_on_x2, 1)
p_fit = np.poly1d(z)
x_range = np.linspace(resid_x1_on_x2.min(), resid_x1_on_x2.max(), 100)
axes[1, 0].plot(x_range, p_fit(x_range), 'r-', linewidth=2)
axes[1, 0].set_xlabel('$X_1$ | $X_2$')
axes[1, 0].set_ylabel('$Y$ | $X_2$')
axes[1, 0].set_title('Partial Regression: $X_1$ controlling for $X_2$')
axes[1, 0].grid(True, alpha=0.3)

# Added variable plot for X2
resid_y_on_x1 = y - MultipleRegression().fit(X[:, [0]], y).fitted
resid_x2_on_x1 = X[:, 1] - MultipleRegression().fit(X[:, [0]], X[:, 1]).fitted

axes[1, 1].scatter(resid_x2_on_x1, resid_y_on_x1, alpha=0.6, s=30)
z = np.polyfit(resid_x2_on_x1, resid_y_on_x1, 1)
p_fit = np.poly1d(z)
x_range = np.linspace(resid_x2_on_x1.min(), resid_x2_on_x1.max(), 100)
axes[1, 1].plot(x_range, p_fit(x_range), 'r-', linewidth=2)
axes[1, 1].set_xlabel('$X_2$ | $X_1$')
axes[1, 1].set_ylabel('$Y$ | $X_1$')
axes[1, 1].set_title('Partial Regression: $X_2$ controlling for $X_1$')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
save_plot('model_selection.pdf',
          'Model comparison using $R^2$, AIC, BIC, and partial regression plots.')

best_aic_model = model_names[np.argmin(aic_vals)]
best_bic_model = model_names[np.argmin(bic_vals)]
\end{pycode}

\section{Prediction Intervals}
\begin{pycode}
# Generate predictions with confidence and prediction intervals
X_new = np.column_stack([
    np.linspace(30, 70, 50),
    np.full(50, 30),
    np.linspace(15, 35, 50)
])

y_pred = model.predict(X_new)

# Variance of predictions
X_new_design = np.column_stack([np.ones(50), X_new])
XtX_inv = inv(model.X_design.T @ model.X_design)

# Confidence interval (for mean)
var_mean = np.array([x @ XtX_inv @ x for x in X_new_design]) * model.mse
se_mean = np.sqrt(var_mean)
t_crit = stats.t.ppf(0.975, model.n - model.p)

ci_lower = y_pred - t_crit * se_mean
ci_upper = y_pred + t_crit * se_mean

# Prediction interval (for individual)
var_pred = var_mean + model.mse
se_pred = np.sqrt(var_pred)

pi_lower = y_pred - t_crit * se_pred
pi_upper = y_pred + t_crit * se_pred

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Prediction with intervals
x_plot = X_new[:, 0]
axes[0, 0].scatter(X[:, 0], y, alpha=0.5, s=30, label='Data')
axes[0, 0].plot(x_plot, y_pred, 'r-', linewidth=2, label='Prediction')
axes[0, 0].fill_between(x_plot, ci_lower, ci_upper, alpha=0.3, color='blue', label='95\% CI')
axes[0, 0].fill_between(x_plot, pi_lower, pi_upper, alpha=0.15, color='green', label='95\% PI')
axes[0, 0].set_xlabel('$X_1$')
axes[0, 0].set_ylabel('$Y$')
axes[0, 0].set_title('Predictions with Confidence and Prediction Intervals')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Interval width comparison
axes[0, 1].plot(x_plot, ci_upper - ci_lower, 'b-', linewidth=2, label='CI Width')
axes[0, 1].plot(x_plot, pi_upper - pi_lower, 'g-', linewidth=2, label='PI Width')
axes[0, 1].set_xlabel('$X_1$')
axes[0, 1].set_ylabel('Interval Width')
axes[0, 1].set_title('Interval Width Comparison')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Cross-validation (leave-one-out)
cv_errors = []
for i in range(n):
    mask = np.ones(n, dtype=bool)
    mask[i] = False
    model_cv = MultipleRegression().fit(X[mask], y[mask])
    pred_i = model_cv.predict(X[i:i+1, :])
    cv_errors.append((y[i] - pred_i[0])**2)

cv_mse = np.mean(cv_errors)
cv_rmse = np.sqrt(cv_mse)

axes[1, 0].hist(np.sqrt(cv_errors), bins=20, alpha=0.7, edgecolor='black')
axes[1, 0].axvline(cv_rmse, color='r', linestyle='--', linewidth=2,
                   label=f'RMSE = {cv_rmse:.2f}')
axes[1, 0].set_xlabel('Absolute CV Error')
axes[1, 0].set_ylabel('Frequency')
axes[1, 0].set_title('Leave-One-Out Cross-Validation Errors')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# Observed vs CV predicted
cv_predictions = []
for i in range(n):
    mask = np.ones(n, dtype=bool)
    mask[i] = False
    model_cv = MultipleRegression().fit(X[mask], y[mask])
    cv_predictions.append(model_cv.predict(X[i:i+1, :])[0])

axes[1, 1].scatter(y, cv_predictions, alpha=0.6, s=30)
min_val = min(min(y), min(cv_predictions))
max_val = max(max(y), max(cv_predictions))
axes[1, 1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)
axes[1, 1].set_xlabel('Observed')
axes[1, 1].set_ylabel('CV Predicted')
axes[1, 1].set_title('Leave-One-Out CV: Observed vs Predicted')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
save_plot('prediction_intervals.pdf',
          'Prediction and confidence intervals with cross-validation assessment.')
\end{pycode}

\section{Results Summary}

\subsection{Regression Coefficients}
\begin{pycode}
print(r'\begin{table}[htbp]')
print(r'\centering')
print(r'\caption{Multiple Regression Coefficient Estimates}')
print(r'\begin{tabular}{lccccc}')
print(r'\toprule')
print(r'Term & True $\beta$ & Estimate & Std. Error & t-stat & p-value \\')
print(r'\midrule')

terms = ['Intercept', '$X_1$', '$X_2$', '$X_3$']
for i, term in enumerate(terms):
    sig = '*' if model.p_values[i] < 0.05 else ''
    print(f'{term} & {true_beta[i]:.1f} & {model.beta[i]:.3f} & {model.se[i]:.3f} & {model.t_stats[i]:.2f} & {model.p_values[i]:.4f}{sig} \\\\')

print(r'\bottomrule')
print(r'\end{tabular}')
print(r'\end{table}')
\end{pycode}

\subsection{Model Fit Statistics}
\begin{pycode}
print(r'\begin{table}[htbp]')
print(r'\centering')
print(r'\caption{Model Fit Statistics}')
print(r'\begin{tabular}{lc}')
print(r'\toprule')
print(r'Statistic & Value \\')
print(r'\midrule')
print(f'$R^2$ & {model.r_squared:.4f} \\\\')
print(f'Adjusted $R^2$ & {model.adj_r_squared:.4f} \\\\')
print(f'RMSE & {np.sqrt(model.mse):.3f} \\\\')
print(f'CV RMSE (LOO) & {cv_rmse:.3f} \\\\')
print(f'AIC & {aic3:.1f} \\\\')
print(f'BIC & {bic3:.1f} \\\\')
print(r'\bottomrule')
print(r'\end{tabular}')
print(r'\end{table}')
\end{pycode}

\subsection{Diagnostic Statistics}
\begin{pycode}
print(r'\begin{table}[htbp]')
print(r'\centering')
print(r'\caption{Diagnostic Test Results}')
print(r'\begin{tabular}{lcc}')
print(r'\toprule')
print(r'Diagnostic & Test Value & Interpretation \\')
print(r'\midrule')
print(f'Shapiro-Wilk (normality) & p = {shapiro_p:.4f} & {"Normal" if shapiro_p > 0.05 else "Non-normal"} \\\\')
print(f'VIF ($X_1$) & {vif_values[0]:.2f} & {"High" if vif_values[0] > 5 else "OK"} \\\\')
print(f'VIF ($X_2$) & {vif_values[1]:.2f} & {"High" if vif_values[1] > 5 else "OK"} \\\\')
print(f'VIF ($X_3$) & {vif_values[2]:.2f} & {"High" if vif_values[2] > 5 else "OK"} \\\\')
print(f'High leverage points & {n_high_leverage} & --- \\\\')
print(f"High Cook's D points & {n_influential} & --- \\\\")
print(r'\bottomrule')
print(r'\end{tabular}')
print(r'\end{table}')
\end{pycode}

\section{Statistical Summary}
Key regression analysis findings:
\begin{itemize}
    \item Model $R^2$: \py{f"{model.r_squared:.4f}"} (Adjusted: \py{f"{model.adj_r_squared:.4f}"})
    \item Root MSE: \py{f"{np.sqrt(model.mse):.3f}"}
    \item Cross-validation RMSE: \py{f"{cv_rmse:.3f}"}
    \item VIF range: \py{f"{vif_values.min():.2f}"} to \py{f"{vif_values.max():.2f}"}
    \item Influential observations: \py{f"{n_influential}"} (Cook's D $>$ threshold)
    \item Best model by AIC: \py{best_aic_model}
    \item Residual normality (Shapiro-Wilk p): \py{f"{shapiro_p:.4f}"}
\end{itemize}

\section{Conclusion}
This comprehensive regression analysis demonstrates model building, assumption checking, and
diagnostic procedures for multiple regression. The variance inflation factors reveal
multicollinearity between $X_1$ and $X_3$, which inflates standard errors but does not bias
coefficient estimates. Residual diagnostics confirm approximate normality and homoscedasticity.
Cook's distance and leverage analysis identify influential observations that may warrant
further investigation. Model selection criteria (AIC, BIC) and cross-validation help balance
model complexity against predictive performance. These tools together enable robust statistical
inference and reliable predictions.

\end{document}
