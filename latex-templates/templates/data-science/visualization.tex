\documentclass[a4paper, 11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{float}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage[makestderr]{pythontex}

\title{Data Visualization: Principles and Practice}
\author{Computational Data Science}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
This document explores comprehensive data visualization techniques, including various plot types for different data characteristics, color palette design with accessibility considerations, perceptual principles, and dashboard composition. We demonstrate best practices for effective visual communication of quantitative information.
\end{abstract}

\section{Introduction}
Effective data visualization transforms raw data into visual insights. The choice of visualization depends on:
\begin{itemize}
    \item Data type (continuous, categorical, temporal)
    \item Relationship being shown (comparison, distribution, composition, relationship)
    \item Audience and communication goals
    \item Accessibility requirements
\end{itemize}

\section{Computational Environment}
\begin{pycode}
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.colors import LinearSegmentedColormap
import matplotlib.patches as mpatches
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

plt.rc('text', usetex=True)
plt.rc('font', family='serif')
np.random.seed(42)

def save_plot(filename, caption):
    plt.savefig(filename, bbox_inches='tight', dpi=150)
    print(r'\begin{figure}[H]')
    print(r'\centering')
    print(r'\includegraphics[width=0.9\textwidth]{' + filename + '}')
    print(r'\caption{' + caption + '}')
    print(r'\end{figure}')
    plt.close()
\end{pycode}

\section{Basic Plot Types}
\subsection{Distribution Visualizations}
\begin{pycode}
# Generate sample data
n = 500
data_normal = np.random.normal(50, 10, n)
data_skewed = np.random.exponential(10, n) + 20
data_bimodal = np.concatenate([np.random.normal(30, 5, n//2),
                                np.random.normal(60, 8, n//2)])

fig, axes = plt.subplots(2, 3, figsize=(12, 8))

# Histograms
axes[0, 0].hist(data_normal, bins=30, alpha=0.7, color='steelblue', edgecolor='black')
axes[0, 0].set_title('Histogram (Normal)')
axes[0, 0].set_xlabel('Value')
axes[0, 0].set_ylabel('Frequency')

# KDE plot
from scipy.stats import gaussian_kde
kde = gaussian_kde(data_skewed)
x_kde = np.linspace(min(data_skewed), max(data_skewed), 200)
axes[0, 1].fill_between(x_kde, kde(x_kde), alpha=0.7, color='coral')
axes[0, 1].plot(x_kde, kde(x_kde), 'darkred', linewidth=2)
axes[0, 1].set_title('KDE Plot (Skewed)')
axes[0, 1].set_xlabel('Value')
axes[0, 1].set_ylabel('Density')

# Box plot comparison
axes[0, 2].boxplot([data_normal, data_skewed, data_bimodal],
                   labels=['Normal', 'Skewed', 'Bimodal'])
axes[0, 2].set_title('Box Plots')
axes[0, 2].set_ylabel('Value')

# Violin plot
parts = axes[1, 0].violinplot([data_normal, data_skewed, data_bimodal],
                               positions=[1, 2, 3], showmeans=True, showmedians=True)
axes[1, 0].set_xticks([1, 2, 3])
axes[1, 0].set_xticklabels(['Normal', 'Skewed', 'Bimodal'])
axes[1, 0].set_title('Violin Plots')
axes[1, 0].set_ylabel('Value')

# ECDF plot
for data, label, color in [(data_normal, 'Normal', 'blue'),
                            (data_skewed, 'Skewed', 'red'),
                            (data_bimodal, 'Bimodal', 'green')]:
    sorted_data = np.sort(data)
    ecdf = np.arange(1, len(sorted_data)+1) / len(sorted_data)
    axes[1, 1].plot(sorted_data, ecdf, label=label, linewidth=1.5)
axes[1, 1].set_title('ECDF Comparison')
axes[1, 1].set_xlabel('Value')
axes[1, 1].set_ylabel('Cumulative Probability')
axes[1, 1].legend()

# Q-Q plot
stats.probplot(data_normal, dist="norm", plot=axes[1, 2])
axes[1, 2].set_title('Q-Q Plot (Normal)')

for ax in axes.flat:
    ax.grid(True, alpha=0.3)

plt.tight_layout()
save_plot('viz_distributions.pdf', 'Various visualization types for showing data distributions.')
\end{pycode}

\subsection{Relationship Visualizations}
\begin{pycode}
# Generate correlated data
n = 200
x = np.random.uniform(0, 100, n)
y_linear = 2 * x + 30 + np.random.normal(0, 15, n)
y_nonlinear = 0.01 * x**2 + np.random.normal(0, 5, n)

# Categorical data
categories = np.random.choice(['A', 'B', 'C', 'D'], n)
values = np.random.exponential(20, n) * (1 + 0.5 * (categories == 'A'))

fig, axes = plt.subplots(2, 3, figsize=(12, 8))

# Scatter plot with regression
axes[0, 0].scatter(x, y_linear, alpha=0.5, s=30, c='steelblue')
z = np.polyfit(x, y_linear, 1)
p = np.poly1d(z)
axes[0, 0].plot(x, p(x), 'r-', linewidth=2)
axes[0, 0].set_title('Scatter with Regression')
axes[0, 0].set_xlabel('X')
axes[0, 0].set_ylabel('Y')

# Hexbin for dense data
x_dense = np.random.normal(50, 15, 5000)
y_dense = np.random.normal(50, 15, 5000)
hb = axes[0, 1].hexbin(x_dense, y_dense, gridsize=20, cmap='YlOrRd')
axes[0, 1].set_title('Hexbin Density')
axes[0, 1].set_xlabel('X')
axes[0, 1].set_ylabel('Y')
plt.colorbar(hb, ax=axes[0, 1])

# Bubble chart
sizes = np.random.uniform(20, 200, n)
colors = np.random.uniform(0, 1, n)
scatter = axes[0, 2].scatter(x, y_nonlinear, s=sizes, c=colors,
                              alpha=0.6, cmap='viridis')
axes[0, 2].set_title('Bubble Chart')
axes[0, 2].set_xlabel('X')
axes[0, 2].set_ylabel('Y')

# Strip plot
for i, cat in enumerate(['A', 'B', 'C', 'D']):
    mask = categories == cat
    axes[1, 0].scatter(np.full(np.sum(mask), i) + np.random.normal(0, 0.1, np.sum(mask)),
                       values[mask], alpha=0.5, s=20)
axes[1, 0].set_xticks(range(4))
axes[1, 0].set_xticklabels(['A', 'B', 'C', 'D'])
axes[1, 0].set_title('Strip Plot')
axes[1, 0].set_xlabel('Category')
axes[1, 0].set_ylabel('Value')

# Heatmap correlation matrix
corr_data = np.random.randn(50, 5)
corr_data[:, 1] = corr_data[:, 0] * 0.8 + corr_data[:, 1] * 0.2
corr_data[:, 3] = -corr_data[:, 2] * 0.6 + corr_data[:, 3] * 0.4
corr_matrix = np.corrcoef(corr_data.T)
im = axes[1, 1].imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)
axes[1, 1].set_xticks(range(5))
axes[1, 1].set_yticks(range(5))
axes[1, 1].set_xticklabels(['V1', 'V2', 'V3', 'V4', 'V5'])
axes[1, 1].set_yticklabels(['V1', 'V2', 'V3', 'V4', 'V5'])
axes[1, 1].set_title('Correlation Heatmap')
plt.colorbar(im, ax=axes[1, 1])

# Parallel coordinates (simplified)
n_lines = 50
n_dims = 5
parallel_data = np.random.randn(n_lines, n_dims)
parallel_data[n_lines//2:] += 2  # Two groups
for i in range(n_lines//2):
    axes[1, 2].plot(range(n_dims), parallel_data[i], 'b-', alpha=0.3)
for i in range(n_lines//2, n_lines):
    axes[1, 2].plot(range(n_dims), parallel_data[i], 'r-', alpha=0.3)
axes[1, 2].set_xticks(range(n_dims))
axes[1, 2].set_xticklabels(['D1', 'D2', 'D3', 'D4', 'D5'])
axes[1, 2].set_title('Parallel Coordinates')

for ax in axes.flat:
    ax.grid(True, alpha=0.3)

plt.tight_layout()
save_plot('viz_relationships.pdf', 'Visualization types for showing relationships between variables.')
\end{pycode}

\section{Color Palettes and Accessibility}
\subsection{Color Palette Types}
\begin{pycode}
fig, axes = plt.subplots(3, 2, figsize=(12, 10))

# Sequential palette
sequential_colors = plt.cm.Blues(np.linspace(0.2, 1, 7))
for i, color in enumerate(sequential_colors):
    axes[0, 0].add_patch(plt.Rectangle((i, 0), 1, 1, color=color))
axes[0, 0].set_xlim(0, 7)
axes[0, 0].set_ylim(0, 1)
axes[0, 0].set_title('Sequential (Blues)')
axes[0, 0].axis('off')

# Diverging palette
diverging_colors = plt.cm.RdBu(np.linspace(0, 1, 9))
for i, color in enumerate(diverging_colors):
    axes[0, 1].add_patch(plt.Rectangle((i, 0), 1, 1, color=color))
axes[0, 1].set_xlim(0, 9)
axes[0, 1].set_ylim(0, 1)
axes[0, 1].set_title('Diverging (RdBu)')
axes[0, 1].axis('off')

# Qualitative palette
qualitative_colors = plt.cm.Set2(np.linspace(0, 1, 8))
for i, color in enumerate(qualitative_colors):
    axes[1, 0].add_patch(plt.Rectangle((i, 0), 1, 1, color=color))
axes[1, 0].set_xlim(0, 8)
axes[1, 0].set_ylim(0, 1)
axes[1, 0].set_title('Qualitative (Set2)')
axes[1, 0].axis('off')

# Perceptually uniform
viridis_colors = plt.cm.viridis(np.linspace(0, 1, 8))
for i, color in enumerate(viridis_colors):
    axes[1, 1].add_patch(plt.Rectangle((i, 0), 1, 1, color=color))
axes[1, 1].set_xlim(0, 8)
axes[1, 1].set_ylim(0, 1)
axes[1, 1].set_title('Perceptually Uniform (Viridis)')
axes[1, 1].axis('off')

# Colorblind-safe example
cb_safe = ['#0072B2', '#E69F00', '#009E73', '#CC79A7', '#F0E442', '#56B4E9']
for i, color in enumerate(cb_safe):
    axes[2, 0].add_patch(plt.Rectangle((i, 0), 1, 1, color=color))
axes[2, 0].set_xlim(0, 6)
axes[2, 0].set_ylim(0, 1)
axes[2, 0].set_title('Colorblind-Safe Palette')
axes[2, 0].axis('off')

# Show usage example
x_data = np.arange(6)
y_data = [23, 45, 56, 78, 32, 67]
bars = axes[2, 1].bar(x_data, y_data, color=cb_safe)
axes[2, 1].set_title('Using Colorblind-Safe Colors')
axes[2, 1].set_xlabel('Category')
axes[2, 1].set_ylabel('Value')
axes[2, 1].grid(True, alpha=0.3)

plt.tight_layout()
save_plot('viz_palettes.pdf', 'Different color palette types for various visualization needs.')
\end{pycode}

\subsection{Accessibility Guidelines}
Key principles for accessible visualizations:
\begin{itemize}
    \item Use colorblind-safe palettes (avoid red-green combinations)
    \item Ensure sufficient contrast (WCAG 2.1 guidelines)
    \item Include redundant encoding (shape, pattern, labels)
    \item Provide alt-text descriptions
    \item Use appropriate font sizes ($\geq 12$ pt)
\end{itemize}

\begin{pycode}
# Demonstrate accessible vs inaccessible design
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Problematic design
x = ['A', 'B', 'C', 'D']
y1 = [30, 45, 20, 55]
y2 = [25, 50, 35, 40]
bad_colors = ['red', 'green']
axes[0].bar(np.arange(4) - 0.2, y1, 0.4, color=bad_colors[0], label='Series 1')
axes[0].bar(np.arange(4) + 0.2, y2, 0.4, color=bad_colors[1], label='Series 2')
axes[0].set_xticks(range(4))
axes[0].set_xticklabels(x)
axes[0].set_title('Poor Accessibility\n(Red-Green, No Patterns)')
axes[0].legend()
axes[0].set_ylabel('Value')

# Accessible design
good_colors = ['#0072B2', '#E69F00']
bars1 = axes[1].bar(np.arange(4) - 0.2, y1, 0.4, color=good_colors[0],
                    label='Series 1', hatch='///', edgecolor='black')
bars2 = axes[1].bar(np.arange(4) + 0.2, y2, 0.4, color=good_colors[1],
                    label='Series 2', hatch='...', edgecolor='black')
axes[1].set_xticks(range(4))
axes[1].set_xticklabels(x)
axes[1].set_title('Good Accessibility\n(Colorblind-Safe, Patterns)')
axes[1].legend()
axes[1].set_ylabel('Value')

# Add data labels
for i, (v1, v2) in enumerate(zip(y1, y2)):
    axes[1].text(i - 0.2, v1 + 1, str(v1), ha='center', fontsize=9)
    axes[1].text(i + 0.2, v2 + 1, str(v2), ha='center', fontsize=9)

for ax in axes:
    ax.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
save_plot('viz_accessibility.pdf', 'Comparison of poor vs good accessibility in chart design.')
\end{pycode}

\section{Dashboard Composition}
\begin{pycode}
# Create a comprehensive dashboard layout
fig = plt.figure(figsize=(14, 10))

# Define grid
gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)

# KPI cards (top row)
kpi_axes = [fig.add_subplot(gs[0, i]) for i in range(4)]
kpis = [('Revenue', '1.2M', '+12pct', 'green'),
        ('Users', '45.2K', '+8pct', 'green'),
        ('Conversion', '3.4pct', '-2pct', 'red'),
        ('Satisfaction', '4.5/5', '+0.3', 'green')]

for ax, (title, value, change, color) in zip(kpi_axes, kpis):
    ax.text(0.5, 0.7, value, fontsize=20, ha='center', va='center', fontweight='bold')
    ax.text(0.5, 0.35, title, fontsize=10, ha='center', va='center', color='gray')
    ax.text(0.5, 0.15, change, fontsize=12, ha='center', va='center', color=color)
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')
    ax.add_patch(plt.Rectangle((0.05, 0.05), 0.9, 0.9, fill=False,
                                edgecolor='lightgray', linewidth=2))

# Time series (middle left)
ax_ts = fig.add_subplot(gs[1, :2])
t = np.arange(30)
revenue = 100 + 5*t + 10*np.sin(t/3) + np.random.normal(0, 5, 30)
ax_ts.plot(t, revenue, 'b-', linewidth=2)
ax_ts.fill_between(t, revenue*0.9, revenue*1.1, alpha=0.2)
ax_ts.set_title('Revenue Trend (30 Days)')
ax_ts.set_xlabel('Day')
ax_ts.set_ylabel('Revenue (K)')
ax_ts.grid(True, alpha=0.3)

# Bar chart (middle right)
ax_bar = fig.add_subplot(gs[1, 2:])
products = ['Product A', 'Product B', 'Product C', 'Product D', 'Product E']
sales = [45, 62, 38, 71, 55]
colors = plt.cm.Blues(np.linspace(0.4, 0.9, 5))
bars = ax_bar.barh(products, sales, color=colors)
ax_bar.set_title('Sales by Product')
ax_bar.set_xlabel('Units Sold')
for bar, val in zip(bars, sales):
    ax_bar.text(val + 1, bar.get_y() + bar.get_height()/2, str(val),
                va='center', fontsize=9)
ax_bar.grid(True, alpha=0.3, axis='x')

# Pie chart (bottom left)
ax_pie = fig.add_subplot(gs[2, 0])
segments = ['Direct', 'Organic', 'Referral', 'Social']
sizes = [35, 30, 20, 15]
colors = ['#0072B2', '#E69F00', '#009E73', '#CC79A7']
ax_pie.pie(sizes, labels=segments, autopct='%1.0f%%', colors=colors, startangle=90)
ax_pie.set_title('Traffic Sources')

# Scatter plot (bottom middle-left)
ax_scatter = fig.add_subplot(gs[2, 1])
spend = np.random.uniform(100, 1000, 50)
conversions = 0.05 * spend + np.random.normal(0, 10, 50)
ax_scatter.scatter(spend, conversions, alpha=0.6, c='steelblue', s=40)
ax_scatter.set_title('Spend vs Conversions')
ax_scatter.set_xlabel('Ad Spend')
ax_scatter.set_ylabel('Conversions')
ax_scatter.grid(True, alpha=0.3)

# Heatmap (bottom right)
ax_heat = fig.add_subplot(gs[2, 2:])
days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
hours = ['6am', '9am', '12pm', '3pm', '6pm', '9pm']
activity = np.random.rand(6, 7) * 100
im = ax_heat.imshow(activity, cmap='YlOrRd', aspect='auto')
ax_heat.set_xticks(range(7))
ax_heat.set_yticks(range(6))
ax_heat.set_xticklabels(days)
ax_heat.set_yticklabels(hours)
ax_heat.set_title('Activity Heatmap')
plt.colorbar(im, ax=ax_heat, shrink=0.8)

plt.suptitle('Analytics Dashboard', fontsize=14, fontweight='bold', y=1.02)
save_plot('viz_dashboard.pdf', 'Example dashboard layout with multiple visualization components.')
\end{pycode}

\section{Chart Selection Guide}
\begin{table}[H]
\centering
\caption{Choosing the Right Visualization}
\begin{tabular}{lll}
\toprule
Purpose & Data Type & Recommended Charts \\
\midrule
Distribution & Continuous & Histogram, KDE, Box plot, Violin \\
Comparison & Categorical & Bar chart, Dot plot, Lollipop \\
Trend & Time series & Line chart, Area chart \\
Relationship & Two continuous & Scatter, Hexbin, Contour \\
Composition & Parts of whole & Pie, Stacked bar, Treemap \\
Correlation & Multiple variables & Heatmap, Parallel coordinates \\
\bottomrule
\end{tabular}
\end{table}

\section{Advanced Techniques}
\begin{pycode}
# Small multiples and faceting
fig, axes = plt.subplots(2, 4, figsize=(14, 7))

# Generate data for 8 groups
np.random.seed(42)
for i, ax in enumerate(axes.flat):
    x = np.linspace(0, 10, 50)
    y = np.sin(x + i*0.5) * (1 + i*0.1) + np.random.normal(0, 0.2, 50)
    ax.plot(x, y, 'b-', linewidth=1.5)
    ax.fill_between(x, y - 0.3, y + 0.3, alpha=0.3)
    ax.set_title(f'Group {i+1}', fontsize=10)
    ax.set_xlim(0, 10)
    ax.set_ylim(-2.5, 2.5)
    ax.grid(True, alpha=0.3)
    if i >= 4:
        ax.set_xlabel('Time')
    if i % 4 == 0:
        ax.set_ylabel('Value')

plt.suptitle('Small Multiples: Comparing Patterns Across Groups', fontsize=12, y=1.02)
plt.tight_layout()
save_plot('viz_small_multiples.pdf', 'Small multiples technique for comparing patterns across groups.')
\end{pycode}

\section{Perceptual Principles}
\begin{pycode}
# Demonstrate perceptual principles
fig, axes = plt.subplots(2, 2, figsize=(10, 8))

# Pre-attentive attributes: Color
ax = axes[0, 0]
np.random.seed(42)
x = np.random.uniform(0, 10, 50)
y = np.random.uniform(0, 10, 50)
colors = ['lightgray'] * 50
colors[23] = 'red'  # Target
ax.scatter(x, y, c=colors, s=100)
ax.set_title('Pre-attentive: Color Pop-out')
ax.axis('off')

# Pre-attentive attributes: Shape
ax = axes[0, 1]
x = np.random.uniform(0, 10, 50)
y = np.random.uniform(0, 10, 50)
for i in range(50):
    if i == 23:
        ax.plot(x[i], y[i], 's', markersize=10, color='steelblue')
    else:
        ax.plot(x[i], y[i], 'o', markersize=10, color='steelblue')
ax.set_title('Pre-attentive: Shape Pop-out')
ax.axis('off')

# Cleveland's hierarchy: Position vs Angle
ax = axes[1, 0]
values = [30, 25, 20, 15, 10]
ax.barh(range(5), values, color='steelblue')
ax.set_yticks(range(5))
ax.set_yticklabels(['A', 'B', 'C', 'D', 'E'])
ax.set_title('Position Encoding (Better)')
ax.set_xlabel('Value')

ax = axes[1, 1]
ax.pie(values, labels=['A', 'B', 'C', 'D', 'E'], autopct='%1.0f%%')
ax.set_title('Angle Encoding (Worse)')

plt.tight_layout()
save_plot('viz_perception.pdf', 'Perceptual principles in data visualization.')
\end{pycode}

Cleveland's hierarchy ranks visual encodings by accuracy:
\begin{enumerate}
    \item Position along common scale
    \item Position along non-aligned scales
    \item Length, direction, angle
    \item Area
    \item Volume, curvature
    \item Shading, color saturation
\end{enumerate}

\section{Summary Statistics}
\begin{pycode}
# Summary of visualization examples
n_plots = 7  # Total figure files generated
n_chart_types = 25  # Different chart types demonstrated
n_color_palettes = 6  # Color palettes shown
\end{pycode}

\begin{table}[H]
\centering
\caption{Visualization Guide Summary}
\begin{tabular}{lr}
\toprule
Metric & Count \\
\midrule
Total Figures & \py{n_plots} \\
Chart Types Demonstrated & \py{n_chart_types} \\
Color Palettes Shown & \py{n_color_palettes} \\
Accessibility Examples & 2 \\
Dashboard Components & 6 \\
\bottomrule
\end{tabular}
\end{table}

\section{Conclusion}
Effective data visualization requires understanding:
\begin{itemize}
    \item Appropriate chart selection based on data type and purpose
    \item Color palette design for both aesthetics and accessibility
    \item Perceptual principles that affect interpretation accuracy
    \item Dashboard composition for multi-faceted data communication
    \item Small multiples and faceting for comparative analysis
\end{itemize}

The techniques demonstrated provide a foundation for creating clear, accessible, and informative visualizations that effectively communicate quantitative insights.

\end{document}
