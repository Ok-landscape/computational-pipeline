# Social Media Posts: Rejection Sampling

## 1. Twitter/X (< 280 chars)

How do you sample from ANY probability distribution? Rejection sampling!

Accept if u ≤ f(x)/(M·g(x)), reject otherwise.

Von Neumann's 1951 algorithm still powers modern Monte Carlo methods.

#Python #Statistics #MonteCarlo #DataScience

---

## 2. Bluesky (< 300 chars)

Rejection sampling: Generate samples from hard-to-sample distributions using an easier "proposal" distribution.

The elegant math: Accept point x with probability f(x)/(M·g(x))

Implemented Beta(2.5, 5) sampling with 44% acceptance rate. Clean convergence to true moments.

#Science #Statistics

---

## 3. Threads (< 500 chars)

Ever wonder how computers generate random samples from complex probability distributions?

Rejection sampling is beautifully simple:
1. Draw x from an easy distribution g(x)
2. Accept with probability f(x)/(M·g(x))
3. Rejected? Try again!

John von Neumann invented this in 1951. I implemented it in Python to sample from a Beta distribution - watched it converge perfectly to the true mean and variance.

The key insight: efficiency depends entirely on how well your proposal approximates your target.

---

## 4. Mastodon (< 500 chars)

Implemented rejection sampling - fundamental Monte Carlo method for generating samples when direct sampling is impossible.

Algorithm:
- Sample x ~ g(x)
- Accept if u ≤ f(x)/(M·g(x))

Key result: Acceptance rate = 1/M

Tested with Beta(2.5, 5) target, Uniform(0,1) proposal:
- M = 2.25, acceptance rate ≈ 44%
- KS test confirms samples match true distribution
- Using Beta(2,4) proposal is 1.63x more efficient

The curse of dimensionality makes this impractical for high-D problems → use MCMC instead.

#Statistics #MonteCarlo #Python

---

## 5. Reddit

**Title:** Rejection Sampling Explained: How to Sample from ANY Distribution with Python

**Subreddit:** r/learnpython or r/statistics

**Body:**

I built a Python implementation of rejection sampling - one of the most elegant algorithms in computational statistics.

**The Problem:** You need random samples from a distribution f(x), but you can't sample from it directly.

**The Solution:** Use an "envelope" distribution g(x) that you CAN sample from, then accept/reject based on a simple rule.

**How it works:**
1. Draw x from your proposal distribution g(x)
2. Draw u from Uniform(0, 1)
3. If u ≤ f(x)/(M·g(x)), accept x; otherwise reject and repeat

**Why does this work?**

The probability of accepting at point x is proportional to f(x), so accepted samples follow the target distribution. The math proves out beautifully using Bayes' theorem.

**Key findings from my implementation:**
- Target: Beta(2.5, 5), Proposal: Uniform(0, 1)
- Scaling constant M = 2.25
- Acceptance rate: ~44%
- Sample mean converged to true mean (0.333)
- Kolmogorov-Smirnov test confirmed distribution match

**Efficiency insight:** Choosing a better proposal distribution dramatically improves efficiency. Using Beta(2, 4) instead of Uniform gives 1.63x better acceptance rate.

**Limitations:** This struggles in high dimensions (curse of dimensionality). For those problems, use MCMC methods like Metropolis-Hastings.

View and run the full notebook here:
https://cocalc.com/github/Ok-landscape/computational-pipeline/blob/main/notebooks/published/rejection_sampling.ipynb

---

## 6. Facebook (< 500 chars)

Ever wondered how computers generate random numbers from complex distributions?

Rejection sampling is brilliant in its simplicity: keep proposing random points until one "fits" under your target curve.

I coded this classic algorithm (invented by von Neumann in 1951!) and watched it generate 10,000 perfect samples from a Beta distribution. The sample statistics matched the theory exactly.

Still one of the most important tools in computational statistics!

Explore the interactive notebook: https://cocalc.com/github/Ok-landscape/computational-pipeline/blob/main/notebooks/published/rejection_sampling.ipynb

---

## 7. LinkedIn (< 1000 chars)

Implementing Rejection Sampling: A Fundamental Monte Carlo Method

I recently built a Python implementation of rejection sampling - John von Neumann's 1951 algorithm that remains foundational in computational statistics and machine learning.

The core challenge: generate samples from a probability distribution f(x) when direct sampling is impossible. The solution elegantly uses a "proposal" distribution g(x) and accepts/rejects based on the ratio f(x)/(M·g(x)).

Key technical results:
- Generated 10,000 samples from Beta(2.5, 5) using Uniform(0,1) proposal
- Achieved 44% acceptance rate (theoretical: 1/M = 44.4%)
- Kolmogorov-Smirnov test confirmed distributional accuracy
- Demonstrated convergence of sample moments to population parameters

The implementation highlights a critical efficiency consideration: proposal distribution selection. Using Beta(2,4) instead of Uniform improved efficiency by 63%.

Skills demonstrated: Monte Carlo methods, statistical validation, algorithm implementation, scientific visualization.

This technique underpins modern applications in Bayesian inference, generative models, and simulation.

View the full implementation: https://cocalc.com/github/Ok-landscape/computational-pipeline/blob/main/notebooks/published/rejection_sampling.ipynb

#MonteCarlo #Statistics #Python #DataScience #MachineLearning

---

## 8. Instagram (< 500 chars, visual-focused)

Rejection Sampling Visualized

This plot shows the beautiful geometry behind one of statistics' most elegant algorithms.

Red = target distribution we want to sample from
Blue = envelope that covers it
Green dots = accepted samples
Red dots = rejected samples

The magic: accepted points perfectly follow the target distribution!

Von Neumann invented this in 1951. Still essential for Monte Carlo methods today.

Swipe to see convergence plots showing sample statistics approaching true values.

#DataVisualization #Statistics #Python #MonteCarlo #Math #Science #Coding #DataScience
