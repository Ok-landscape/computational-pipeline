{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Game Theory\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Evolutionary Game Theory (EGT) extends classical game theory by incorporating dynamics of strategy evolution in populations. Unlike traditional game theory, which assumes rational players making optimal decisions, EGT models how strategies spread through a population based on their relative fitness.\n",
    "\n",
    "## Theoretical Framework\n",
    "\n",
    "### Payoff Matrix\n",
    "\n",
    "Consider a two-player symmetric game with strategies $S_1, S_2, \\ldots, S_n$. The interactions are described by a payoff matrix $\\mathbf{A}$ where element $a_{ij}$ represents the payoff to a player using strategy $i$ against an opponent using strategy $j$.\n",
    "\n",
    "### Population State\n",
    "\n",
    "The state of a population is described by a vector $\\mathbf{x} = (x_1, x_2, \\ldots, x_n)$ where $x_i$ represents the proportion of the population using strategy $i$. This vector lies on the simplex:\n",
    "\n",
    "$$\\Delta^n = \\left\\{ \\mathbf{x} \\in \\mathbb{R}^n : x_i \\geq 0, \\sum_{i=1}^n x_i = 1 \\right\\}$$\n",
    "\n",
    "### Fitness and Average Payoff\n",
    "\n",
    "The expected payoff (fitness) of strategy $i$ in population state $\\mathbf{x}$ is:\n",
    "\n",
    "$$f_i(\\mathbf{x}) = (\\mathbf{A}\\mathbf{x})_i = \\sum_{j=1}^n a_{ij} x_j$$\n",
    "\n",
    "The average fitness of the population is:\n",
    "\n",
    "$$\\bar{f}(\\mathbf{x}) = \\mathbf{x}^T \\mathbf{A} \\mathbf{x} = \\sum_{i=1}^n x_i f_i(\\mathbf{x})$$\n",
    "\n",
    "### Replicator Dynamics\n",
    "\n",
    "The replicator equation describes how strategy frequencies evolve over time:\n",
    "\n",
    "$$\\frac{dx_i}{dt} = x_i \\left[ f_i(\\mathbf{x}) - \\bar{f}(\\mathbf{x}) \\right]$$\n",
    "\n",
    "This equation captures the intuition that strategies with above-average fitness increase in frequency, while those with below-average fitness decrease.\n",
    "\n",
    "### Evolutionarily Stable Strategy (ESS)\n",
    "\n",
    "A strategy $\\mathbf{x}^*$ is an Evolutionarily Stable Strategy if for any mutant strategy $\\mathbf{y} \\neq \\mathbf{x}^*$:\n",
    "\n",
    "1. $(\\mathbf{x}^*)^T \\mathbf{A} \\mathbf{x}^* \\geq \\mathbf{y}^T \\mathbf{A} \\mathbf{x}^*$ (Nash equilibrium condition)\n",
    "2. If equality holds, then $(\\mathbf{x}^*)^T \\mathbf{A} \\mathbf{y} > \\mathbf{y}^T \\mathbf{A} \\mathbf{y}$ (stability condition)\n",
    "\n",
    "## Classic Games in EGT\n",
    "\n",
    "### Hawk-Dove Game\n",
    "\n",
    "The Hawk-Dove game models conflict over resources with payoff matrix:\n",
    "\n",
    "$$\\mathbf{A} = \\begin{pmatrix} \\frac{V-C}{2} & V \\\\ 0 & \\frac{V}{2} \\end{pmatrix}$$\n",
    "\n",
    "where $V$ is the resource value and $C$ is the cost of fighting.\n",
    "\n",
    "### Rock-Paper-Scissors\n",
    "\n",
    "A cyclic dominance game with payoff matrix:\n",
    "\n",
    "$$\\mathbf{A} = \\begin{pmatrix} 0 & -1 & 1 \\\\ 1 & 0 & -1 \\\\ -1 & 1 & 0 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Replicator Dynamics\n",
    "\n",
    "We implement a general solver for the replicator equation that works with any payoff matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replicator_dynamics(x, t, A):\n",
    "    \"\"\"\n",
    "    Compute the replicator dynamics dx/dt.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : array-like\n",
    "        Population state vector (strategy frequencies)\n",
    "    t : float\n",
    "        Time (unused, required for odeint)\n",
    "    A : ndarray\n",
    "        Payoff matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dxdt : ndarray\n",
    "        Rate of change of strategy frequencies\n",
    "    \"\"\"\n",
    "    # Fitness of each strategy\n",
    "    fitness = A @ x\n",
    "    \n",
    "    # Average fitness\n",
    "    avg_fitness = x @ fitness\n",
    "    \n",
    "    # Replicator equation\n",
    "    dxdt = x * (fitness - avg_fitness)\n",
    "    \n",
    "    return dxdt\n",
    "\n",
    "\n",
    "def simulate_evolution(A, x0, t_max=50, num_points=1000):\n",
    "    \"\"\"\n",
    "    Simulate evolutionary dynamics using the replicator equation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    A : ndarray\n",
    "        Payoff matrix\n",
    "    x0 : array-like\n",
    "        Initial population state\n",
    "    t_max : float\n",
    "        Maximum simulation time\n",
    "    num_points : int\n",
    "        Number of time points\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    t : ndarray\n",
    "        Time points\n",
    "    x : ndarray\n",
    "        Population states over time\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, t_max, num_points)\n",
    "    x = odeint(replicator_dynamics, x0, t, args=(A,))\n",
    "    return t, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation 1: Hawk-Dove Game\n",
    "\n",
    "We simulate the Hawk-Dove game with $V = 2$ (resource value) and $C = 3$ (cost of fighting).\n",
    "\n",
    "The ESS for this game is a mixed strategy with proportion of Hawks:\n",
    "\n",
    "$$x^*_{\\text{Hawk}} = \\frac{V}{C}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hawk-Dove payoff matrix\n",
    "V = 2  # Resource value\n",
    "C = 3  # Cost of fighting\n",
    "\n",
    "A_hawk_dove = np.array([\n",
    "    [(V - C) / 2, V],\n",
    "    [0, V / 2]\n",
    "])\n",
    "\n",
    "print(\"Hawk-Dove Payoff Matrix:\")\n",
    "print(A_hawk_dove)\n",
    "print(f\"\\nTheoretical ESS: {V/C:.3f} Hawks, {1 - V/C:.3f} Doves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate from multiple initial conditions\n",
    "initial_conditions = [\n",
    "    [0.1, 0.9],\n",
    "    [0.5, 0.5],\n",
    "    [0.9, 0.1],\n",
    "    [0.3, 0.7]\n",
    "]\n",
    "\n",
    "hawk_dove_results = []\n",
    "for x0 in initial_conditions:\n",
    "    t, x = simulate_evolution(A_hawk_dove, x0, t_max=30)\n",
    "    hawk_dove_results.append((t, x, x0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation 2: Rock-Paper-Scissors\n",
    "\n",
    "The RPS game exhibits cyclic dynamics without a stable equilibrium in pure strategies. The interior fixed point $\\mathbf{x}^* = (1/3, 1/3, 1/3)$ is neutrally stable, leading to periodic orbits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rock-Paper-Scissors payoff matrix\n",
    "A_rps = np.array([\n",
    "    [0, -1, 1],\n",
    "    [1, 0, -1],\n",
    "    [-1, 1, 0]\n",
    "])\n",
    "\n",
    "print(\"Rock-Paper-Scissors Payoff Matrix:\")\n",
    "print(A_rps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate RPS dynamics\n",
    "x0_rps = [0.6, 0.3, 0.1]\n",
    "t_rps, x_rps = simulate_evolution(A_rps, x0_rps, t_max=100, num_points=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation 3: Prisoner's Dilemma\n",
    "\n",
    "The Prisoner's Dilemma payoff matrix with $T > R > P > S$:\n",
    "\n",
    "$$\\mathbf{A} = \\begin{pmatrix} R & S \\\\ T & P \\end{pmatrix}$$\n",
    "\n",
    "where:\n",
    "- $R$ = Reward for mutual cooperation\n",
    "- $S$ = Sucker's payoff\n",
    "- $T$ = Temptation to defect\n",
    "- $P$ = Punishment for mutual defection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prisoner's Dilemma payoff matrix\n",
    "R, S, T, P = 3, 0, 5, 1\n",
    "\n",
    "A_pd = np.array([\n",
    "    [R, S],\n",
    "    [T, P]\n",
    "])\n",
    "\n",
    "print(\"Prisoner's Dilemma Payoff Matrix (Cooperate, Defect):\")\n",
    "print(A_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate PD from multiple initial conditions\n",
    "pd_initial_conditions = [\n",
    "    [0.9, 0.1],\n",
    "    [0.7, 0.3],\n",
    "    [0.5, 0.5],\n",
    "    [0.3, 0.7]\n",
    "]\n",
    "\n",
    "pd_results = []\n",
    "for x0 in pd_initial_conditions:\n",
    "    t, x = simulate_evolution(A_pd, x0, t_max=20)\n",
    "    pd_results.append((t, x, x0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We create a comprehensive visualization showing the dynamics of all three games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Hawk-Dove dynamics\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "for i, (t, x, x0) in enumerate(hawk_dove_results):\n",
    "    ax1.plot(t, x[:, 0], color=colors[i], \n",
    "             label=f'Initial Hawks = {x0[0]:.1f}', linewidth=2)\n",
    "\n",
    "ax1.axhline(y=V/C, color='black', linestyle='--', \n",
    "            label=f'ESS = {V/C:.2f}', linewidth=1.5)\n",
    "ax1.set_xlabel('Time', fontsize=11)\n",
    "ax1.set_ylabel('Proportion of Hawks', fontsize=11)\n",
    "ax1.set_title('Hawk-Dove Game: Convergence to ESS', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Plot 2: Rock-Paper-Scissors dynamics\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax2.plot(t_rps, x_rps[:, 0], 'b-', label='Rock', linewidth=2)\n",
    "ax2.plot(t_rps, x_rps[:, 1], 'r-', label='Paper', linewidth=2)\n",
    "ax2.plot(t_rps, x_rps[:, 2], 'g-', label='Scissors', linewidth=2)\n",
    "ax2.axhline(y=1/3, color='black', linestyle='--', \n",
    "            label='Equilibrium = 1/3', linewidth=1.5)\n",
    "ax2.set_xlabel('Time', fontsize=11)\n",
    "ax2.set_ylabel('Strategy Frequency', fontsize=11)\n",
    "ax2.set_title('Rock-Paper-Scissors: Cyclic Dynamics', fontsize=12, fontweight='bold')\n",
    "ax2.legend(loc='best', fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Plot 3: Prisoner's Dilemma dynamics\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "for i, (t, x, x0) in enumerate(pd_results):\n",
    "    ax3.plot(t, x[:, 0], color=colors[i], \n",
    "             label=f'Initial Coop = {x0[0]:.1f}', linewidth=2)\n",
    "\n",
    "ax3.set_xlabel('Time', fontsize=11)\n",
    "ax3.set_ylabel('Proportion of Cooperators', fontsize=11)\n",
    "ax3.set_title(\"Prisoner's Dilemma: Defection Dominates\", fontsize=12, fontweight='bold')\n",
    "ax3.legend(loc='best', fontsize=9)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(0, 1)\n",
    "\n",
    "# Plot 4: RPS Simplex trajectory\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "# Convert to 2D simplex coordinates\n",
    "def to_simplex_coords(x):\n",
    "    \"\"\"Convert 3D simplex point to 2D coordinates.\"\"\"\n",
    "    return x[:, 1] + 0.5 * x[:, 2], np.sqrt(3) / 2 * x[:, 2]\n",
    "\n",
    "# Plot simplex boundary\n",
    "triangle = plt.Polygon([[0, 0], [1, 0], [0.5, np.sqrt(3)/2]], \n",
    "                        fill=False, edgecolor='black', linewidth=2)\n",
    "ax4.add_patch(triangle)\n",
    "\n",
    "# Plot trajectory\n",
    "coords_x, coords_y = to_simplex_coords(x_rps)\n",
    "ax4.plot(coords_x, coords_y, 'b-', linewidth=0.5, alpha=0.7)\n",
    "ax4.plot(coords_x[0], coords_y[0], 'go', markersize=10, label='Start')\n",
    "ax4.plot(0.5, np.sqrt(3)/6, 'k*', markersize=15, label='Center (1/3, 1/3, 1/3)')\n",
    "\n",
    "# Label vertices\n",
    "ax4.text(-0.05, -0.05, 'Rock', fontsize=10, ha='center')\n",
    "ax4.text(1.05, -0.05, 'Paper', fontsize=10, ha='center')\n",
    "ax4.text(0.5, np.sqrt(3)/2 + 0.05, 'Scissors', fontsize=10, ha='center')\n",
    "\n",
    "ax4.set_xlim(-0.1, 1.1)\n",
    "ax4.set_ylim(-0.1, 1)\n",
    "ax4.set_aspect('equal')\n",
    "ax4.axis('off')\n",
    "ax4.set_title('RPS: Simplex Trajectory', fontsize=12, fontweight='bold')\n",
    "ax4.legend(loc='upper right', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Conclusions\n",
    "\n",
    "### Hawk-Dove Game\n",
    "The simulations demonstrate convergence to the mixed ESS $x^* = V/C$ from all initial conditions. This represents a stable polymorphism where both strategies coexist.\n",
    "\n",
    "### Rock-Paper-Scissors\n",
    "The cyclic dynamics show that no pure strategy dominates. The trajectory orbits around the center point $(1/3, 1/3, 1/3)$, which is a neutrally stable fixed point. This demonstrates that in systems with cyclic dominance, biodiversity can be maintained through frequency-dependent selection.\n",
    "\n",
    "### Prisoner's Dilemma\n",
    "Regardless of initial conditions, the population evolves toward complete defection. This illustrates the \"tragedy of the commons\" - individually rational behavior leads to collectively suboptimal outcomes.\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Frequency-dependent selection**: Strategy success depends on population composition\n",
    "2. **Convergence properties**: Different games exhibit qualitatively different long-term behaviors\n",
    "3. **ESS as attractors**: Evolutionarily stable strategies act as attractors in replicator dynamics\n",
    "4. **Social dilemmas**: The divergence between individual and collective optima remains a central challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*50)\n",
    "print(\"SIMULATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nHawk-Dove Game:\")\n",
    "print(f\"  ESS (theoretical): {V/C:.4f} Hawks\")\n",
    "print(f\"  Final state (avg): {np.mean([x[-1, 0] for _, x, _ in hawk_dove_results]):.4f} Hawks\")\n",
    "\n",
    "print(\"\\nRock-Paper-Scissors:\")\n",
    "print(f\"  Final state: R={x_rps[-1, 0]:.4f}, P={x_rps[-1, 1]:.4f}, S={x_rps[-1, 2]:.4f}\")\n",
    "print(f\"  Distance from center: {np.linalg.norm(x_rps[-1] - 1/3):.4f}\")\n",
    "\n",
    "print(\"\\nPrisoner's Dilemma:\")\n",
    "print(f\"  Final cooperation rate (avg): {np.mean([x[-1, 0] for _, x, _ in pd_results]):.6f}\")\n",
    "print(\"  Outcome: Defection dominates (as expected)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
