{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition (SVD)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Singular Value Decomposition (SVD) is one of the most fundamental and powerful matrix factorization techniques in linear algebra. It provides a way to decompose any matrix into a product of three matrices with special properties, revealing the intrinsic geometric structure of linear transformations.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### The SVD Theorem\n",
    "\n",
    "For any matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, there exists a factorization of the form:\n",
    "\n",
    "$$\\mathbf{A} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{U} \\in \\mathbb{R}^{m \\times m}$ is an orthogonal matrix (left singular vectors)\n",
    "- $\\mathbf{\\Sigma} \\in \\mathbb{R}^{m \\times n}$ is a diagonal matrix with non-negative entries (singular values)\n",
    "- $\\mathbf{V} \\in \\mathbb{R}^{n \\times n}$ is an orthogonal matrix (right singular vectors)\n",
    "\n",
    "### Properties of the Decomposition\n",
    "\n",
    "The singular values $\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_r > 0$ (where $r = \\text{rank}(\\mathbf{A})$) satisfy:\n",
    "\n",
    "$$\\sigma_i = \\sqrt{\\lambda_i(\\mathbf{A}^T\\mathbf{A})} = \\sqrt{\\lambda_i(\\mathbf{A}\\mathbf{A}^T)}$$\n",
    "\n",
    "where $\\lambda_i$ denotes the $i$-th eigenvalue.\n",
    "\n",
    "### Geometric Interpretation\n",
    "\n",
    "The SVD reveals that any linear transformation can be decomposed into three operations:\n",
    "1. **Rotation/Reflection** ($\\mathbf{V}^T$): Rotate the input space\n",
    "2. **Scaling** ($\\mathbf{\\Sigma}$): Scale along coordinate axes\n",
    "3. **Rotation/Reflection** ($\\mathbf{U}$): Rotate the output space\n",
    "\n",
    "### Low-Rank Approximation\n",
    "\n",
    "The Eckart-Young-Mirsky theorem states that the best rank-$k$ approximation to $\\mathbf{A}$ in the Frobenius norm is:\n",
    "\n",
    "$$\\mathbf{A}_k = \\sum_{i=1}^{k} \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T$$\n",
    "\n",
    "with approximation error:\n",
    "\n",
    "$$\\|\\mathbf{A} - \\mathbf{A}_k\\|_F = \\sqrt{\\sum_{i=k+1}^{r} \\sigma_i^2}$$\n",
    "\n",
    "## Applications\n",
    "\n",
    "- **Image Compression**: Storing only the largest singular values and vectors\n",
    "- **Dimensionality Reduction**: Principal Component Analysis (PCA)\n",
    "- **Noise Reduction**: Filtering out small singular values\n",
    "- **Recommender Systems**: Matrix completion problems\n",
    "- **Natural Language Processing**: Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import svd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a sample matrix for demonstration\n",
    "# We'll create a low-rank matrix with added noise\n",
    "m, n = 50, 40\n",
    "true_rank = 5\n",
    "\n",
    "# Generate a low-rank matrix\n",
    "U_true = np.random.randn(m, true_rank)\n",
    "V_true = np.random.randn(true_rank, n)\n",
    "A_clean = U_true @ V_true\n",
    "\n",
    "# Add some noise\n",
    "noise_level = 0.5\n",
    "noise = noise_level * np.random.randn(m, n)\n",
    "A = A_clean + noise\n",
    "\n",
    "print(f\"Matrix A shape: {A.shape}\")\n",
    "print(f\"Matrix A rank (numerical): {np.linalg.matrix_rank(A)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Singular Value Decomposition\n",
    "U, sigma, Vt = svd(A, full_matrices=False)\n",
    "\n",
    "print(f\"U shape: {U.shape}\")\n",
    "print(f\"Sigma shape: {sigma.shape}\")\n",
    "print(f\"V^T shape: {Vt.shape}\")\n",
    "print(f\"\\nFirst 10 singular values:\")\n",
    "print(sigma[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the decomposition: A â‰ˆ U @ diag(sigma) @ Vt\n",
    "A_reconstructed = U @ np.diag(sigma) @ Vt\n",
    "reconstruction_error = np.linalg.norm(A - A_reconstructed, 'fro')\n",
    "print(f\"Full reconstruction error (Frobenius norm): {reconstruction_error:.2e}\")\n",
    "\n",
    "# Verify orthogonality of U and V\n",
    "U_orthogonality = np.linalg.norm(U.T @ U - np.eye(U.shape[1]), 'fro')\n",
    "V_orthogonality = np.linalg.norm(Vt @ Vt.T - np.eye(Vt.shape[0]), 'fro')\n",
    "print(f\"U orthogonality error: {U_orthogonality:.2e}\")\n",
    "print(f\"V orthogonality error: {V_orthogonality:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-rank approximation\n",
    "def low_rank_approximation(U, sigma, Vt, k):\n",
    "    \"\"\"Compute rank-k approximation of matrix.\"\"\"\n",
    "    return U[:, :k] @ np.diag(sigma[:k]) @ Vt[:k, :]\n",
    "\n",
    "# Compute approximation errors for different ranks\n",
    "ranks = np.arange(1, min(m, n) + 1)\n",
    "errors = []\n",
    "cumulative_energy = []\n",
    "\n",
    "total_energy = np.sum(sigma**2)\n",
    "for k in ranks:\n",
    "    A_k = low_rank_approximation(U, sigma, Vt, k)\n",
    "    error = np.linalg.norm(A - A_k, 'fro')\n",
    "    errors.append(error)\n",
    "    energy = np.sum(sigma[:k]**2) / total_energy\n",
    "    cumulative_energy.append(energy)\n",
    "\n",
    "errors = np.array(errors)\n",
    "cumulative_energy = np.array(cumulative_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Singular value spectrum\n",
    "ax1 = axes[0, 0]\n",
    "ax1.semilogy(np.arange(1, len(sigma) + 1), sigma, 'b-o', markersize=4)\n",
    "ax1.axvline(x=true_rank, color='r', linestyle='--', label=f'True rank = {true_rank}')\n",
    "ax1.set_xlabel('Index $i$', fontsize=12)\n",
    "ax1.set_ylabel('Singular value $\\\\sigma_i$', fontsize=12)\n",
    "ax1.set_title('Singular Value Spectrum', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cumulative energy\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(ranks, cumulative_energy * 100, 'g-', linewidth=2)\n",
    "ax2.axhline(y=90, color='r', linestyle='--', label='90% energy')\n",
    "ax2.axhline(y=99, color='orange', linestyle='--', label='99% energy')\n",
    "# Find ranks that capture 90% and 99% energy\n",
    "rank_90 = np.argmax(cumulative_energy >= 0.90) + 1\n",
    "rank_99 = np.argmax(cumulative_energy >= 0.99) + 1\n",
    "ax2.axvline(x=rank_90, color='r', linestyle=':', alpha=0.5)\n",
    "ax2.axvline(x=rank_99, color='orange', linestyle=':', alpha=0.5)\n",
    "ax2.set_xlabel('Rank $k$', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative Energy (%)', fontsize=12)\n",
    "ax2.set_title('Cumulative Singular Value Energy', fontsize=14)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Approximation error vs rank\n",
    "ax3 = axes[1, 0]\n",
    "ax3.semilogy(ranks, errors, 'b-', linewidth=2)\n",
    "ax3.axvline(x=true_rank, color='r', linestyle='--', label=f'True rank = {true_rank}')\n",
    "# Theoretical error: sqrt(sum of remaining singular values squared)\n",
    "theoretical_errors = np.array([np.sqrt(np.sum(sigma[k:]**2)) for k in ranks])\n",
    "ax3.semilogy(ranks, theoretical_errors, 'g--', linewidth=1.5, alpha=0.7, label='Theoretical')\n",
    "ax3.set_xlabel('Rank $k$', fontsize=12)\n",
    "ax3.set_ylabel('$\\\\|\\\\mathbf{A} - \\\\mathbf{A}_k\\\\|_F$', fontsize=12)\n",
    "ax3.set_title('Approximation Error vs. Rank', fontsize=14)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Visual comparison of original and low-rank approximations\n",
    "ax4 = axes[1, 1]\n",
    "# Show singular values as bar chart with color coding\n",
    "colors = ['tab:blue' if i < true_rank else 'tab:gray' for i in range(len(sigma[:20]))]\n",
    "bars = ax4.bar(np.arange(1, 21), sigma[:20], color=colors, edgecolor='black', linewidth=0.5)\n",
    "ax4.set_xlabel('Index $i$', fontsize=12)\n",
    "ax4.set_ylabel('Singular value $\\\\sigma_i$', fontsize=12)\n",
    "ax4.set_title('First 20 Singular Values', fontsize=14)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add text annotations\n",
    "textstr = f'Rank for 90% energy: {rank_90}\\nRank for 99% energy: {rank_99}'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "ax4.text(0.95, 0.95, textstr, transform=ax4.transAxes, fontsize=10,\n",
    "         verticalalignment='top', horizontalalignment='right', bbox=props)\n",
    "\n",
    "plt.suptitle('Singular Value Decomposition Analysis', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate image compression using SVD\n",
    "# Create a synthetic grayscale image\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = np.linspace(-5, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Create an image with some structure (sum of Gaussians)\n",
    "image = (np.exp(-(X**2 + Y**2)/4) + \n",
    "         0.5 * np.exp(-((X-2)**2 + (Y-2)**2)/2) +\n",
    "         0.5 * np.exp(-((X+2)**2 + (Y-2)**2)/2))\n",
    "\n",
    "# Perform SVD on the image\n",
    "U_img, sigma_img, Vt_img = svd(image, full_matrices=False)\n",
    "\n",
    "# Create compressed versions\n",
    "compression_ranks = [1, 5, 10, 20]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(image, cmap='viridis')\n",
    "axes[0].set_title(f'Original\\n({image.size} values)', fontsize=10)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Compressed images\n",
    "for idx, k in enumerate(compression_ranks):\n",
    "    compressed = low_rank_approximation(U_img, sigma_img, Vt_img, k)\n",
    "    compression_ratio = (k * (image.shape[0] + image.shape[1] + 1)) / image.size\n",
    "    axes[idx + 1].imshow(compressed, cmap='viridis')\n",
    "    axes[idx + 1].set_title(f'Rank {k}\\n({compression_ratio*100:.1f}% storage)', fontsize=10)\n",
    "    axes[idx + 1].axis('off')\n",
    "\n",
    "plt.suptitle('Image Compression via SVD', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored the Singular Value Decomposition (SVD), demonstrating:\n",
    "\n",
    "1. **Mathematical properties**: Verified orthogonality of $\\mathbf{U}$ and $\\mathbf{V}$, and the reconstruction accuracy\n",
    "\n",
    "2. **Singular value spectrum**: The rapid decay of singular values reveals the effective rank of the matrix\n",
    "\n",
    "3. **Low-rank approximation**: The cumulative energy plot shows how many singular values are needed to capture most of the matrix's \"information\"\n",
    "\n",
    "4. **Practical application**: Image compression demonstrates how SVD can efficiently represent data with far fewer parameters\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- SVD is numerically stable and always exists for any matrix\n",
    "- The singular values quantify the \"importance\" of each component\n",
    "- Low-rank approximations provide optimal compression in the Frobenius norm sense\n",
    "- SVD is foundational to many machine learning and signal processing algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
