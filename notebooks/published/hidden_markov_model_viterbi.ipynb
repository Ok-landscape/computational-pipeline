{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models and the Viterbi Algorithm\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "A **Hidden Markov Model (HMM)** is a statistical model used to represent systems that transition between hidden states over time, where each state emits observable outputs with certain probabilities. HMMs are widely used in speech recognition, natural language processing, bioinformatics, and finance.\n",
    "\n",
    "The **Viterbi algorithm** is a dynamic programming algorithm for finding the most likely sequence of hidden states (the *Viterbi path*) given a sequence of observations.\n",
    "\n",
    "## 2. Mathematical Framework\n",
    "\n",
    "### 2.1 HMM Definition\n",
    "\n",
    "An HMM is defined by the tuple $\\lambda = (S, O, \\mathbf{A}, \\mathbf{B}, \\boldsymbol{\\pi})$ where:\n",
    "\n",
    "- $S = \\{s_1, s_2, \\ldots, s_N\\}$ is the set of $N$ hidden states\n",
    "- $O = \\{o_1, o_2, \\ldots, o_M\\}$ is the set of $M$ possible observations\n",
    "- $\\mathbf{A} = [a_{ij}]$ is the **transition probability matrix** where:\n",
    "  $$a_{ij} = P(q_{t+1} = s_j \\mid q_t = s_i)$$\n",
    "  represents the probability of transitioning from state $s_i$ to state $s_j$\n",
    "- $\\mathbf{B} = [b_j(k)]$ is the **emission probability matrix** where:\n",
    "  $$b_j(k) = P(x_t = o_k \\mid q_t = s_j)$$\n",
    "  represents the probability of emitting observation $o_k$ when in state $s_j$\n",
    "- $\\boldsymbol{\\pi} = [\\pi_i]$ is the **initial state distribution** where:\n",
    "  $$\\pi_i = P(q_1 = s_i)$$\n",
    "\n",
    "### 2.2 The Viterbi Algorithm\n",
    "\n",
    "Given an observation sequence $\\mathbf{X} = (x_1, x_2, \\ldots, x_T)$, the Viterbi algorithm finds:\n",
    "\n",
    "$$\\mathbf{Q}^* = \\arg\\max_{\\mathbf{Q}} P(\\mathbf{Q} \\mid \\mathbf{X}, \\lambda)$$\n",
    "\n",
    "The algorithm uses dynamic programming with two key quantities:\n",
    "\n",
    "**Viterbi variable** $\\delta_t(i)$: The probability of the most likely path ending in state $s_i$ at time $t$:\n",
    "$$\\delta_t(i) = \\max_{q_1, \\ldots, q_{t-1}} P(q_1, \\ldots, q_{t-1}, q_t = s_i, x_1, \\ldots, x_t \\mid \\lambda)$$\n",
    "\n",
    "**Backpointer** $\\psi_t(i)$: The state at time $t-1$ that maximizes the path probability:\n",
    "$$\\psi_t(i) = \\arg\\max_{1 \\leq j \\leq N} [\\delta_{t-1}(j) \\cdot a_{ji}]$$\n",
    "\n",
    "### 2.3 Algorithm Steps\n",
    "\n",
    "**Initialization** ($t = 1$):\n",
    "$$\\delta_1(i) = \\pi_i \\cdot b_i(x_1), \\quad \\psi_1(i) = 0$$\n",
    "\n",
    "**Recursion** ($t = 2, \\ldots, T$):\n",
    "$$\\delta_t(j) = \\max_{1 \\leq i \\leq N} [\\delta_{t-1}(i) \\cdot a_{ij}] \\cdot b_j(x_t)$$\n",
    "$$\\psi_t(j) = \\arg\\max_{1 \\leq i \\leq N} [\\delta_{t-1}(i) \\cdot a_{ij}]$$\n",
    "\n",
    "**Termination**:\n",
    "$$P^* = \\max_{1 \\leq i \\leq N} \\delta_T(i)$$\n",
    "$$q_T^* = \\arg\\max_{1 \\leq i \\leq N} \\delta_T(i)$$\n",
    "\n",
    "**Backtracking** ($t = T-1, \\ldots, 1$):\n",
    "$$q_t^* = \\psi_{t+1}(q_{t+1}^*)$$\n",
    "\n",
    "The time complexity is $O(N^2 T)$ and space complexity is $O(NT)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementation\n",
    "\n",
    "We will implement a Hidden Markov Model with the Viterbi algorithm and apply it to a classic example: inferring weather states (Hidden: Sunny/Rainy) from observable activities (Observed: Walk/Shop/Clean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:\n",
    "    \"\"\"\n",
    "    Hidden Markov Model implementation with Viterbi decoding.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    states : list\n",
    "        List of hidden state names\n",
    "    observations : list\n",
    "        List of possible observation names\n",
    "    A : np.ndarray\n",
    "        Transition probability matrix (N x N)\n",
    "    B : np.ndarray\n",
    "        Emission probability matrix (N x M)\n",
    "    pi : np.ndarray\n",
    "        Initial state distribution (N,)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, states: List[str], observations: List[str],\n",
    "                 A: np.ndarray, B: np.ndarray, pi: np.ndarray):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.N = len(states)  # Number of hidden states\n",
    "        self.M = len(observations)  # Number of observation symbols\n",
    "        self.A = A  # Transition matrix\n",
    "        self.B = B  # Emission matrix\n",
    "        self.pi = pi  # Initial distribution\n",
    "        \n",
    "        # Create mappings for convenience\n",
    "        self.state_to_idx = {s: i for i, s in enumerate(states)}\n",
    "        self.obs_to_idx = {o: i for i, o in enumerate(observations)}\n",
    "        \n",
    "    def viterbi(self, obs_sequence: List[str]) -> Tuple[List[str], float, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Find the most likely state sequence using the Viterbi algorithm.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        obs_sequence : list\n",
    "            Sequence of observations\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        path : list\n",
    "            Most likely state sequence\n",
    "        prob : float\n",
    "            Probability of the path\n",
    "        delta : np.ndarray\n",
    "            Viterbi trellis (for visualization)\n",
    "        \"\"\"\n",
    "        T = len(obs_sequence)\n",
    "        \n",
    "        # Convert observations to indices\n",
    "        obs_idx = [self.obs_to_idx[o] for o in obs_sequence]\n",
    "        \n",
    "        # Initialize delta and psi matrices\n",
    "        # Using log probabilities to avoid underflow\n",
    "        delta = np.zeros((T, self.N))\n",
    "        psi = np.zeros((T, self.N), dtype=int)\n",
    "        \n",
    "        # Initialization step (t=0)\n",
    "        delta[0] = np.log(self.pi + 1e-10) + np.log(self.B[:, obs_idx[0]] + 1e-10)\n",
    "        psi[0] = 0\n",
    "        \n",
    "        # Recursion step\n",
    "        for t in range(1, T):\n",
    "            for j in range(self.N):\n",
    "                # Compute probabilities of arriving at state j from all states\n",
    "                trans_probs = delta[t-1] + np.log(self.A[:, j] + 1e-10)\n",
    "                # Find the best predecessor\n",
    "                psi[t, j] = np.argmax(trans_probs)\n",
    "                delta[t, j] = trans_probs[psi[t, j]] + np.log(self.B[j, obs_idx[t]] + 1e-10)\n",
    "        \n",
    "        # Termination\n",
    "        best_path_prob = np.max(delta[T-1])\n",
    "        best_last_state = np.argmax(delta[T-1])\n",
    "        \n",
    "        # Backtracking\n",
    "        path_idx = np.zeros(T, dtype=int)\n",
    "        path_idx[T-1] = best_last_state\n",
    "        \n",
    "        for t in range(T-2, -1, -1):\n",
    "            path_idx[t] = psi[t+1, path_idx[t+1]]\n",
    "        \n",
    "        # Convert indices back to state names\n",
    "        path = [self.states[i] for i in path_idx]\n",
    "        \n",
    "        return path, np.exp(best_path_prob), delta\n",
    "    \n",
    "    def generate_sequence(self, length: int) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Generate a random sequence of states and observations.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        length : int\n",
    "            Length of sequence to generate\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        states_seq : list\n",
    "            Generated state sequence (ground truth)\n",
    "        obs_seq : list\n",
    "            Generated observation sequence\n",
    "        \"\"\"\n",
    "        states_seq = []\n",
    "        obs_seq = []\n",
    "        \n",
    "        # Initial state\n",
    "        current_state = np.random.choice(self.N, p=self.pi)\n",
    "        \n",
    "        for _ in range(length):\n",
    "            states_seq.append(self.states[current_state])\n",
    "            \n",
    "            # Emit observation\n",
    "            obs = np.random.choice(self.M, p=self.B[current_state])\n",
    "            obs_seq.append(self.observations[obs])\n",
    "            \n",
    "            # Transition to next state\n",
    "            current_state = np.random.choice(self.N, p=self.A[current_state])\n",
    "        \n",
    "        return states_seq, obs_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example: Weather Inference from Activities\n",
    "\n",
    "We model a scenario where:\n",
    "- **Hidden states**: Weather (Sunny, Rainy)\n",
    "- **Observations**: Activities (Walk, Shop, Clean)\n",
    "\n",
    "The intuition is that people tend to walk when it's sunny and clean when it's rainy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HMM parameters\n",
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['Walk', 'Shop', 'Clean']\n",
    "\n",
    "# Transition probability matrix A[i,j] = P(state_j | state_i)\n",
    "# Sunny tends to stay sunny, rainy tends to stay rainy\n",
    "A = np.array([\n",
    "    [0.7, 0.3],  # From Sunny: 70% stay sunny, 30% become rainy\n",
    "    [0.4, 0.6]   # From Rainy: 40% become sunny, 60% stay rainy\n",
    "])\n",
    "\n",
    "# Emission probability matrix B[state, observation]\n",
    "# B[i,j] = P(observation_j | state_i)\n",
    "B = np.array([\n",
    "    [0.6, 0.3, 0.1],  # Sunny: likely walk, might shop, unlikely clean\n",
    "    [0.1, 0.4, 0.5]   # Rainy: unlikely walk, might shop, likely clean\n",
    "])\n",
    "\n",
    "# Initial state distribution\n",
    "pi = np.array([0.6, 0.4])  # 60% chance of starting sunny\n",
    "\n",
    "# Create the HMM\n",
    "hmm = HiddenMarkovModel(states, observations, A, B, pi)\n",
    "\n",
    "print(\"HMM Parameters:\")\n",
    "print(f\"States: {states}\")\n",
    "print(f\"Observations: {observations}\")\n",
    "print(f\"\\nTransition Matrix A:\\n{A}\")\n",
    "print(f\"\\nEmission Matrix B:\\n{B}\")\n",
    "print(f\"\\nInitial Distribution π: {pi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sequence and decode it\n",
    "sequence_length = 20\n",
    "true_states, observed_activities = hmm.generate_sequence(sequence_length)\n",
    "\n",
    "print(\"Generated Sequence:\")\n",
    "print(f\"True weather states:    {true_states}\")\n",
    "print(f\"Observed activities:    {observed_activities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Viterbi algorithm to decode the most likely state sequence\n",
    "decoded_states, path_prob, delta = hmm.viterbi(observed_activities)\n",
    "\n",
    "print(\"Viterbi Decoding Results:\")\n",
    "print(f\"Decoded weather states: {decoded_states}\")\n",
    "print(f\"Path probability: {path_prob:.2e}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = sum(t == d for t, d in zip(true_states, decoded_states)) / len(true_states)\n",
    "print(f\"Decoding accuracy: {accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "We create a comprehensive visualization showing:\n",
    "1. The Viterbi trellis (log-probabilities over time)\n",
    "2. Comparison of true vs decoded states\n",
    "3. The HMM structure as a state diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Viterbi Trellis\n",
    "ax1 = axes[0, 0]\n",
    "im = ax1.imshow(delta.T, aspect='auto', cmap='viridis', origin='lower')\n",
    "ax1.set_xlabel('Time step', fontsize=11)\n",
    "ax1.set_ylabel('State', fontsize=11)\n",
    "ax1.set_yticks([0, 1])\n",
    "ax1.set_yticklabels(states)\n",
    "ax1.set_title('Viterbi Trellis (Log-Probabilities)', fontsize=12)\n",
    "plt.colorbar(im, ax=ax1, label='Log probability')\n",
    "\n",
    "# Overlay the optimal path\n",
    "path_indices = [hmm.state_to_idx[s] for s in decoded_states]\n",
    "ax1.plot(range(len(decoded_states)), path_indices, 'r-o', \n",
    "         markersize=6, linewidth=2, label='Viterbi path')\n",
    "ax1.legend(loc='lower left')\n",
    "\n",
    "# Plot 2: State Comparison\n",
    "ax2 = axes[0, 1]\n",
    "time_steps = np.arange(sequence_length)\n",
    "true_indices = [hmm.state_to_idx[s] for s in true_states]\n",
    "decoded_indices = [hmm.state_to_idx[s] for s in decoded_states]\n",
    "\n",
    "ax2.step(time_steps, true_indices, where='mid', label='True states', \n",
    "         linewidth=2, alpha=0.7)\n",
    "ax2.step(time_steps, decoded_indices, where='mid', label='Decoded states', \n",
    "         linewidth=2, linestyle='--', alpha=0.9)\n",
    "ax2.set_xlabel('Time step', fontsize=11)\n",
    "ax2.set_ylabel('State', fontsize=11)\n",
    "ax2.set_yticks([0, 1])\n",
    "ax2.set_yticklabels(states)\n",
    "ax2.set_title(f'True vs Decoded States (Accuracy: {accuracy:.1%})', fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.set_xlim(-0.5, sequence_length - 0.5)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Transition Matrix Heatmap\n",
    "ax3 = axes[1, 0]\n",
    "im3 = ax3.imshow(A, cmap='Blues', vmin=0, vmax=1)\n",
    "ax3.set_xlabel('To State', fontsize=11)\n",
    "ax3.set_ylabel('From State', fontsize=11)\n",
    "ax3.set_xticks([0, 1])\n",
    "ax3.set_xticklabels(states)\n",
    "ax3.set_yticks([0, 1])\n",
    "ax3.set_yticklabels(states)\n",
    "ax3.set_title('Transition Probability Matrix A', fontsize=12)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax3.text(j, i, f'{A[i,j]:.2f}', ha='center', va='center', \n",
    "                fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im3, ax=ax3, label='Probability')\n",
    "\n",
    "# Plot 4: Emission Matrix Heatmap\n",
    "ax4 = axes[1, 1]\n",
    "im4 = ax4.imshow(B, cmap='Greens', vmin=0, vmax=1)\n",
    "ax4.set_xlabel('Observation', fontsize=11)\n",
    "ax4.set_ylabel('State', fontsize=11)\n",
    "ax4.set_xticks([0, 1, 2])\n",
    "ax4.set_xticklabels(observations)\n",
    "ax4.set_yticks([0, 1])\n",
    "ax4.set_yticklabels(states)\n",
    "ax4.set_title('Emission Probability Matrix B', fontsize=12)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ax4.text(j, i, f'{B[i,j]:.2f}', ha='center', va='center', \n",
    "                fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im4, ax=ax4, label='Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Analysis\n",
    "\n",
    "Let's analyze the Viterbi algorithm's performance over multiple random sequences to understand its average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple trials\n",
    "n_trials = 100\n",
    "seq_lengths = [10, 20, 50, 100]\n",
    "results = {length: [] for length in seq_lengths}\n",
    "\n",
    "for length in seq_lengths:\n",
    "    for _ in range(n_trials):\n",
    "        true_seq, obs_seq = hmm.generate_sequence(length)\n",
    "        decoded_seq, _, _ = hmm.viterbi(obs_seq)\n",
    "        acc = sum(t == d for t, d in zip(true_seq, decoded_seq)) / length\n",
    "        results[length].append(acc)\n",
    "\n",
    "print(\"Viterbi Decoding Performance:\")\n",
    "print(\"=\"*50)\n",
    "for length in seq_lengths:\n",
    "    mean_acc = np.mean(results[length])\n",
    "    std_acc = np.std(results[length])\n",
    "    print(f\"Sequence length {length:3d}: {mean_acc:.1%} ± {std_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we explored:\n",
    "\n",
    "1. **Hidden Markov Models (HMMs)**: A powerful framework for modeling sequential data with latent states\n",
    "2. **The Viterbi Algorithm**: An efficient dynamic programming approach with $O(N^2T)$ complexity\n",
    "3. **Practical Implementation**: A complete Python implementation with log-probability handling\n",
    "4. **Performance Analysis**: Demonstrated robust decoding accuracy across different sequence lengths\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- The Viterbi algorithm finds the globally optimal state sequence, not just locally optimal decisions\n",
    "- Using log probabilities prevents numerical underflow for long sequences\n",
    "- HMMs can effectively capture temporal dependencies in sequential data\n",
    "- Decoding accuracy depends on the discriminability of emission distributions\n",
    "\n",
    "### Extensions\n",
    "\n",
    "- **Forward-Backward Algorithm**: Compute posterior probabilities $P(q_t | \\mathbf{X})$\n",
    "- **Baum-Welch Algorithm**: Learn HMM parameters from data (EM algorithm)\n",
    "- **Higher-order HMMs**: Model longer-range dependencies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
