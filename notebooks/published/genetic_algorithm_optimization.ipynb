{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm Optimization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Genetic Algorithms (GAs) are metaheuristic optimization techniques inspired by the process of natural selection. They belong to the broader class of evolutionary algorithms and are particularly effective for solving complex optimization problems where traditional gradient-based methods fail.\n",
    "\n",
    "## Theoretical Foundation\n",
    "\n",
    "### Biological Inspiration\n",
    "\n",
    "GAs mimic Darwinian evolution through the following mechanisms:\n",
    "- **Selection**: Fitter individuals have higher probability of reproduction\n",
    "- **Crossover (Recombination)**: Genetic material is exchanged between parents\n",
    "- **Mutation**: Random alterations introduce genetic diversity\n",
    "\n",
    "### Mathematical Framework\n",
    "\n",
    "Consider an optimization problem:\n",
    "\n",
    "$$\\min_{\\mathbf{x} \\in \\mathcal{S}} f(\\mathbf{x})$$\n",
    "\n",
    "where $\\mathbf{x} = (x_1, x_2, \\ldots, x_n)$ is a candidate solution in search space $\\mathcal{S}$, and $f: \\mathcal{S} \\rightarrow \\mathbb{R}$ is the objective (fitness) function.\n",
    "\n",
    "### Population Representation\n",
    "\n",
    "A population $P_t$ at generation $t$ consists of $N$ individuals:\n",
    "\n",
    "$$P_t = \\{\\mathbf{x}_1^{(t)}, \\mathbf{x}_2^{(t)}, \\ldots, \\mathbf{x}_N^{(t)}\\}$$\n",
    "\n",
    "### Selection Probability\n",
    "\n",
    "For fitness-proportionate (roulette wheel) selection, the probability of selecting individual $i$ is:\n",
    "\n",
    "$$p_i = \\frac{f_i}{\\sum_{j=1}^{N} f_j}$$\n",
    "\n",
    "For tournament selection with tournament size $k$, we select the best individual from $k$ randomly chosen candidates.\n",
    "\n",
    "### Crossover Operators\n",
    "\n",
    "**Single-point crossover** at position $c$:\n",
    "\n",
    "$$\\mathbf{x}_{\\text{child}} = (x_1^{(a)}, \\ldots, x_c^{(a)}, x_{c+1}^{(b)}, \\ldots, x_n^{(b)})$$\n",
    "\n",
    "**Arithmetic crossover** with parameter $\\alpha \\in [0, 1]$:\n",
    "\n",
    "$$\\mathbf{x}_{\\text{child}} = \\alpha \\mathbf{x}^{(a)} + (1 - \\alpha) \\mathbf{x}^{(b)}$$\n",
    "\n",
    "### Mutation\n",
    "\n",
    "For real-valued encoding, Gaussian mutation adds noise:\n",
    "\n",
    "$$x_i' = x_i + \\mathcal{N}(0, \\sigma^2)$$\n",
    "\n",
    "where $\\sigma$ is the mutation strength parameter.\n",
    "\n",
    "### Convergence\n",
    "\n",
    "The schema theorem provides theoretical grounding. A schema $H$ with order $o(H)$ and defining length $\\delta(H)$ has expected growth:\n",
    "\n",
    "$$E[m(H, t+1)] \\geq m(H, t) \\cdot \\frac{f(H)}{\\bar{f}} \\cdot \\left[1 - p_c \\frac{\\delta(H)}{L-1}\\right] \\cdot (1 - p_m)^{o(H)}$$\n",
    "\n",
    "where $m(H, t)$ is the number of instances of schema $H$ at time $t$, $f(H)$ is the average fitness of individuals matching $H$, and $\\bar{f}$ is the population average fitness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We will implement a GA to optimize the **Rastrigin function**, a classic benchmark for optimization algorithms:\n",
    "\n",
    "$$f(\\mathbf{x}) = An + \\sum_{i=1}^{n} \\left[x_i^2 - A\\cos(2\\pi x_i)\\right]$$\n",
    "\n",
    "where $A = 10$ and $x_i \\in [-5.12, 5.12]$. The global minimum is at $\\mathbf{x}^* = \\mathbf{0}$ with $f(\\mathbf{x}^*) = 0$.\n",
    "\n",
    "This function is highly multimodal with many local minima, making it challenging for gradient-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rastrigin(x):\n",
    "    \"\"\"\n",
    "    Rastrigin function - a non-convex function with many local minima.\n",
    "    Global minimum at x = 0 with f(0) = 0.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : ndarray\n",
    "        Input vector of shape (n,) or (pop_size, n)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float or ndarray\n",
    "        Function value(s)\n",
    "    \"\"\"\n",
    "    A = 10\n",
    "    x = np.atleast_2d(x)\n",
    "    n = x.shape[1]\n",
    "    return A * n + np.sum(x**2 - A * np.cos(2 * np.pi * x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "    \"\"\"\n",
    "    Genetic Algorithm for continuous optimization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fitness_func : callable\n",
    "        Objective function to minimize\n",
    "    n_dims : int\n",
    "        Number of dimensions\n",
    "    bounds : tuple\n",
    "        (lower, upper) bounds for each dimension\n",
    "    pop_size : int\n",
    "        Population size\n",
    "    n_generations : int\n",
    "        Number of generations\n",
    "    crossover_rate : float\n",
    "        Probability of crossover\n",
    "    mutation_rate : float\n",
    "        Probability of mutation\n",
    "    mutation_strength : float\n",
    "        Standard deviation for Gaussian mutation\n",
    "    tournament_size : int\n",
    "        Number of individuals in tournament selection\n",
    "    elitism : int\n",
    "        Number of best individuals to preserve\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fitness_func, n_dims, bounds, pop_size=100, \n",
    "                 n_generations=200, crossover_rate=0.8, mutation_rate=0.1,\n",
    "                 mutation_strength=0.5, tournament_size=3, elitism=2):\n",
    "        self.fitness_func = fitness_func\n",
    "        self.n_dims = n_dims\n",
    "        self.bounds = bounds\n",
    "        self.pop_size = pop_size\n",
    "        self.n_generations = n_generations\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_strength = mutation_strength\n",
    "        self.tournament_size = tournament_size\n",
    "        self.elitism = elitism\n",
    "        \n",
    "        # History tracking\n",
    "        self.best_fitness_history = []\n",
    "        self.avg_fitness_history = []\n",
    "        self.best_solution_history = []\n",
    "        \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Create initial random population within bounds.\"\"\"\n",
    "        lower, upper = self.bounds\n",
    "        return np.random.uniform(lower, upper, (self.pop_size, self.n_dims))\n",
    "    \n",
    "    def evaluate_fitness(self, population):\n",
    "        \"\"\"Evaluate fitness for entire population.\"\"\"\n",
    "        return self.fitness_func(population)\n",
    "    \n",
    "    def tournament_selection(self, population, fitness):\n",
    "        \"\"\"Select parent using tournament selection.\"\"\"\n",
    "        indices = np.random.randint(0, self.pop_size, self.tournament_size)\n",
    "        tournament_fitness = fitness[indices]\n",
    "        winner_idx = indices[np.argmin(tournament_fitness)]\n",
    "        return population[winner_idx].copy()\n",
    "    \n",
    "    def arithmetic_crossover(self, parent1, parent2):\n",
    "        \"\"\"Perform arithmetic crossover between two parents.\"\"\"\n",
    "        if np.random.random() < self.crossover_rate:\n",
    "            alpha = np.random.random()\n",
    "            child1 = alpha * parent1 + (1 - alpha) * parent2\n",
    "            child2 = (1 - alpha) * parent1 + alpha * parent2\n",
    "            return child1, child2\n",
    "        return parent1.copy(), parent2.copy()\n",
    "    \n",
    "    def gaussian_mutation(self, individual):\n",
    "        \"\"\"Apply Gaussian mutation to an individual.\"\"\"\n",
    "        for i in range(self.n_dims):\n",
    "            if np.random.random() < self.mutation_rate:\n",
    "                individual[i] += np.random.normal(0, self.mutation_strength)\n",
    "                # Enforce bounds\n",
    "                individual[i] = np.clip(individual[i], self.bounds[0], self.bounds[1])\n",
    "        return individual\n",
    "    \n",
    "    def evolve(self):\n",
    "        \"\"\"Run the genetic algorithm.\"\"\"\n",
    "        # Initialize population\n",
    "        population = self.initialize_population()\n",
    "        fitness = self.evaluate_fitness(population)\n",
    "        \n",
    "        for generation in range(self.n_generations):\n",
    "            # Sort population by fitness (ascending for minimization)\n",
    "            sorted_indices = np.argsort(fitness)\n",
    "            population = population[sorted_indices]\n",
    "            fitness = fitness[sorted_indices]\n",
    "            \n",
    "            # Record history\n",
    "            self.best_fitness_history.append(fitness[0])\n",
    "            self.avg_fitness_history.append(np.mean(fitness))\n",
    "            self.best_solution_history.append(population[0].copy())\n",
    "            \n",
    "            # Create new population\n",
    "            new_population = []\n",
    "            \n",
    "            # Elitism: preserve best individuals\n",
    "            for i in range(self.elitism):\n",
    "                new_population.append(population[i].copy())\n",
    "            \n",
    "            # Generate offspring\n",
    "            while len(new_population) < self.pop_size:\n",
    "                # Selection\n",
    "                parent1 = self.tournament_selection(population, fitness)\n",
    "                parent2 = self.tournament_selection(population, fitness)\n",
    "                \n",
    "                # Crossover\n",
    "                child1, child2 = self.arithmetic_crossover(parent1, parent2)\n",
    "                \n",
    "                # Mutation\n",
    "                child1 = self.gaussian_mutation(child1)\n",
    "                child2 = self.gaussian_mutation(child2)\n",
    "                \n",
    "                new_population.append(child1)\n",
    "                if len(new_population) < self.pop_size:\n",
    "                    new_population.append(child2)\n",
    "            \n",
    "            population = np.array(new_population)\n",
    "            fitness = self.evaluate_fitness(population)\n",
    "        \n",
    "        # Final evaluation\n",
    "        best_idx = np.argmin(fitness)\n",
    "        return population[best_idx], fitness[best_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Optimization\n",
    "\n",
    "We optimize the 2D Rastrigin function to visualize the search process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and run the genetic algorithm\n",
    "ga = GeneticAlgorithm(\n",
    "    fitness_func=rastrigin,\n",
    "    n_dims=2,\n",
    "    bounds=(-5.12, 5.12),\n",
    "    pop_size=100,\n",
    "    n_generations=150,\n",
    "    crossover_rate=0.85,\n",
    "    mutation_rate=0.15,\n",
    "    mutation_strength=0.3,\n",
    "    tournament_size=3,\n",
    "    elitism=2\n",
    ")\n",
    "\n",
    "best_solution, best_fitness = ga.evolve()\n",
    "\n",
    "print(\"Optimization Results\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Best solution found: x = [{best_solution[0]:.6f}, {best_solution[1]:.6f}]\")\n",
    "print(f\"Best fitness value: f(x) = {best_fitness:.6f}\")\n",
    "print(f\"True optimum: x* = [0, 0], f(x*) = 0\")\n",
    "print(f\"Distance from optimum: {np.linalg.norm(best_solution):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We create a comprehensive visualization showing:\n",
    "1. The Rastrigin function landscape\n",
    "2. Convergence history\n",
    "3. Search trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot 1: 3D surface of Rastrigin function\n",
    "ax1 = fig.add_subplot(221, projection='3d')\n",
    "x = np.linspace(-5.12, 5.12, 100)\n",
    "y = np.linspace(-5.12, 5.12, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = 20 + X**2 - 10*np.cos(2*np.pi*X) + Y**2 - 10*np.cos(2*np.pi*Y)\n",
    "\n",
    "surf = ax1.plot_surface(X, Y, Z, cmap=cm.viridis, alpha=0.8, \n",
    "                        linewidth=0, antialiased=True)\n",
    "ax1.set_xlabel('$x_1$')\n",
    "ax1.set_ylabel('$x_2$')\n",
    "ax1.set_zlabel('$f(x)$')\n",
    "ax1.set_title('Rastrigin Function Landscape')\n",
    "ax1.view_init(elev=30, azim=45)\n",
    "\n",
    "# Plot 2: Contour plot with search trajectory\n",
    "ax2 = fig.add_subplot(222)\n",
    "contour = ax2.contourf(X, Y, Z, levels=50, cmap=cm.viridis)\n",
    "plt.colorbar(contour, ax=ax2, label='$f(x)$')\n",
    "\n",
    "# Plot trajectory of best solution\n",
    "trajectory = np.array(ga.best_solution_history)\n",
    "ax2.plot(trajectory[:, 0], trajectory[:, 1], 'r.-', markersize=3, \n",
    "         linewidth=0.8, alpha=0.7, label='Search trajectory')\n",
    "ax2.plot(trajectory[0, 0], trajectory[0, 1], 'go', markersize=8, label='Start')\n",
    "ax2.plot(trajectory[-1, 0], trajectory[-1, 1], 'r*', markersize=12, label='Final')\n",
    "ax2.plot(0, 0, 'w+', markersize=10, markeredgewidth=2, label='Global optimum')\n",
    "\n",
    "ax2.set_xlabel('$x_1$')\n",
    "ax2.set_ylabel('$x_2$')\n",
    "ax2.set_title('Search Trajectory on Rastrigin Function')\n",
    "ax2.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "# Plot 3: Convergence history\n",
    "ax3 = fig.add_subplot(223)\n",
    "generations = np.arange(len(ga.best_fitness_history))\n",
    "ax3.semilogy(generations, ga.best_fitness_history, 'b-', linewidth=2, label='Best fitness')\n",
    "ax3.semilogy(generations, ga.avg_fitness_history, 'r--', linewidth=1.5, \n",
    "             alpha=0.7, label='Average fitness')\n",
    "ax3.set_xlabel('Generation')\n",
    "ax3.set_ylabel('Fitness (log scale)')\n",
    "ax3.set_title('Convergence History')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Distance from optimum over generations\n",
    "ax4 = fig.add_subplot(224)\n",
    "distances = [np.linalg.norm(sol) for sol in ga.best_solution_history]\n",
    "ax4.plot(generations, distances, 'g-', linewidth=2)\n",
    "ax4.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "ax4.set_xlabel('Generation')\n",
    "ax4.set_ylabel('Distance from optimum $||\\mathbf{x}||$')\n",
    "ax4.set_title('Solution Quality Over Generations')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Discussion\n",
    "\n",
    "### Observations\n",
    "\n",
    "1. **Convergence Behavior**: The algorithm shows rapid initial improvement followed by gradual refinement. The semi-log plot reveals exponential-like convergence in early generations.\n",
    "\n",
    "2. **Population Diversity**: The gap between best and average fitness indicates population diversity. A shrinking gap suggests convergence, while maintaining some gap prevents premature convergence.\n",
    "\n",
    "3. **Local Optima**: The Rastrigin function has $\\approx 10^n$ local minima. Despite this, the GA successfully navigates toward the global optimum through its stochastic search mechanisms.\n",
    "\n",
    "### Parameter Sensitivity\n",
    "\n",
    "- **Mutation rate**: Higher values maintain diversity but slow convergence; lower values risk premature convergence\n",
    "- **Crossover rate**: Balances exploration (low) vs exploitation (high)\n",
    "- **Tournament size**: Larger sizes increase selection pressure\n",
    "- **Elitism**: Preserves good solutions but may reduce diversity\n",
    "\n",
    "### Computational Complexity\n",
    "\n",
    "Per generation: $O(N \\cdot n \\cdot k)$ where $N$ is population size, $n$ is dimensionality, and $k$ is tournament size.\n",
    "\n",
    "Total: $O(G \\cdot N \\cdot n \\cdot k)$ for $G$ generations.\n",
    "\n",
    "### Extensions\n",
    "\n",
    "- **Adaptive parameters**: Adjust mutation/crossover rates during evolution\n",
    "- **Island models**: Parallel subpopulations with migration\n",
    "- **Hybrid approaches**: Combine with local search (memetic algorithms)\n",
    "- **Constraint handling**: Penalty functions or specialized operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the implementation of a Genetic Algorithm for continuous optimization. Key takeaways:\n",
    "\n",
    "1. GAs are effective for multimodal optimization problems where gradient methods fail\n",
    "2. The balance between exploration and exploitation is crucial\n",
    "3. Parameter tuning significantly affects performance\n",
    "4. The stochastic nature provides robustness to local optima\n",
    "\n",
    "The algorithm successfully optimized the challenging Rastrigin function, finding solutions very close to the global optimum despite the presence of numerous local minima."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
