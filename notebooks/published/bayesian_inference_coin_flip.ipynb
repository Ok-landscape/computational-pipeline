{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference for Coin Flip Experiments\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Bayesian inference provides a principled framework for updating our beliefs about unknown parameters as we observe data. In this notebook, we explore the canonical example of Bayesian statistics: inferring the bias of a coin from observed flips.\n",
    "\n",
    "## Theoretical Foundation\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Consider a coin with unknown probability $\\theta$ of landing heads. We flip the coin $n$ times and observe $k$ heads. Our goal is to infer the posterior distribution of $\\theta$ given this data.\n",
    "\n",
    "### Bayes' Theorem\n",
    "\n",
    "Bayes' theorem relates the posterior probability to the prior and likelihood:\n",
    "\n",
    "$$P(\\theta | D) = \\frac{P(D | \\theta) P(\\theta)}{P(D)}$$\n",
    "\n",
    "where:\n",
    "- $P(\\theta | D)$ is the **posterior**: our updated belief about $\\theta$ after observing data $D$\n",
    "- $P(D | \\theta)$ is the **likelihood**: the probability of observing data $D$ given $\\theta$\n",
    "- $P(\\theta)$ is the **prior**: our initial belief about $\\theta$\n",
    "- $P(D)$ is the **evidence**: a normalizing constant\n",
    "\n",
    "### Likelihood Function\n",
    "\n",
    "For $n$ coin flips with $k$ heads, the likelihood follows a binomial distribution:\n",
    "\n",
    "$$P(D | \\theta) = \\binom{n}{k} \\theta^k (1-\\theta)^{n-k}$$\n",
    "\n",
    "### Prior Distribution\n",
    "\n",
    "We use a Beta distribution as our prior, which is conjugate to the binomial likelihood:\n",
    "\n",
    "$$P(\\theta) = \\text{Beta}(\\theta | \\alpha, \\beta) = \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}$$\n",
    "\n",
    "where $B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$ is the Beta function.\n",
    "\n",
    "### Posterior Distribution\n",
    "\n",
    "Due to conjugacy, the posterior is also a Beta distribution:\n",
    "\n",
    "$$P(\\theta | D) = \\text{Beta}(\\theta | \\alpha + k, \\beta + n - k)$$\n",
    "\n",
    "This elegant result shows that we simply update the Beta parameters by adding the number of successes to $\\alpha$ and the number of failures to $\\beta$.\n",
    "\n",
    "### Posterior Statistics\n",
    "\n",
    "The posterior mean and variance are:\n",
    "\n",
    "$$\\mathbb{E}[\\theta | D] = \\frac{\\alpha + k}{\\alpha + \\beta + n}$$\n",
    "\n",
    "$$\\text{Var}[\\theta | D] = \\frac{(\\alpha + k)(\\beta + n - k)}{(\\alpha + \\beta + n)^2(\\alpha + \\beta + n + 1)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plot style\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "### Define Bayesian Update Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_update(prior_alpha, prior_beta, n_heads, n_tails):\n",
    "    \"\"\"\n",
    "    Perform Bayesian update for coin flip experiment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prior_alpha : float\n",
    "        Alpha parameter of Beta prior\n",
    "    prior_beta : float\n",
    "        Beta parameter of Beta prior\n",
    "    n_heads : int\n",
    "        Number of observed heads\n",
    "    n_tails : int\n",
    "        Number of observed tails\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    posterior_alpha : float\n",
    "        Alpha parameter of Beta posterior\n",
    "    posterior_beta : float\n",
    "        Beta parameter of Beta posterior\n",
    "    \"\"\"\n",
    "    posterior_alpha = prior_alpha + n_heads\n",
    "    posterior_beta = prior_beta + n_tails\n",
    "    return posterior_alpha, posterior_beta\n",
    "\n",
    "\n",
    "def compute_posterior_stats(alpha, beta):\n",
    "    \"\"\"\n",
    "    Compute mean, variance, and credible interval for Beta distribution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float\n",
    "        Alpha parameter of Beta distribution\n",
    "    beta : float\n",
    "        Beta parameter of Beta distribution\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing mean, variance, and 95% credible interval\n",
    "    \"\"\"\n",
    "    dist = stats.beta(alpha, beta)\n",
    "    return {\n",
    "        'mean': dist.mean(),\n",
    "        'variance': dist.var(),\n",
    "        'std': dist.std(),\n",
    "        'ci_95': dist.ppf([0.025, 0.975])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Simulated Data\n",
    "\n",
    "We simulate coin flips from a coin with true bias $\\theta_{\\text{true}} = 0.7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True probability of heads (unknown to the inference procedure)\n",
    "theta_true = 0.7\n",
    "\n",
    "# Total number of flips\n",
    "n_flips = 100\n",
    "\n",
    "# Simulate coin flips\n",
    "flips = np.random.binomial(1, theta_true, n_flips)\n",
    "cumulative_heads = np.cumsum(flips)\n",
    "cumulative_tails = np.arange(1, n_flips + 1) - cumulative_heads\n",
    "\n",
    "print(f\"True bias: θ = {theta_true}\")\n",
    "print(f\"Total flips: {n_flips}\")\n",
    "print(f\"Observed heads: {cumulative_heads[-1]}\")\n",
    "print(f\"Observed tails: {cumulative_tails[-1]}\")\n",
    "print(f\"Observed proportion: {cumulative_heads[-1]/n_flips:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Bayesian Updates\n",
    "\n",
    "We now perform sequential Bayesian updates, starting from different priors, to visualize how the posterior evolves as we observe more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different priors to compare\n",
    "priors = {\n",
    "    'Uniform (α=1, β=1)': (1, 1),\n",
    "    'Skeptical of bias (α=5, β=5)': (5, 5),\n",
    "    'Strong prior at 0.5 (α=20, β=20)': (20, 20),\n",
    "    'Prior favoring heads (α=3, β=1)': (3, 1)\n",
    "}\n",
    "\n",
    "# Points at which to evaluate posterior\n",
    "theta_range = np.linspace(0, 1, 1000)\n",
    "\n",
    "# Observation points for visualization\n",
    "observation_points = [0, 1, 5, 10, 25, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Posterior Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.9, len(observation_points)))\n",
    "\n",
    "for idx, (prior_name, (alpha_0, beta_0)) in enumerate(priors.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for i, n_obs in enumerate(observation_points):\n",
    "        if n_obs == 0:\n",
    "            alpha_n, beta_n = alpha_0, beta_0\n",
    "            label = f'Prior (n=0)'\n",
    "        else:\n",
    "            n_heads = cumulative_heads[n_obs - 1]\n",
    "            n_tails = cumulative_tails[n_obs - 1]\n",
    "            alpha_n, beta_n = bayesian_update(alpha_0, beta_0, n_heads, n_tails)\n",
    "            label = f'n={n_obs}'\n",
    "        \n",
    "        posterior = stats.beta(alpha_n, beta_n)\n",
    "        pdf = posterior.pdf(theta_range)\n",
    "        \n",
    "        ax.plot(theta_range, pdf, color=colors[i], \n",
    "                linewidth=2 if n_obs in [0, 100] else 1.5,\n",
    "                alpha=0.9 if n_obs in [0, 100] else 0.7,\n",
    "                label=label)\n",
    "    \n",
    "    ax.axvline(theta_true, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'True θ={theta_true}')\n",
    "    ax.set_xlabel(r'$\\theta$')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(prior_name)\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Evolution of Posterior Distribution with Different Priors', \n",
    "             fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative Analysis of Final Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Posterior Statistics after 100 observations\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "total_heads = cumulative_heads[-1]\n",
    "total_tails = cumulative_tails[-1]\n",
    "\n",
    "for prior_name, (alpha_0, beta_0) in priors.items():\n",
    "    alpha_n, beta_n = bayesian_update(alpha_0, beta_0, total_heads, total_tails)\n",
    "    stats_dict = compute_posterior_stats(alpha_n, beta_n)\n",
    "    \n",
    "    print(f\"\\n{prior_name}\")\n",
    "    print(f\"  Posterior parameters: α={alpha_n}, β={beta_n}\")\n",
    "    print(f\"  Posterior mean: {stats_dict['mean']:.4f}\")\n",
    "    print(f\"  Posterior std: {stats_dict['std']:.4f}\")\n",
    "    print(f\"  95% Credible Interval: [{stats_dict['ci_95'][0]:.4f}, {stats_dict['ci_95'][1]:.4f}]\")\n",
    "    print(f\"  Contains true θ={theta_true}: {stats_dict['ci_95'][0] <= theta_true <= stats_dict['ci_95'][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Sensitivity Analysis\n",
    "\n",
    "Let's examine how the posterior mean converges to the true value as we collect more data, demonstrating that with sufficient data, the influence of the prior diminishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Posterior mean evolution\n",
    "n_observations = np.arange(1, n_flips + 1)\n",
    "\n",
    "for prior_name, (alpha_0, beta_0) in priors.items():\n",
    "    posterior_means = []\n",
    "    for n in n_observations:\n",
    "        alpha_n = alpha_0 + cumulative_heads[n-1]\n",
    "        beta_n = beta_0 + cumulative_tails[n-1]\n",
    "        posterior_means.append(alpha_n / (alpha_n + beta_n))\n",
    "    \n",
    "    ax1.plot(n_observations, posterior_means, linewidth=2, label=prior_name)\n",
    "\n",
    "ax1.axhline(theta_true, color='red', linestyle='--', linewidth=2, label=f'True θ={theta_true}')\n",
    "ax1.set_xlabel('Number of observations')\n",
    "ax1.set_ylabel('Posterior mean')\n",
    "ax1.set_title('Convergence of Posterior Mean')\n",
    "ax1.legend(loc='lower right', fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Posterior standard deviation evolution\n",
    "for prior_name, (alpha_0, beta_0) in priors.items():\n",
    "    posterior_stds = []\n",
    "    for n in n_observations:\n",
    "        alpha_n = alpha_0 + cumulative_heads[n-1]\n",
    "        beta_n = beta_0 + cumulative_tails[n-1]\n",
    "        var = (alpha_n * beta_n) / ((alpha_n + beta_n)**2 * (alpha_n + beta_n + 1))\n",
    "        posterior_stds.append(np.sqrt(var))\n",
    "    \n",
    "    ax2.plot(n_observations, posterior_stds, linewidth=2, label=prior_name)\n",
    "\n",
    "ax2.set_xlabel('Number of observations')\n",
    "ax2.set_ylabel('Posterior standard deviation')\n",
    "ax2.set_title('Reduction in Posterior Uncertainty')\n",
    "ax2.legend(loc='upper right', fontsize=8)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated Bayesian inference for estimating the bias of a coin:\n",
    "\n",
    "1. **Conjugate Prior**: The Beta-Binomial conjugacy provides closed-form posterior updates\n",
    "2. **Prior Influence**: Different priors lead to different posteriors with limited data, but converge as data accumulates\n",
    "3. **Uncertainty Quantification**: The posterior provides not just point estimates but full uncertainty quantification via credible intervals\n",
    "4. **Sequential Learning**: Bayesian inference naturally accommodates sequential data through iterative updates\n",
    "\n",
    "The key insight is that Bayesian inference provides a principled way to combine prior knowledge with observed data, with the data eventually overwhelming the prior as more observations are collected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
