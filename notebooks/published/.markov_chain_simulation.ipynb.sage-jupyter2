{"backend_state":"running","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-3b65e338-63f7-4e42-83ca-1b0c4c9d7f19.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_backend_state":1763839855625,"last_ipynb_save":1763839892667,"metadata":{"language_info":{"name":"python","version":"3.9"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1763839857254,"exec_count":3,"id":"f13819","input":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import linalg\n\n# Set random seed for reproducibility\nnp.random.seed(42)","kernel":"python3","pos":1,"start":1763839855654,"state":"done","type":"cell"}
{"cell_type":"code","end":1763839857280,"exec_count":4,"id":"0f4f0c","input":"# Define states\nstates = ['Sunny', 'Cloudy', 'Rainy']\nn_states = len(states)\n\n# Define transition matrix\n# P[i,j] = probability of transitioning from state i to state j\nP = np.array([\n    [0.7, 0.2, 0.1],  # From Sunny\n    [0.3, 0.4, 0.3],  # From Cloudy\n    [0.2, 0.3, 0.5]   # From Rainy\n])\n\n# Verify it's a valid stochastic matrix\nprint(\"Transition Matrix P:\")\nprint(P)\nprint(f\"\\nRow sums: {P.sum(axis=1)}\")\nprint(\"All rows sum to 1:\", np.allclose(P.sum(axis=1), 1))","kernel":"python3","output":{"0":{"name":"stdout","text":"Transition Matrix P:\n[[0.7 0.2 0.1]\n [0.3 0.4 0.3]\n [0.2 0.3 0.5]]\n\nRow sums: [1. 1. 1.]\nAll rows sum to 1: True\n"}},"pos":3,"start":1763839857263,"state":"done","type":"cell"}
{"cell_type":"code","end":1763839857315,"exec_count":5,"id":"7a08cd","input":"def simulate_markov_chain(P, initial_state, n_steps):\n    \"\"\"\n    Simulate a Markov chain.\n    \n    Parameters:\n    -----------\n    P : ndarray\n        Transition matrix (n_states x n_states)\n    initial_state : int\n        Starting state index\n    n_steps : int\n        Number of steps to simulate\n        \n    Returns:\n    --------\n    states_history : list\n        Sequence of visited states\n    \"\"\"\n    n_states = P.shape[0]\n    current_state = initial_state\n    states_history = [current_state]\n    \n    for _ in range(n_steps):\n        # Sample next state from transition probabilities\n        next_state = np.random.choice(n_states, p=P[current_state])\n        states_history.append(next_state)\n        current_state = next_state\n    \n    return states_history\n\n# Simulate the chain\nn_steps = 1000\ninitial_state = 0  # Start with Sunny\ntrajectory = simulate_markov_chain(P, initial_state, n_steps)\n\nprint(f\"First 20 states: {[states[s] for s in trajectory[:20]]}\")","kernel":"python3","output":{"0":{"name":"stdout","text":"First 20 states: ['Sunny', 'Sunny', 'Rainy', 'Rainy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Cloudy', 'Rainy', 'Sunny', 'Rainy', 'Rainy', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny']\n"}},"pos":5,"start":1763839857290,"state":"done","type":"cell"}
{"cell_type":"code","end":1763839857471,"exec_count":6,"id":"794745","input":"def compute_stationary_distribution(P):\n    \"\"\"\n    Compute the stationary distribution of a Markov chain.\n    \n    Parameters:\n    -----------\n    P : ndarray\n        Transition matrix\n        \n    Returns:\n    --------\n    pi : ndarray\n        Stationary distribution\n    \"\"\"\n    n = P.shape[0]\n    \n    # Solve (P^T - I) * pi = 0 with constraint sum(pi) = 1\n    # Augment the system with the normalization constraint\n    A = np.vstack([P.T - np.eye(n), np.ones(n)])\n    b = np.zeros(n + 1)\n    b[-1] = 1\n    \n    # Solve using least squares\n    pi, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n    \n    return pi\n\n# Compute analytical stationary distribution\npi_analytical = compute_stationary_distribution(P)\nprint(\"Analytical Stationary Distribution:\")\nfor i, state in enumerate(states):\n    print(f\"  {state}: {pi_analytical[i]:.4f}\")","kernel":"python3","output":{"0":{"name":"stdout","text":"Analytical Stationary Distribution:\n  Sunny: 0.4565\n  Cloudy: 0.2826\n  Rainy: 0.2609\n"}},"pos":7,"start":1763839857467,"state":"done","type":"cell"}
{"cell_type":"code","end":1763839857491,"exec_count":7,"id":"8c901e","input":"# Compute empirical distribution from simulation\ntrajectory_array = np.array(trajectory)\npi_empirical = np.array([np.sum(trajectory_array == i) for i in range(n_states)]) / len(trajectory)\n\nprint(\"Empirical Stationary Distribution (from simulation):\")\nfor i, state in enumerate(states):\n    print(f\"  {state}: {pi_empirical[i]:.4f}\")\n\nprint(f\"\\nMaximum absolute error: {np.max(np.abs(pi_analytical - pi_empirical)):.4f}\")","kernel":"python3","output":{"0":{"name":"stdout","text":"Empirical Stationary Distribution (from simulation):\n  Sunny: 0.4715\n  Cloudy: 0.2597\n  Rainy: 0.2687\n\nMaximum absolute error: 0.0229\n"}},"pos":9,"start":1763839857481,"state":"done","type":"cell"}
{"cell_type":"code","end":1763839857509,"exec_count":8,"id":"4504c1","input":"def compute_distribution_over_time(P, initial_dist, n_steps):\n    \"\"\"\n    Compute the probability distribution at each time step.\n    \n    Parameters:\n    -----------\n    P : ndarray\n        Transition matrix\n    initial_dist : ndarray\n        Initial probability distribution\n    n_steps : int\n        Number of steps\n        \n    Returns:\n    --------\n    distributions : ndarray\n        Distribution at each time step (n_steps+1 x n_states)\n    \"\"\"\n    distributions = [initial_dist]\n    current_dist = initial_dist.copy()\n    \n    for _ in range(n_steps):\n        current_dist = current_dist @ P\n        distributions.append(current_dist.copy())\n    \n    return np.array(distributions)\n\n# Start from different initial distributions\ninitial_distributions = [\n    np.array([1.0, 0.0, 0.0]),  # Start in Sunny\n    np.array([0.0, 1.0, 0.0]),  # Start in Cloudy\n    np.array([0.0, 0.0, 1.0])   # Start in Rainy\n]\n\nn_convergence_steps = 50\nconvergence_results = []\n\nfor init_dist in initial_distributions:\n    result = compute_distribution_over_time(P, init_dist, n_convergence_steps)\n    convergence_results.append(result)","kernel":"python3","pos":11,"start":1763839857501,"state":"done","type":"cell"}
{"cell_type":"code","end":1763839859672,"exec_count":9,"id":"b0bc41","input":"fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# Plot 1: Transition Matrix Heatmap\nax1 = axes[0, 0]\nim = ax1.imshow(P, cmap='Blues', vmin=0, vmax=1)\nax1.set_xticks(range(n_states))\nax1.set_yticks(range(n_states))\nax1.set_xticklabels(states)\nax1.set_yticklabels(states)\nax1.set_xlabel('To State', fontsize=12)\nax1.set_ylabel('From State', fontsize=12)\nax1.set_title('Transition Matrix', fontsize=14, fontweight='bold')\n\n# Add text annotations\nfor i in range(n_states):\n    for j in range(n_states):\n        text = ax1.text(j, i, f'{P[i, j]:.2f}',\n                       ha='center', va='center', fontsize=12,\n                       color='white' if P[i, j] > 0.5 else 'black')\n\nplt.colorbar(im, ax=ax1, label='Probability')\n\n# Plot 2: Sample Trajectory\nax2 = axes[0, 1]\nplot_steps = 100\nax2.step(range(plot_steps + 1), trajectory[:plot_steps + 1], where='mid', \n         linewidth=1.5, color='#2E86AB')\nax2.set_yticks(range(n_states))\nax2.set_yticklabels(states)\nax2.set_xlabel('Time Step', fontsize=12)\nax2.set_ylabel('State', fontsize=12)\nax2.set_title('Sample Markov Chain Trajectory', fontsize=14, fontweight='bold')\nax2.set_xlim(0, plot_steps)\nax2.grid(True, alpha=0.3)\n\n# Plot 3: Convergence to Stationary Distribution\nax3 = axes[1, 0]\ncolors = ['#E74C3C', '#F39C12', '#3498DB']\nlinestyles = ['-', '--', ':']\n\nfor idx, (result, init_name) in enumerate(zip(convergence_results, states)):\n    for state_idx in range(n_states):\n        if idx == 0:  # Only label once\n            label = states[state_idx]\n        else:\n            label = None\n        ax3.plot(result[:, state_idx], \n                color=colors[state_idx], \n                linestyle=linestyles[idx],\n                linewidth=1.5,\n                label=label,\n                alpha=0.8)\n\n# Add horizontal lines for stationary distribution\nfor state_idx in range(n_states):\n    ax3.axhline(y=pi_analytical[state_idx], color=colors[state_idx], \n               linestyle='-.', alpha=0.5, linewidth=2)\n\nax3.set_xlabel('Time Step', fontsize=12)\nax3.set_ylabel('Probability', fontsize=12)\nax3.set_title('Convergence to Stationary Distribution', fontsize=14, fontweight='bold')\nax3.legend(loc='upper right')\nax3.set_xlim(0, n_convergence_steps)\nax3.set_ylim(0, 1)\nax3.grid(True, alpha=0.3)\n\n# Plot 4: Comparison of Analytical vs Empirical Distribution\nax4 = axes[1, 1]\nx = np.arange(n_states)\nwidth = 0.35\n\nbars1 = ax4.bar(x - width/2, pi_analytical, width, label='Analytical', \n               color='#3498DB', alpha=0.8, edgecolor='black')\nbars2 = ax4.bar(x + width/2, pi_empirical, width, label='Empirical', \n               color='#E74C3C', alpha=0.8, edgecolor='black')\n\nax4.set_xlabel('State', fontsize=12)\nax4.set_ylabel('Probability', fontsize=12)\nax4.set_title('Stationary Distribution: Analytical vs Empirical', \n             fontsize=14, fontweight='bold')\nax4.set_xticks(x)\nax4.set_xticklabels(states)\nax4.legend()\nax4.set_ylim(0, 0.6)\nax4.grid(True, alpha=0.3, axis='y')\n\n# Add value labels on bars\nfor bar, val in zip(bars1, pi_analytical):\n    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\nfor bar, val in zip(bars2, pi_empirical):\n    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n\nplt.tight_layout()\nplt.savefig('plot.png', dpi=150, bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(\"\\nPlot saved to 'plot.png'\")","kernel":"python3","output":{"0":{"data":{"image/png":"071b5bb5ed18cb1799b2f08d8112533ffd6f0b35","text/plain":"<Figure size 1400x1200 with 5 Axes>"},"metadata":{"image/png":{"height":1188,"width":1388}}},"1":{"name":"stdout","text":"\nPlot saved to 'plot.png'\n"}},"pos":13,"start":1763839857549,"state":"done","type":"cell"}
{"cell_type":"code","end":1763839859685,"exec_count":10,"id":"b7e20f","input":"# Verify stationarity condition\npi_P = pi_analytical @ P\nprint(\"Verification of πP = π:\")\nprint(f\"π:    {pi_analytical}\")\nprint(f\"πP:   {pi_P}\")\nprint(f\"Equal: {np.allclose(pi_analytical, pi_P)}\")","kernel":"python3","output":{"0":{"name":"stdout","text":"Verification of πP = π:\nπ:    [0.45652174 0.2826087  0.26086957]\nπP:   [0.45652174 0.2826087  0.26086957]\nEqual: True\n"}},"pos":15,"start":1763839859681,"state":"done","type":"cell"}
{"cell_type":"code","end":1763839859698,"exec_count":11,"id":"d7536b","input":"# Compute P^n for large n\nP_100 = np.linalg.matrix_power(P, 100)\n\nprint(\"P^100 (should have identical rows equal to π):\")\nprint(P_100)\nprint(f\"\\nStationary distribution π: {pi_analytical}\")\nprint(f\"\\nAll rows equal to π: {np.allclose(P_100, pi_analytical)}\")","kernel":"python3","output":{"0":{"name":"stdout","text":"P^100 (should have identical rows equal to π):\n[[0.45652174 0.2826087  0.26086957]\n [0.45652174 0.2826087  0.26086957]\n [0.45652174 0.2826087  0.26086957]]\n\nStationary distribution π: [0.45652174 0.2826087  0.26086957]\n\nAll rows equal to π: True\n"}},"pos":17,"start":1763839859693,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1856ea","input":"## Theoretical Verification\n\n### Verifying Stationarity\n\nWe verify that $\\boldsymbol{\\pi} \\mathbf{P} = \\boldsymbol{\\pi}$:","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"2c55ba","input":"## Markov Chain Simulation\n\nWe now implement a function to simulate the Markov chain and visualize its behavior.","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"3c23f9","input":"## Conclusion\n\nThis notebook demonstrated the fundamental concepts of Markov chains:\n\n1. **Transition matrices** encode the probabilistic dynamics of the system\n2. **Simulations** can be performed by sampling from transition probabilities\n3. **Stationary distributions** can be computed analytically as eigenvectors or estimated empirically\n4. **Convergence** to the stationary distribution occurs regardless of initial conditions for irreducible, aperiodic chains\n\nThe simulation results closely match the analytical predictions, validating both the implementation and the theoretical foundations of Markov chain theory.","pos":18,"type":"cell"}
{"cell_type":"markdown","id":"47d2e8","input":"### Long-term Behavior\n\nFor large $n$, all rows of $\\mathbf{P}^n$ should converge to the stationary distribution:","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"6afcc3","input":"## Convergence Analysis\n\nWe examine how the state distribution converges to the stationary distribution over time.","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"caf6a3","input":"## Example: Weather Model\n\nConsider a simple weather model with three states:\n- State 0: Sunny\n- State 1: Cloudy\n- State 2: Rainy\n\nWe define a transition matrix based on typical weather patterns.","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"db86ca","input":"## Visualization\n\nWe create a comprehensive visualization showing:\n1. The transition matrix as a heatmap\n2. A sample trajectory\n3. Convergence to stationary distribution\n4. Comparison of analytical vs empirical distributions","pos":12,"type":"cell"}
{"cell_type":"markdown","id":"e2917a","input":"## Computing the Stationary Distribution\n\n### Analytical Solution\n\nWe find $\\boldsymbol{\\pi}$ by solving $\\boldsymbol{\\pi} \\mathbf{P} = \\boldsymbol{\\pi}$ subject to $\\sum_i \\pi_i = 1$.\n\nThis is equivalent to finding the left eigenvector of $\\mathbf{P}$ corresponding to eigenvalue 1.","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"fa897f","input":"# Markov Chain Simulation\n\n## Introduction\n\nA **Markov chain** is a stochastic process that satisfies the **Markov property**: the future state depends only on the current state, not on the sequence of events that preceded it. This \"memoryless\" property makes Markov chains powerful tools for modeling systems in physics, biology, economics, and computer science.\n\n## Mathematical Foundation\n\n### Definition\n\nA discrete-time Markov chain is a sequence of random variables $X_0, X_1, X_2, \\ldots$ taking values in a finite or countable state space $S$, satisfying:\n\n$$P(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i)$$\n\nThis conditional probability is called the **transition probability** and is denoted:\n\n$$p_{ij} = P(X_{n+1} = j \\mid X_n = i)$$\n\n### Transition Matrix\n\nFor a Markov chain with $N$ states, the transition probabilities are organized into an $N \\times N$ **transition matrix** $\\mathbf{P}$:\n\n$$\\mathbf{P} = \\begin{pmatrix} p_{11} & p_{12} & \\cdots & p_{1N} \\\\ p_{21} & p_{22} & \\cdots & p_{2N} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ p_{N1} & p_{N2} & \\cdots & p_{NN} \\end{pmatrix}$$\n\nEach row must sum to 1 (stochastic matrix):\n\n$$\\sum_{j=1}^{N} p_{ij} = 1 \\quad \\forall i$$\n\n### Chapman-Kolmogorov Equation\n\nThe $n$-step transition probability is given by:\n\n$$p_{ij}^{(n)} = P(X_{m+n} = j \\mid X_m = i) = (\\mathbf{P}^n)_{ij}$$\n\n### Stationary Distribution\n\nA probability distribution $\\boldsymbol{\\pi} = (\\pi_1, \\pi_2, \\ldots, \\pi_N)$ is a **stationary distribution** if:\n\n$$\\boldsymbol{\\pi} \\mathbf{P} = \\boldsymbol{\\pi}$$\n\nThis means $\\boldsymbol{\\pi}$ is a left eigenvector of $\\mathbf{P}$ with eigenvalue 1.\n\nFor an irreducible and aperiodic Markov chain, the stationary distribution exists, is unique, and:\n\n$$\\lim_{n \\to \\infty} p_{ij}^{(n)} = \\pi_j$$\n\nregardless of the initial state $i$.","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"fb3202","input":"### Empirical Estimation\n\nWe can also estimate the stationary distribution from the simulation by computing the fraction of time spent in each state.","pos":8,"type":"cell"}
{"id":0,"time":1763839849325,"type":"user"}
{"last_load":1763839849602,"type":"file"}