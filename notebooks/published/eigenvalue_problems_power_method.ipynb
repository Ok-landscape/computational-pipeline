{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalue Problems: The Power Method\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Eigenvalue problems are fundamental in linear algebra and have widespread applications in physics, engineering, data science, and numerical analysis. Given a square matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$, the eigenvalue problem seeks to find scalar $\\lambda$ (eigenvalue) and non-zero vector $\\mathbf{v}$ (eigenvector) satisfying:\n",
    "\n",
    "$$\\mathbf{A}\\mathbf{v} = \\lambda \\mathbf{v}$$\n",
    "\n",
    "## The Power Method\n",
    "\n",
    "The **Power Method** (also known as power iteration) is an iterative algorithm for finding the **dominant eigenvalue** (the eigenvalue with largest absolute value) and its corresponding eigenvector.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "Given an initial guess $\\mathbf{v}_0$, the power method iterates:\n",
    "\n",
    "$$\\mathbf{w}_{k+1} = \\mathbf{A}\\mathbf{v}_k$$\n",
    "\n",
    "$$\\mathbf{v}_{k+1} = \\frac{\\mathbf{w}_{k+1}}{\\|\\mathbf{w}_{k+1}\\|}$$\n",
    "\n",
    "The eigenvalue estimate at iteration $k$ is given by the **Rayleigh quotient**:\n",
    "\n",
    "$$\\lambda_k = \\frac{\\mathbf{v}_k^T \\mathbf{A} \\mathbf{v}_k}{\\mathbf{v}_k^T \\mathbf{v}_k}$$\n",
    "\n",
    "### Convergence\n",
    "\n",
    "If the matrix $\\mathbf{A}$ has eigenvalues $|\\lambda_1| > |\\lambda_2| \\geq \\cdots \\geq |\\lambda_n|$, the convergence rate is:\n",
    "\n",
    "$$\\text{Error} \\sim \\mathcal{O}\\left(\\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^k\\right)$$\n",
    "\n",
    "The method converges linearly, with faster convergence when the ratio $|\\lambda_2/\\lambda_1|$ is small.\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **PageRank algorithm**: Finding dominant eigenvector of web graph\n",
    "- **Principal Component Analysis (PCA)**: Largest eigenvalues of covariance matrix\n",
    "- **Structural analysis**: Natural frequencies of vibrating systems\n",
    "- **Quantum mechanics**: Ground state energy calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm, eig\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the Power Method\n",
    "\n",
    "We implement the power method with the following features:\n",
    "- Normalization at each step to prevent overflow\n",
    "- Rayleigh quotient for eigenvalue estimation\n",
    "- Convergence history tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_method(A, num_iterations=100, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Power method for finding the dominant eigenvalue and eigenvector.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    A : ndarray\n",
    "        Square matrix\n",
    "    num_iterations : int\n",
    "        Maximum number of iterations\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    eigenvalue : float\n",
    "        Dominant eigenvalue\n",
    "    eigenvector : ndarray\n",
    "        Corresponding eigenvector (normalized)\n",
    "    history : dict\n",
    "        Convergence history\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # Initialize with random vector\n",
    "    v = np.random.rand(n)\n",
    "    v = v / norm(v)\n",
    "    \n",
    "    eigenvalue_history = []\n",
    "    error_history = []\n",
    "    \n",
    "    eigenvalue = 0\n",
    "    \n",
    "    for k in range(num_iterations):\n",
    "        # Matrix-vector multiplication\n",
    "        w = A @ v\n",
    "        \n",
    "        # Normalize\n",
    "        v_new = w / norm(w)\n",
    "        \n",
    "        # Rayleigh quotient for eigenvalue estimate\n",
    "        eigenvalue_new = (v_new @ A @ v_new) / (v_new @ v_new)\n",
    "        \n",
    "        # Track convergence\n",
    "        eigenvalue_history.append(eigenvalue_new)\n",
    "        \n",
    "        # Compute error (change in eigenvalue)\n",
    "        error = abs(eigenvalue_new - eigenvalue)\n",
    "        error_history.append(error)\n",
    "        \n",
    "        # Check convergence\n",
    "        if error < tol and k > 0:\n",
    "            v = v_new\n",
    "            eigenvalue = eigenvalue_new\n",
    "            break\n",
    "        \n",
    "        v = v_new\n",
    "        eigenvalue = eigenvalue_new\n",
    "    \n",
    "    history = {\n",
    "        'eigenvalues': eigenvalue_history,\n",
    "        'errors': error_history,\n",
    "        'iterations': k + 1\n",
    "    }\n",
    "    \n",
    "    return eigenvalue, v, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Symmetric Positive Definite Matrix\n",
    "\n",
    "We first test the power method on a symmetric positive definite matrix, which guarantees real positive eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a symmetric positive definite matrix\n",
    "n = 5\n",
    "B = np.random.rand(n, n)\n",
    "A1 = B.T @ B + np.eye(n)  # Guarantees positive definiteness\n",
    "\n",
    "print(\"Matrix A1:\")\n",
    "print(A1.round(4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply power method\n",
    "eigenvalue_pm, eigenvector_pm, history1 = power_method(A1, num_iterations=50)\n",
    "\n",
    "# Compare with numpy's eigenvalue decomposition\n",
    "eigenvalues_np, eigenvectors_np = eig(A1)\n",
    "idx = np.argmax(np.abs(eigenvalues_np))\n",
    "dominant_eigenvalue_np = eigenvalues_np[idx].real\n",
    "\n",
    "print(f\"Power Method Result:\")\n",
    "print(f\"  Dominant eigenvalue: {eigenvalue_pm:.10f}\")\n",
    "print(f\"  Iterations: {history1['iterations']}\")\n",
    "print()\n",
    "print(f\"NumPy Reference:\")\n",
    "print(f\"  Dominant eigenvalue: {dominant_eigenvalue_np:.10f}\")\n",
    "print()\n",
    "print(f\"Absolute Error: {abs(eigenvalue_pm - dominant_eigenvalue_np):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Convergence Rate Analysis\n",
    "\n",
    "We analyze how the ratio $|\\lambda_2/\\lambda_1|$ affects convergence speed by constructing matrices with known eigenvalue structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix_with_eigenvalues(eigenvalues):\n",
    "    \"\"\"\n",
    "    Create a matrix with specified eigenvalues using random orthogonal similarity transform.\n",
    "    \"\"\"\n",
    "    n = len(eigenvalues)\n",
    "    D = np.diag(eigenvalues)\n",
    "    \n",
    "    # Random orthogonal matrix via QR decomposition\n",
    "    Q, _ = np.linalg.qr(np.random.rand(n, n))\n",
    "    \n",
    "    # Similar matrix with same eigenvalues\n",
    "    A = Q @ D @ Q.T\n",
    "    return A\n",
    "\n",
    "# Test different eigenvalue ratios\n",
    "ratios = [0.9, 0.7, 0.5, 0.3, 0.1]\n",
    "results = []\n",
    "\n",
    "for ratio in ratios:\n",
    "    eigenvalues = [10, 10*ratio, 1, 0.5, 0.1]\n",
    "    A = create_matrix_with_eigenvalues(eigenvalues)\n",
    "    \n",
    "    _, _, history = power_method(A, num_iterations=100, tol=1e-12)\n",
    "    results.append({\n",
    "        'ratio': ratio,\n",
    "        'history': history\n",
    "    })\n",
    "\n",
    "print(\"Convergence analysis completed for different λ₂/λ₁ ratios.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We create comprehensive visualizations showing:\n",
    "1. Convergence of eigenvalue estimates\n",
    "2. Error decay on logarithmic scale\n",
    "3. Comparison of convergence rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Eigenvalue convergence for Example 1\n",
    "ax1 = axes[0, 0]\n",
    "iterations = range(1, len(history1['eigenvalues']) + 1)\n",
    "ax1.plot(iterations, history1['eigenvalues'], 'b-o', markersize=4, label='Power Method')\n",
    "ax1.axhline(y=dominant_eigenvalue_np, color='r', linestyle='--', label='True Value')\n",
    "ax1.set_xlabel('Iteration', fontsize=11)\n",
    "ax1.set_ylabel('Eigenvalue Estimate', fontsize=11)\n",
    "ax1.set_title('Convergence of Eigenvalue Estimate', fontsize=12)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Error decay (log scale)\n",
    "ax2 = axes[0, 1]\n",
    "errors = history1['errors'][1:]  # Skip first (undefined)\n",
    "ax2.semilogy(range(2, len(errors) + 2), errors, 'g-o', markersize=4)\n",
    "ax2.set_xlabel('Iteration', fontsize=11)\n",
    "ax2.set_ylabel('|λₖ - λₖ₋₁|', fontsize=11)\n",
    "ax2.set_title('Error Decay (Logarithmic Scale)', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Comparison of convergence rates for different ratios\n",
    "ax3 = axes[1, 0]\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.9, len(ratios)))\n",
    "\n",
    "for i, (result, color) in enumerate(zip(results, colors)):\n",
    "    errors = result['history']['errors'][1:]\n",
    "    if len(errors) > 1:\n",
    "        ax3.semilogy(range(2, len(errors) + 2), errors, \n",
    "                     color=color, linewidth=2,\n",
    "                     label=f'λ₂/λ₁ = {result[\"ratio\"]}')\n",
    "\n",
    "ax3.set_xlabel('Iteration', fontsize=11)\n",
    "ax3.set_ylabel('Error', fontsize=11)\n",
    "ax3.set_title('Effect of Eigenvalue Ratio on Convergence', fontsize=12)\n",
    "ax3.legend(loc='upper right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Theoretical vs observed convergence rate\n",
    "ax4 = axes[1, 1]\n",
    "theoretical_rates = ratios\n",
    "observed_rates = []\n",
    "\n",
    "for result in results:\n",
    "    errors = result['history']['errors']\n",
    "    if len(errors) > 10:\n",
    "        # Estimate convergence rate from error decay\n",
    "        rate = (errors[-1] / errors[10]) ** (1/(len(errors) - 11))\n",
    "        observed_rates.append(min(rate, 1.0))  # Cap at 1\n",
    "    else:\n",
    "        observed_rates.append(0)\n",
    "\n",
    "ax4.plot(theoretical_rates, theoretical_rates, 'k--', linewidth=2, label='Theoretical')\n",
    "ax4.scatter(theoretical_rates, observed_rates, s=100, c='red', zorder=5, label='Observed')\n",
    "ax4.set_xlabel('Theoretical Rate (λ₂/λ₁)', fontsize=11)\n",
    "ax4.set_ylabel('Observed Convergence Rate', fontsize=11)\n",
    "ax4.set_title('Theoretical vs Observed Convergence Rate', fontsize=12)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_xlim(0, 1)\n",
    "ax4.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Application to PageRank-like Problem\n",
    "\n",
    "The power method is famously used in Google's PageRank algorithm. Here we demonstrate a simplified version using a stochastic matrix (rows sum to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple web graph (stochastic matrix)\n",
    "# 5 pages with links between them\n",
    "n_pages = 5\n",
    "G = np.array([\n",
    "    [0, 1, 1, 0, 0],  # Page 0 links to 1, 2\n",
    "    [0, 0, 1, 1, 0],  # Page 1 links to 2, 3\n",
    "    [1, 0, 0, 1, 1],  # Page 2 links to 0, 3, 4\n",
    "    [0, 1, 0, 0, 1],  # Page 3 links to 1, 4\n",
    "    [1, 0, 1, 0, 0]   # Page 4 links to 0, 2\n",
    "], dtype=float)\n",
    "\n",
    "# Normalize rows to create transition matrix\n",
    "row_sums = G.sum(axis=1)\n",
    "P = G / row_sums[:, np.newaxis]\n",
    "\n",
    "# Add damping factor (standard PageRank)\n",
    "d = 0.85\n",
    "M = d * P + (1 - d) / n_pages * np.ones((n_pages, n_pages))\n",
    "\n",
    "# PageRank uses the transpose (we want column stochastic)\n",
    "M_T = M.T\n",
    "\n",
    "print(\"Transition Matrix (with damping):\")\n",
    "print(M_T.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply power method to find PageRank scores\n",
    "pagerank_eigenvalue, pagerank_vector, _ = power_method(M_T, num_iterations=100)\n",
    "\n",
    "# Normalize to get probability distribution\n",
    "pagerank_scores = np.abs(pagerank_vector)\n",
    "pagerank_scores = pagerank_scores / pagerank_scores.sum()\n",
    "\n",
    "print(\"PageRank Scores:\")\n",
    "for i, score in enumerate(pagerank_scores):\n",
    "    print(f\"  Page {i}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nDominant eigenvalue: {pagerank_eigenvalue:.6f}\")\n",
    "print(\"(Should be close to 1 for stochastic matrices)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **The Power Method** is a simple iterative algorithm for finding the dominant eigenvalue and eigenvector of a matrix.\n",
    "\n",
    "2. **Convergence Rate**: The method converges linearly with rate $|\\lambda_2/\\lambda_1|$. Faster convergence occurs when there is a large gap between the dominant and second eigenvalue.\n",
    "\n",
    "3. **Rayleigh Quotient**: Provides the eigenvalue estimate $\\lambda = \\frac{\\mathbf{v}^T \\mathbf{A} \\mathbf{v}}{\\mathbf{v}^T \\mathbf{v}}$.\n",
    "\n",
    "4. **Applications**: The method is foundational for PageRank, PCA initialization, and finding dominant modes in physical systems.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Only finds the **dominant** eigenvalue (modifications like inverse iteration can find others)\n",
    "- Slow convergence when eigenvalues are closely spaced\n",
    "- May fail if the dominant eigenvalue is complex or has multiplicity > 1\n",
    "\n",
    "### Extensions\n",
    "\n",
    "- **Inverse Power Method**: Finds smallest eigenvalue using $\\mathbf{A}^{-1}$\n",
    "- **Shifted Power Method**: Finds eigenvalue closest to a shift $\\sigma$\n",
    "- **QR Algorithm**: Modern method for computing all eigenvalues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
