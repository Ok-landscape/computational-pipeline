{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton-Raphson Root Finding Method\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The Newton-Raphson method (also known as Newton's method) is one of the most powerful and widely used iterative techniques for finding roots of nonlinear equations. Given a function $f(x)$, we seek values of $x$ such that $f(x) = 0$.\n",
    "\n",
    "## Theoretical Foundation\n",
    "\n",
    "### Derivation from Taylor Series\n",
    "\n",
    "The Newton-Raphson method can be derived from the Taylor series expansion of $f(x)$ about a point $x_n$:\n",
    "\n",
    "$$f(x) = f(x_n) + f'(x_n)(x - x_n) + \\frac{f''(x_n)}{2!}(x - x_n)^2 + \\mathcal{O}((x - x_n)^3)$$\n",
    "\n",
    "Truncating after the linear term and setting $f(x) = 0$:\n",
    "\n",
    "$$0 \\approx f(x_n) + f'(x_n)(x - x_n)$$\n",
    "\n",
    "Solving for $x$ gives us the next approximation $x_{n+1}$:\n",
    "\n",
    "$$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$$\n",
    "\n",
    "This is the **Newton-Raphson iteration formula**.\n",
    "\n",
    "### Geometric Interpretation\n",
    "\n",
    "Geometrically, each iteration finds where the tangent line to the curve $y = f(x)$ at the point $(x_n, f(x_n))$ crosses the $x$-axis. The equation of this tangent line is:\n",
    "\n",
    "$$y - f(x_n) = f'(x_n)(x - x_n)$$\n",
    "\n",
    "Setting $y = 0$ and solving for $x$ yields the Newton-Raphson formula.\n",
    "\n",
    "### Convergence Analysis\n",
    "\n",
    "The Newton-Raphson method exhibits **quadratic convergence** near simple roots. If $\\alpha$ is a root of $f(x)$ and $e_n = x_n - \\alpha$ is the error at iteration $n$, then:\n",
    "\n",
    "$$e_{n+1} \\approx \\frac{f''(\\alpha)}{2f'(\\alpha)} e_n^2$$\n",
    "\n",
    "This means the number of correct digits approximately doubles with each iteration. The convergence rate depends on:\n",
    "\n",
    "1. **Quality of initial guess**: $x_0$ should be sufficiently close to the root\n",
    "2. **Non-zero derivative**: $f'(x) \\neq 0$ near the root\n",
    "3. **Continuous second derivative**: For the error analysis to hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "# Set up publication-quality plots\n",
    "plt.rcParams['figure.figsize'] = [12, 10]\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "### Core Algorithm\n",
    "\n",
    "We implement the Newton-Raphson method with convergence tracking and error handling for cases where the derivative vanishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson(f, df, x0, tol=1e-10, max_iter=100):\n",
    "    \"\"\"\n",
    "    Newton-Raphson root finding algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        The function whose root we seek\n",
    "    df : callable\n",
    "        The derivative of f\n",
    "    x0 : float\n",
    "        Initial guess\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    max_iter : int\n",
    "        Maximum number of iterations\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    root : float\n",
    "        Approximate root\n",
    "    iterations : list\n",
    "        History of x values\n",
    "    converged : bool\n",
    "        Whether the method converged\n",
    "    \"\"\"\n",
    "    iterations = [x0]\n",
    "    x = x0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        fx = f(x)\n",
    "        dfx = df(x)\n",
    "        \n",
    "        # Check for zero derivative\n",
    "        if abs(dfx) < 1e-15:\n",
    "            print(f\"Warning: Near-zero derivative at iteration {i}\")\n",
    "            return x, iterations, False\n",
    "        \n",
    "        # Newton-Raphson update\n",
    "        x_new = x - fx / dfx\n",
    "        iterations.append(x_new)\n",
    "        \n",
    "        # Check convergence\n",
    "        if abs(x_new - x) < tol:\n",
    "            return x_new, iterations, True\n",
    "        \n",
    "        x = x_new\n",
    "    \n",
    "    return x, iterations, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Finding Square Roots\n",
    "\n",
    "To find $\\sqrt{a}$, we solve $f(x) = x^2 - a = 0$.\n",
    "\n",
    "With $f'(x) = 2x$, the iteration becomes:\n",
    "\n",
    "$$x_{n+1} = x_n - \\frac{x_n^2 - a}{2x_n} = \\frac{1}{2}\\left(x_n + \\frac{a}{x_n}\\right)$$\n",
    "\n",
    "This is the famous **Babylonian method** for computing square roots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sqrt(2)\n",
    "a = 2\n",
    "f_sqrt = lambda x: x**2 - a\n",
    "df_sqrt = lambda x: 2*x\n",
    "\n",
    "root, iterations, converged = newton_raphson(f_sqrt, df_sqrt, x0=1.0)\n",
    "\n",
    "print(f\"Finding √{a}:\")\n",
    "print(f\"{'Iteration':<12} {'x_n':<20} {'Error':<20}\")\n",
    "print(\"-\" * 52)\n",
    "\n",
    "exact = np.sqrt(a)\n",
    "for i, x in enumerate(iterations):\n",
    "    error = abs(x - exact)\n",
    "    print(f\"{i:<12} {x:<20.15f} {error:<20.2e}\")\n",
    "\n",
    "print(f\"\\nConverged: {converged}\")\n",
    "print(f\"Root found: {root:.15f}\")\n",
    "print(f\"Exact value: {exact:.15f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Transcendental Equation\n",
    "\n",
    "Consider finding the root of:\n",
    "\n",
    "$$f(x) = x - \\cos(x) = 0$$\n",
    "\n",
    "This equation arises in various physics problems. The derivative is:\n",
    "\n",
    "$$f'(x) = 1 + \\sin(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcendental equation: x = cos(x)\n",
    "f_trans = lambda x: x - np.cos(x)\n",
    "df_trans = lambda x: 1 + np.sin(x)\n",
    "\n",
    "root_trans, iter_trans, conv_trans = newton_raphson(f_trans, df_trans, x0=0.5)\n",
    "\n",
    "print(\"Finding root of x = cos(x):\")\n",
    "print(f\"{'Iteration':<12} {'x_n':<20} {'|f(x_n)|':<20}\")\n",
    "print(\"-\" * 52)\n",
    "\n",
    "for i, x in enumerate(iter_trans):\n",
    "    print(f\"{i:<12} {x:<20.15f} {abs(f_trans(x)):<20.2e}\")\n",
    "\n",
    "print(f\"\\nRoot found: {root_trans:.15f}\")\n",
    "print(f\"Verification: f({root_trans:.10f}) = {f_trans(root_trans):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Newton-Raphson Iterations\n",
    "\n",
    "We now create a comprehensive visualization showing:\n",
    "1. The geometric interpretation of Newton-Raphson iterations\n",
    "2. Convergence rate analysis\n",
    "3. Comparison with different initial guesses\n",
    "4. Error reduction over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Test function: f(x) = x^3 - 2x - 5\n",
    "f = lambda x: x**3 - 2*x - 5\n",
    "df = lambda x: 3*x**2 - 2\n",
    "\n",
    "# Plot 1: Geometric interpretation\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "\n",
    "x_plot = np.linspace(0, 3, 1000)\n",
    "y_plot = f(x_plot)\n",
    "\n",
    "ax1.plot(x_plot, y_plot, 'b-', linewidth=2, label=r'$f(x) = x^3 - 2x - 5$')\n",
    "ax1.axhline(y=0, color='k', linewidth=0.5)\n",
    "ax1.axvline(x=0, color='k', linewidth=0.5)\n",
    "\n",
    "# Newton-Raphson iterations starting from x0 = 3\n",
    "x0 = 3.0\n",
    "root, iterations, _ = newton_raphson(f, df, x0, tol=1e-12)\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(iterations)-1))\n",
    "\n",
    "for i in range(min(4, len(iterations)-1)):\n",
    "    xi = iterations[i]\n",
    "    xi1 = iterations[i+1]\n",
    "    \n",
    "    # Plot point on curve\n",
    "    ax1.plot(xi, f(xi), 'o', color=colors[i], markersize=8)\n",
    "    \n",
    "    # Plot tangent line\n",
    "    x_tan = np.linspace(xi1 - 0.5, xi + 0.5, 100)\n",
    "    y_tan = f(xi) + df(xi) * (x_tan - xi)\n",
    "    ax1.plot(x_tan, y_tan, '--', color=colors[i], alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    # Vertical line to x-axis\n",
    "    ax1.plot([xi, xi], [0, f(xi)], ':', color=colors[i], alpha=0.5)\n",
    "    \n",
    "    # Label iteration\n",
    "    ax1.annotate(f'$x_{i}$', xy=(xi, 0), xytext=(xi, -2),\n",
    "                 fontsize=10, ha='center')\n",
    "\n",
    "# Mark the root\n",
    "ax1.plot(root, 0, 'r*', markersize=15, label=f'Root ≈ {root:.6f}')\n",
    "\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('f(x)')\n",
    "ax1.set_title('Geometric Interpretation of Newton-Raphson Method')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.set_xlim([0, 3.5])\n",
    "ax1.set_ylim([-10, 20])\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Convergence rate (quadratic convergence)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "\n",
    "errors = [abs(x - root) for x in iterations]\n",
    "errors = [e for e in errors if e > 1e-16]  # Remove zero errors for log plot\n",
    "\n",
    "iterations_num = range(len(errors))\n",
    "ax2.semilogy(iterations_num, errors, 'bo-', linewidth=2, markersize=8, label='Actual error')\n",
    "\n",
    "# Theoretical quadratic convergence\n",
    "if len(errors) > 1:\n",
    "    # Estimate convergence constant\n",
    "    theoretical = [errors[0]]\n",
    "    C = abs(df(root) / (2 * (3*root**2 - 2)))  # Approximate constant\n",
    "    for i in range(1, len(errors)):\n",
    "        theoretical.append(C * theoretical[-1]**2)\n",
    "    ax2.semilogy(range(len(theoretical)), theoretical, 'r--', linewidth=1.5, \n",
    "                 alpha=0.7, label='Quadratic convergence')\n",
    "\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Error (log scale)')\n",
    "ax2.set_title('Convergence Rate Analysis')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Different initial guesses\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "\n",
    "initial_guesses = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "colors_init = plt.cm.tab10(np.linspace(0, 1, len(initial_guesses)))\n",
    "\n",
    "for x0, color in zip(initial_guesses, colors_init):\n",
    "    _, iters, conv = newton_raphson(f, df, x0, tol=1e-12)\n",
    "    errs = [abs(x - root) for x in iters]\n",
    "    errs = [e if e > 1e-16 else 1e-16 for e in errs]\n",
    "    ax3.semilogy(range(len(errs)), errs, 'o-', color=color, \n",
    "                 linewidth=1.5, markersize=6, label=f'$x_0 = {x0}$')\n",
    "\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('Error (log scale)')\n",
    "ax3.set_title('Effect of Initial Guess on Convergence')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Basin of attraction / Function landscape\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "# For a polynomial with multiple roots: f(x) = x^3 - x\n",
    "f_multi = lambda x: x**3 - x\n",
    "df_multi = lambda x: 3*x**2 - 1\n",
    "\n",
    "x_basin = np.linspace(-2, 2, 500)\n",
    "roots_found = []\n",
    "\n",
    "for x0 in x_basin:\n",
    "    try:\n",
    "        r, _, _ = newton_raphson(f_multi, df_multi, x0, tol=1e-10, max_iter=50)\n",
    "        roots_found.append(r)\n",
    "    except:\n",
    "        roots_found.append(np.nan)\n",
    "\n",
    "roots_found = np.array(roots_found)\n",
    "\n",
    "# Color by which root is found\n",
    "colors_basin = np.zeros(len(x_basin))\n",
    "colors_basin[np.abs(roots_found - (-1)) < 0.1] = -1\n",
    "colors_basin[np.abs(roots_found - 0) < 0.1] = 0\n",
    "colors_basin[np.abs(roots_found - 1) < 0.1] = 1\n",
    "\n",
    "ax4.scatter(x_basin, roots_found, c=colors_basin, cmap='coolwarm', s=1, alpha=0.7)\n",
    "ax4.axhline(y=-1, color='b', linestyle='--', alpha=0.5, label='Root: -1')\n",
    "ax4.axhline(y=0, color='gray', linestyle='--', alpha=0.5, label='Root: 0')\n",
    "ax4.axhline(y=1, color='r', linestyle='--', alpha=0.5, label='Root: 1')\n",
    "\n",
    "ax4.set_xlabel('Initial guess $x_0$')\n",
    "ax4.set_ylabel('Root found')\n",
    "ax4.set_title(r'Basin of Attraction for $f(x) = x^3 - x$')\n",
    "ax4.legend(loc='upper left')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Results\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **Quadratic Convergence**: The error plot demonstrates that the number of correct digits approximately doubles with each iteration, characteristic of quadratic convergence.\n",
    "\n",
    "2. **Sensitivity to Initial Guess**: While the method converges from various starting points, the number of iterations required depends on the quality of the initial guess.\n",
    "\n",
    "3. **Basin of Attraction**: For functions with multiple roots, the initial guess determines which root is found. The basin of attraction can have complex, fractal-like boundaries.\n",
    "\n",
    "### Limitations and Failure Modes\n",
    "\n",
    "The Newton-Raphson method can fail when:\n",
    "\n",
    "- $f'(x_n) = 0$ (horizontal tangent)\n",
    "- The iterates oscillate or diverge\n",
    "- The function has discontinuities or is not differentiable\n",
    "\n",
    "### Extensions\n",
    "\n",
    "- **Modified Newton's Method**: Uses $x_{n+1} = x_n - m\\frac{f(x_n)}{f'(x_n)}$ for roots of multiplicity $m$\n",
    "- **Quasi-Newton Methods**: Approximate the derivative numerically\n",
    "- **Multivariate Newton's Method**: Extends to systems of equations using the Jacobian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate failure mode: cycling behavior\n",
    "print(\"Demonstration of potential failure modes:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Function where Newton-Raphson can cycle\n",
    "f_cycle = lambda x: x**3 - 2*x + 2\n",
    "df_cycle = lambda x: 3*x**2 - 2\n",
    "\n",
    "# This starting point leads to slow convergence\n",
    "x0_bad = 0.0\n",
    "try:\n",
    "    root_bad, iter_bad, conv_bad = newton_raphson(f_cycle, df_cycle, x0_bad, max_iter=10)\n",
    "    print(f\"\\nStarting from x0 = {x0_bad} for f(x) = x³ - 2x + 2:\")\n",
    "    for i, x in enumerate(iter_bad[:6]):\n",
    "        print(f\"  x_{i} = {x:.10f}\")\n",
    "    print(f\"  Converged: {conv_bad}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Failed: {e}\")\n",
    "\n",
    "# Good starting point\n",
    "x0_good = -2.0\n",
    "root_good, iter_good, conv_good = newton_raphson(f_cycle, df_cycle, x0_good)\n",
    "print(f\"\\nStarting from x0 = {x0_good}:\")\n",
    "for i, x in enumerate(iter_good):\n",
    "    print(f\"  x_{i} = {x:.10f}\")\n",
    "print(f\"  Converged: {conv_good}\")\n",
    "print(f\"  Root: {root_good:.15f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Newton-Raphson method is a powerful root-finding algorithm characterized by:\n",
    "\n",
    "- **Quadratic convergence** near simple roots\n",
    "- **Elegant geometric interpretation** via tangent lines\n",
    "- **Wide applicability** to differentiable functions\n",
    "\n",
    "However, practitioners must be aware of its limitations:\n",
    "\n",
    "- Requires computation of the derivative\n",
    "- Sensitive to the initial guess\n",
    "- May fail near stationary points\n",
    "\n",
    "For production use, the method is often combined with safeguards such as bracketing or line search to ensure global convergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
