{"backend_state":"running","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-b572e84c-86c4-4892-a76a-ade358170189.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_backend_state":1763840234768,"last_ipynb_save":1763840254262,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1763840234949,"exec_count":3,"id":"2257c6","input":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.linalg import norm, eig\n\n# Set random seed for reproducibility\nnp.random.seed(42)","kernel":"python3","pos":1,"start":1763840234862,"state":"done","type":"cell"}
{"cell_type":"code","end":1763840235049,"exec_count":4,"id":"9798d7","input":"def power_method(A, num_iterations=100, tol=1e-10):\n    \"\"\"\n    Power method for finding the dominant eigenvalue and eigenvector.\n    \n    Parameters:\n    -----------\n    A : ndarray\n        Square matrix\n    num_iterations : int\n        Maximum number of iterations\n    tol : float\n        Convergence tolerance\n    \n    Returns:\n    --------\n    eigenvalue : float\n        Dominant eigenvalue\n    eigenvector : ndarray\n        Corresponding eigenvector (normalized)\n    history : dict\n        Convergence history\n    \"\"\"\n    n = A.shape[0]\n    \n    # Initialize with random vector\n    v = np.random.rand(n)\n    v = v / norm(v)\n    \n    eigenvalue_history = []\n    error_history = []\n    \n    eigenvalue = 0\n    \n    for k in range(num_iterations):\n        # Matrix-vector multiplication\n        w = A @ v\n        \n        # Normalize\n        v_new = w / norm(w)\n        \n        # Rayleigh quotient for eigenvalue estimate\n        eigenvalue_new = (v_new @ A @ v_new) / (v_new @ v_new)\n        \n        # Track convergence\n        eigenvalue_history.append(eigenvalue_new)\n        \n        # Compute error (change in eigenvalue)\n        error = abs(eigenvalue_new - eigenvalue)\n        error_history.append(error)\n        \n        # Check convergence\n        if error < tol and k > 0:\n            v = v_new\n            eigenvalue = eigenvalue_new\n            break\n        \n        v = v_new\n        eigenvalue = eigenvalue_new\n    \n    history = {\n        'eigenvalues': eigenvalue_history,\n        'errors': error_history,\n        'iterations': k + 1\n    }\n    \n    return eigenvalue, v, history","kernel":"python3","pos":3,"start":1763840234967,"state":"done","type":"cell"}
{"cell_type":"code","end":1763840235248,"exec_count":5,"id":"89b820","input":"# Create a symmetric positive definite matrix\nn = 5\nB = np.random.rand(n, n)\nA1 = B.T @ B + np.eye(n)  # Guarantees positive definiteness\n\nprint(\"Matrix A1:\")\nprint(A1.round(4))\nprint()","kernel":"python3","output":{"0":{"name":"stdout","text":"Matrix A1:\n[[1.573  0.5263 0.7014 0.6257 0.5051]\n [0.5263 2.96   1.754  0.9925 0.518 ]\n [0.7014 1.754  3.3398 1.4693 1.1649]\n [0.6257 0.9925 1.4693 2.0856 0.8505]\n [0.5051 0.518  1.1649 0.8505 1.8516]]\n\n"}},"pos":5,"start":1763840235166,"state":"done","type":"cell"}
{"cell_type":"code","end":1763840235269,"exec_count":6,"id":"f05153","input":"# Apply power method\neigenvalue_pm, eigenvector_pm, history1 = power_method(A1, num_iterations=50)\n\n# Compare with numpy's eigenvalue decomposition\neigenvalues_np, eigenvectors_np = eig(A1)\nidx = np.argmax(np.abs(eigenvalues_np))\ndominant_eigenvalue_np = eigenvalues_np[idx].real\n\nprint(f\"Power Method Result:\")\nprint(f\"  Dominant eigenvalue: {eigenvalue_pm:.10f}\")\nprint(f\"  Iterations: {history1['iterations']}\")\nprint()\nprint(f\"NumPy Reference:\")\nprint(f\"  Dominant eigenvalue: {dominant_eigenvalue_np:.10f}\")\nprint()\nprint(f\"Absolute Error: {abs(eigenvalue_pm - dominant_eigenvalue_np):.2e}\")","kernel":"python3","output":{"0":{"name":"stdout","text":"Power Method Result:\n  Dominant eigenvalue: 6.5296998592\n  Iterations: 11\n\nNumPy Reference:\n  Dominant eigenvalue: 6.5296998592\n\nAbsolute Error: 8.97e-13\n"}},"pos":6,"start":1763840235263,"state":"done","type":"cell"}
{"cell_type":"code","end":1763840235366,"exec_count":7,"id":"1acd52","input":"def create_matrix_with_eigenvalues(eigenvalues):\n    \"\"\"\n    Create a matrix with specified eigenvalues using random orthogonal similarity transform.\n    \"\"\"\n    n = len(eigenvalues)\n    D = np.diag(eigenvalues)\n    \n    # Random orthogonal matrix via QR decomposition\n    Q, _ = np.linalg.qr(np.random.rand(n, n))\n    \n    # Similar matrix with same eigenvalues\n    A = Q @ D @ Q.T\n    return A\n\n# Test different eigenvalue ratios\nratios = [0.9, 0.7, 0.5, 0.3, 0.1]\nresults = []\n\nfor ratio in ratios:\n    eigenvalues = [10, 10*ratio, 1, 0.5, 0.1]\n    A = create_matrix_with_eigenvalues(eigenvalues)\n    \n    _, _, history = power_method(A, num_iterations=100, tol=1e-12)\n    results.append({\n        'ratio': ratio,\n        'history': history\n    })\n\nprint(\"Convergence analysis completed for different λ₂/λ₁ ratios.\")","kernel":"python3","output":{"0":{"name":"stdout","text":"Convergence analysis completed for different λ₂/λ₁ ratios.\n"}},"pos":8,"start":1763840235281,"state":"done","type":"cell"}
{"cell_type":"code","end":1763840238649,"exec_count":8,"id":"dba7c0","input":"fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Plot 1: Eigenvalue convergence for Example 1\nax1 = axes[0, 0]\niterations = range(1, len(history1['eigenvalues']) + 1)\nax1.plot(iterations, history1['eigenvalues'], 'b-o', markersize=4, label='Power Method')\nax1.axhline(y=dominant_eigenvalue_np, color='r', linestyle='--', label='True Value')\nax1.set_xlabel('Iteration', fontsize=11)\nax1.set_ylabel('Eigenvalue Estimate', fontsize=11)\nax1.set_title('Convergence of Eigenvalue Estimate', fontsize=12)\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Error decay (log scale)\nax2 = axes[0, 1]\nerrors = history1['errors'][1:]  # Skip first (undefined)\nax2.semilogy(range(2, len(errors) + 2), errors, 'g-o', markersize=4)\nax2.set_xlabel('Iteration', fontsize=11)\nax2.set_ylabel('|λₖ - λₖ₋₁|', fontsize=11)\nax2.set_title('Error Decay (Logarithmic Scale)', fontsize=12)\nax2.grid(True, alpha=0.3)\n\n# Plot 3: Comparison of convergence rates for different ratios\nax3 = axes[1, 0]\ncolors = plt.cm.viridis(np.linspace(0, 0.9, len(ratios)))\n\nfor i, (result, color) in enumerate(zip(results, colors)):\n    errors = result['history']['errors'][1:]\n    if len(errors) > 1:\n        ax3.semilogy(range(2, len(errors) + 2), errors, \n                     color=color, linewidth=2,\n                     label=f'λ₂/λ₁ = {result[\"ratio\"]}')\n\nax3.set_xlabel('Iteration', fontsize=11)\nax3.set_ylabel('Error', fontsize=11)\nax3.set_title('Effect of Eigenvalue Ratio on Convergence', fontsize=12)\nax3.legend(loc='upper right')\nax3.grid(True, alpha=0.3)\n\n# Plot 4: Theoretical vs observed convergence rate\nax4 = axes[1, 1]\ntheoretical_rates = ratios\nobserved_rates = []\n\nfor result in results:\n    errors = result['history']['errors']\n    if len(errors) > 10:\n        # Estimate convergence rate from error decay\n        rate = (errors[-1] / errors[10]) ** (1/(len(errors) - 11))\n        observed_rates.append(min(rate, 1.0))  # Cap at 1\n    else:\n        observed_rates.append(0)\n\nax4.plot(theoretical_rates, theoretical_rates, 'k--', linewidth=2, label='Theoretical')\nax4.scatter(theoretical_rates, observed_rates, s=100, c='red', zorder=5, label='Observed')\nax4.set_xlabel('Theoretical Rate (λ₂/λ₁)', fontsize=11)\nax4.set_ylabel('Observed Convergence Rate', fontsize=11)\nax4.set_title('Theoretical vs Observed Convergence Rate', fontsize=12)\nax4.legend()\nax4.grid(True, alpha=0.3)\nax4.set_xlim(0, 1)\nax4.set_ylim(0, 1)\n\nplt.tight_layout()\nplt.savefig('plot.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nFigure saved to 'plot.png'\")","kernel":"python3","output":{"0":{"data":{"image/png":"d099c20f66867cb585704b7b08082aefc0bf4373","text/plain":"<Figure size 1200x1000 with 4 Axes>"},"metadata":{"image/png":{"height":988,"width":1188}}},"1":{"name":"stdout","text":"\nFigure saved to 'plot.png'\n"}},"pos":10,"start":1763840235450,"state":"done","type":"cell"}
{"cell_type":"code","end":1763840238665,"exec_count":9,"id":"82e5ef","input":"# Create a simple web graph (stochastic matrix)\n# 5 pages with links between them\nn_pages = 5\nG = np.array([\n    [0, 1, 1, 0, 0],  # Page 0 links to 1, 2\n    [0, 0, 1, 1, 0],  # Page 1 links to 2, 3\n    [1, 0, 0, 1, 1],  # Page 2 links to 0, 3, 4\n    [0, 1, 0, 0, 1],  # Page 3 links to 1, 4\n    [1, 0, 1, 0, 0]   # Page 4 links to 0, 2\n], dtype=float)\n\n# Normalize rows to create transition matrix\nrow_sums = G.sum(axis=1)\nP = G / row_sums[:, np.newaxis]\n\n# Add damping factor (standard PageRank)\nd = 0.85\nM = d * P + (1 - d) / n_pages * np.ones((n_pages, n_pages))\n\n# PageRank uses the transpose (we want column stochastic)\nM_T = M.T\n\nprint(\"Transition Matrix (with damping):\")\nprint(M_T.round(4))","kernel":"python3","output":{"0":{"name":"stdout","text":"Transition Matrix (with damping):\n[[0.03   0.03   0.3133 0.03   0.455 ]\n [0.455  0.03   0.03   0.455  0.03  ]\n [0.455  0.455  0.03   0.03   0.455 ]\n [0.03   0.455  0.3133 0.03   0.03  ]\n [0.03   0.03   0.3133 0.455  0.03  ]]\n"}},"pos":12,"start":1763840238659,"state":"done","type":"cell"}
{"cell_type":"code","end":1763840238682,"exec_count":10,"id":"2287cd","input":"# Apply power method to find PageRank scores\npagerank_eigenvalue, pagerank_vector, _ = power_method(M_T, num_iterations=100)\n\n# Normalize to get probability distribution\npagerank_scores = np.abs(pagerank_vector)\npagerank_scores = pagerank_scores / pagerank_scores.sum()\n\nprint(\"PageRank Scores:\")\nfor i, score in enumerate(pagerank_scores):\n    print(f\"  Page {i}: {score:.4f}\")\n\nprint(f\"\\nDominant eigenvalue: {pagerank_eigenvalue:.6f}\")\nprint(\"(Should be close to 1 for stochastic matrices)\")","kernel":"python3","output":{"0":{"name":"stdout","text":"PageRank Scores:\n  Page 0: 0.1827\n  Page 1: 0.1858\n  Page 2: 0.2645\n  Page 3: 0.1839\n  Page 4: 0.1831\n\nDominant eigenvalue: 1.000000\n(Should be close to 1 for stochastic matrices)\n"}},"pos":13,"start":1763840238676,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"2df6ee","input":"# Eigenvalue Problems: The Power Method\n\n## Introduction\n\nEigenvalue problems are fundamental in linear algebra and have widespread applications in physics, engineering, data science, and numerical analysis. Given a square matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$, the eigenvalue problem seeks to find scalar $\\lambda$ (eigenvalue) and non-zero vector $\\mathbf{v}$ (eigenvector) satisfying:\n\n$$\\mathbf{A}\\mathbf{v} = \\lambda \\mathbf{v}$$\n\n## The Power Method\n\nThe **Power Method** (also known as power iteration) is an iterative algorithm for finding the **dominant eigenvalue** (the eigenvalue with largest absolute value) and its corresponding eigenvector.\n\n### Algorithm\n\nGiven an initial guess $\\mathbf{v}_0$, the power method iterates:\n\n$$\\mathbf{w}_{k+1} = \\mathbf{A}\\mathbf{v}_k$$\n\n$$\\mathbf{v}_{k+1} = \\frac{\\mathbf{w}_{k+1}}{\\|\\mathbf{w}_{k+1}\\|}$$\n\nThe eigenvalue estimate at iteration $k$ is given by the **Rayleigh quotient**:\n\n$$\\lambda_k = \\frac{\\mathbf{v}_k^T \\mathbf{A} \\mathbf{v}_k}{\\mathbf{v}_k^T \\mathbf{v}_k}$$\n\n### Convergence\n\nIf the matrix $\\mathbf{A}$ has eigenvalues $|\\lambda_1| > |\\lambda_2| \\geq \\cdots \\geq |\\lambda_n|$, the convergence rate is:\n\n$$\\text{Error} \\sim \\mathcal{O}\\left(\\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^k\\right)$$\n\nThe method converges linearly, with faster convergence when the ratio $|\\lambda_2/\\lambda_1|$ is small.\n\n### Applications\n\n- **PageRank algorithm**: Finding dominant eigenvector of web graph\n- **Principal Component Analysis (PCA)**: Largest eigenvalues of covariance matrix\n- **Structural analysis**: Natural frequencies of vibrating systems\n- **Quantum mechanics**: Ground state energy calculations","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"3741f8","input":"## Summary\n\n### Key Takeaways\n\n1. **The Power Method** is a simple iterative algorithm for finding the dominant eigenvalue and eigenvector of a matrix.\n\n2. **Convergence Rate**: The method converges linearly with rate $|\\lambda_2/\\lambda_1|$. Faster convergence occurs when there is a large gap between the dominant and second eigenvalue.\n\n3. **Rayleigh Quotient**: Provides the eigenvalue estimate $\\lambda = \\frac{\\mathbf{v}^T \\mathbf{A} \\mathbf{v}}{\\mathbf{v}^T \\mathbf{v}}$.\n\n4. **Applications**: The method is foundational for PageRank, PCA initialization, and finding dominant modes in physical systems.\n\n### Limitations\n\n- Only finds the **dominant** eigenvalue (modifications like inverse iteration can find others)\n- Slow convergence when eigenvalues are closely spaced\n- May fail if the dominant eigenvalue is complex or has multiplicity > 1\n\n### Extensions\n\n- **Inverse Power Method**: Finds smallest eigenvalue using $\\mathbf{A}^{-1}$\n- **Shifted Power Method**: Finds eigenvalue closest to a shift $\\sigma$\n- **QR Algorithm**: Modern method for computing all eigenvalues","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"b8f7ac","input":"## Example 1: Symmetric Positive Definite Matrix\n\nWe first test the power method on a symmetric positive definite matrix, which guarantees real positive eigenvalues.","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"c352d9","input":"## Example 3: Application to PageRank-like Problem\n\nThe power method is famously used in Google's PageRank algorithm. Here we demonstrate a simplified version using a stochastic matrix (rows sum to 1).","pos":11,"type":"cell"}
{"cell_type":"markdown","id":"ddf550","input":"## Visualization\n\nWe create comprehensive visualizations showing:\n1. Convergence of eigenvalue estimates\n2. Error decay on logarithmic scale\n3. Comparison of convergence rates","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"fabf1a","input":"## Implementation of the Power Method\n\nWe implement the power method with the following features:\n- Normalization at each step to prevent overflow\n- Rayleigh quotient for eigenvalue estimation\n- Convergence history tracking","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"fb1b6e","input":"## Example 2: Convergence Rate Analysis\n\nWe analyze how the ratio $|\\lambda_2/\\lambda_1|$ affects convergence speed by constructing matrices with known eigenvalue structures.","pos":7,"type":"cell"}
{"id":0,"time":1763840228442,"type":"user"}
{"last_load":1763840228750,"type":"file"}