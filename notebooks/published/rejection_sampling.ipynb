{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rejection Sampling: A Fundamental Monte Carlo Method\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Rejection sampling (also known as the acceptance-rejection method) is a fundamental Monte Carlo technique for generating samples from a probability distribution $f(x)$ when direct sampling is difficult or impossible. The method was introduced by John von Neumann in 1951 and remains one of the most important tools in computational statistics.\n",
    "\n",
    "## Theoretical Foundation\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Suppose we wish to sample from a target probability density function $f(x)$ but cannot do so directly. Instead, we have access to:\n",
    "\n",
    "1. A **proposal distribution** $g(x)$ from which we can easily sample\n",
    "2. A **scaling constant** $M \\geq 1$ such that $f(x) \\leq M \\cdot g(x)$ for all $x$ in the support\n",
    "\n",
    "### The Algorithm\n",
    "\n",
    "The rejection sampling algorithm proceeds as follows:\n",
    "\n",
    "1. Generate a sample $x$ from the proposal distribution $g(x)$\n",
    "2. Generate $u \\sim \\text{Uniform}(0, 1)$\n",
    "3. Accept $x$ if $u \\leq \\frac{f(x)}{M \\cdot g(x)}$; otherwise reject and return to step 1\n",
    "\n",
    "### Mathematical Justification\n",
    "\n",
    "The validity of rejection sampling follows from the fundamental theorem:\n",
    "\n",
    "**Theorem:** If $X$ is accepted by the rejection sampling algorithm, then $X \\sim f(x)$.\n",
    "\n",
    "**Proof:** The probability of accepting a point $(x, u)$ drawn from the proposal is:\n",
    "\n",
    "$$P(\\text{accept} | X = x) = P\\left(U \\leq \\frac{f(x)}{M \\cdot g(x)}\\right) = \\frac{f(x)}{M \\cdot g(x)}$$\n",
    "\n",
    "The marginal probability of acceptance is:\n",
    "\n",
    "$$P(\\text{accept}) = \\int_{-\\infty}^{\\infty} \\frac{f(x)}{M \\cdot g(x)} g(x) dx = \\frac{1}{M} \\int_{-\\infty}^{\\infty} f(x) dx = \\frac{1}{M}$$\n",
    "\n",
    "By Bayes' theorem, the density of accepted samples is:\n",
    "\n",
    "$$p(x | \\text{accept}) = \\frac{P(\\text{accept} | X = x) \\cdot g(x)}{P(\\text{accept})} = \\frac{\\frac{f(x)}{M \\cdot g(x)} \\cdot g(x)}{\\frac{1}{M}} = f(x)$$\n",
    "\n",
    "### Efficiency Considerations\n",
    "\n",
    "The **acceptance rate** of the algorithm is $\\frac{1}{M}$. Thus:\n",
    "\n",
    "- Smaller values of $M$ lead to more efficient sampling\n",
    "- The optimal choice of $g(x)$ minimizes $M$ while maintaining $f(x) \\leq M \\cdot g(x)$\n",
    "- The expected number of proposals needed to generate one sample is $M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We will demonstrate rejection sampling by generating samples from a Beta(2.5, 5) distribution using a uniform proposal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.special import gamma\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the target distribution: Beta(alpha, beta)\n",
    "alpha = 2.5\n",
    "beta_param = 5.0\n",
    "\n",
    "def target_pdf(x):\n",
    "    \"\"\"Beta distribution PDF.\"\"\"\n",
    "    if np.isscalar(x):\n",
    "        if x < 0 or x > 1:\n",
    "            return 0.0\n",
    "    else:\n",
    "        result = np.zeros_like(x, dtype=float)\n",
    "        mask = (x >= 0) & (x <= 1)\n",
    "        x_valid = x[mask]\n",
    "        B = gamma(alpha) * gamma(beta_param) / gamma(alpha + beta_param)\n",
    "        result[mask] = (x_valid ** (alpha - 1)) * ((1 - x_valid) ** (beta_param - 1)) / B\n",
    "        return result\n",
    "    \n",
    "    B = gamma(alpha) * gamma(beta_param) / gamma(alpha + beta_param)\n",
    "    return (x ** (alpha - 1)) * ((1 - x) ** (beta_param - 1)) / B\n",
    "\n",
    "# Proposal distribution: Uniform(0, 1)\n",
    "def proposal_pdf(x):\n",
    "    \"\"\"Uniform distribution PDF on [0, 1].\"\"\"\n",
    "    if np.isscalar(x):\n",
    "        return 1.0 if 0 <= x <= 1 else 0.0\n",
    "    return np.where((x >= 0) & (x <= 1), 1.0, 0.0)\n",
    "\n",
    "def sample_proposal():\n",
    "    \"\"\"Sample from the proposal distribution.\"\"\"\n",
    "    return np.random.uniform(0, 1)\n",
    "\n",
    "# Find the scaling constant M\n",
    "# For Beta distribution, the mode is at x = (alpha - 1) / (alpha + beta - 2)\n",
    "x_mode = (alpha - 1) / (alpha + beta_param - 2)\n",
    "M = target_pdf(x_mode) / proposal_pdf(x_mode)\n",
    "\n",
    "print(f\"Target distribution: Beta({alpha}, {beta_param})\")\n",
    "print(f\"Proposal distribution: Uniform(0, 1)\")\n",
    "print(f\"Mode of target: x = {x_mode:.4f}\")\n",
    "print(f\"Scaling constant M = {M:.4f}\")\n",
    "print(f\"Expected acceptance rate: {1/M:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampling(n_samples, target, proposal_sampler, proposal_pdf, M):\n",
    "    \"\"\"\n",
    "    Perform rejection sampling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Number of samples to generate\n",
    "    target : callable\n",
    "        Target PDF\n",
    "    proposal_sampler : callable\n",
    "        Function to sample from proposal distribution\n",
    "    proposal_pdf : callable\n",
    "        Proposal PDF\n",
    "    M : float\n",
    "        Scaling constant\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    samples : ndarray\n",
    "        Array of accepted samples\n",
    "    n_proposals : int\n",
    "        Total number of proposals made\n",
    "    accepted_points : list\n",
    "        List of (x, u*M*g(x)) for accepted points\n",
    "    rejected_points : list\n",
    "        List of (x, u*M*g(x)) for rejected points\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    n_proposals = 0\n",
    "    accepted_points = []\n",
    "    rejected_points = []\n",
    "    \n",
    "    while len(samples) < n_samples:\n",
    "        # Step 1: Sample from proposal\n",
    "        x = proposal_sampler()\n",
    "        n_proposals += 1\n",
    "        \n",
    "        # Step 2: Sample uniform for acceptance test\n",
    "        u = np.random.uniform(0, 1)\n",
    "        \n",
    "        # Step 3: Accept/reject\n",
    "        acceptance_threshold = target(x) / (M * proposal_pdf(x))\n",
    "        y_point = u * M * proposal_pdf(x)\n",
    "        \n",
    "        if u <= acceptance_threshold:\n",
    "            samples.append(x)\n",
    "            if len(accepted_points) < 500:  # Store limited points for visualization\n",
    "                accepted_points.append((x, y_point))\n",
    "        else:\n",
    "            if len(rejected_points) < 500:\n",
    "                rejected_points.append((x, y_point))\n",
    "    \n",
    "    return np.array(samples), n_proposals, accepted_points, rejected_points\n",
    "\n",
    "# Generate samples\n",
    "n_samples = 10000\n",
    "samples, n_proposals, accepted_pts, rejected_pts = rejection_sampling(\n",
    "    n_samples, target_pdf, sample_proposal, proposal_pdf, M\n",
    ")\n",
    "\n",
    "actual_acceptance_rate = n_samples / n_proposals\n",
    "print(f\"\\nGenerated {n_samples} samples\")\n",
    "print(f\"Total proposals: {n_proposals}\")\n",
    "print(f\"Actual acceptance rate: {actual_acceptance_rate:.4f}\")\n",
    "print(f\"Theoretical acceptance rate: {1/M:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We now create visualizations to illustrate:\n",
    "1. The geometry of rejection sampling\n",
    "2. The histogram of samples compared to the true distribution\n",
    "3. Convergence of sample statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Rejection sampling geometry\n",
    "ax1 = axes[0, 0]\n",
    "x_range = np.linspace(0, 1, 1000)\n",
    "ax1.fill_between(x_range, 0, M * proposal_pdf(x_range), alpha=0.3, color='blue', label=r'$M \\cdot g(x)$')\n",
    "ax1.fill_between(x_range, 0, target_pdf(x_range), alpha=0.5, color='red', label=r'$f(x)$')\n",
    "\n",
    "# Plot accepted and rejected points\n",
    "if accepted_pts:\n",
    "    acc_x, acc_y = zip(*accepted_pts[:200])\n",
    "    ax1.scatter(acc_x, acc_y, s=5, c='green', alpha=0.5, label='Accepted')\n",
    "if rejected_pts:\n",
    "    rej_x, rej_y = zip(*rejected_pts[:200])\n",
    "    ax1.scatter(rej_x, rej_y, s=5, c='red', alpha=0.5, label='Rejected')\n",
    "\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Rejection Sampling Geometry')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, M * 1.1)\n",
    "\n",
    "# Plot 2: Histogram vs true distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(samples, bins=50, density=True, alpha=0.7, color='steelblue', edgecolor='black', label='Samples')\n",
    "ax2.plot(x_range, target_pdf(x_range), 'r-', lw=2, label=f'Beta({alpha}, {beta_param})')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('Sample Histogram vs True Distribution')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: Convergence of mean\n",
    "ax3 = axes[1, 0]\n",
    "cumulative_mean = np.cumsum(samples) / np.arange(1, n_samples + 1)\n",
    "true_mean = alpha / (alpha + beta_param)\n",
    "ax3.plot(cumulative_mean, 'b-', alpha=0.7, label='Sample mean')\n",
    "ax3.axhline(y=true_mean, color='r', linestyle='--', lw=2, label=f'True mean = {true_mean:.4f}')\n",
    "ax3.set_xlabel('Number of samples')\n",
    "ax3.set_ylabel('Cumulative mean')\n",
    "ax3.set_title('Convergence of Sample Mean')\n",
    "ax3.legend()\n",
    "ax3.set_xscale('log')\n",
    "\n",
    "# Plot 4: Convergence of variance\n",
    "ax4 = axes[1, 1]\n",
    "cumulative_var = np.array([np.var(samples[:i+1]) for i in range(n_samples)])\n",
    "true_var = (alpha * beta_param) / ((alpha + beta_param)**2 * (alpha + beta_param + 1))\n",
    "ax4.plot(cumulative_var, 'b-', alpha=0.7, label='Sample variance')\n",
    "ax4.axhline(y=true_var, color='r', linestyle='--', lw=2, label=f'True variance = {true_var:.4f}')\n",
    "ax4.set_xlabel('Number of samples')\n",
    "ax4.set_ylabel('Cumulative variance')\n",
    "ax4.set_title('Convergence of Sample Variance')\n",
    "ax4.legend()\n",
    "ax4.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Validation\n",
    "\n",
    "We perform statistical tests to verify that our samples are indeed drawn from the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sample moments with theoretical moments\n",
    "true_mean = alpha / (alpha + beta_param)\n",
    "true_var = (alpha * beta_param) / ((alpha + beta_param)**2 * (alpha + beta_param + 1))\n",
    "true_skewness = (2 * (beta_param - alpha) * np.sqrt(alpha + beta_param + 1)) / \\\n",
    "                ((alpha + beta_param + 2) * np.sqrt(alpha * beta_param))\n",
    "\n",
    "sample_mean = np.mean(samples)\n",
    "sample_var = np.var(samples)\n",
    "sample_skewness = stats.skew(samples)\n",
    "\n",
    "print(\"Moment Comparison:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Statistic':<20} {'True':>12} {'Sample':>12} {'Error':>12}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Mean':<20} {true_mean:>12.6f} {sample_mean:>12.6f} {abs(true_mean - sample_mean):>12.6f}\")\n",
    "print(f\"{'Variance':<20} {true_var:>12.6f} {sample_var:>12.6f} {abs(true_var - sample_var):>12.6f}\")\n",
    "print(f\"{'Skewness':<20} {true_skewness:>12.6f} {sample_skewness:>12.6f} {abs(true_skewness - sample_skewness):>12.6f}\")\n",
    "\n",
    "# Kolmogorov-Smirnov test\n",
    "ks_statistic, ks_pvalue = stats.kstest(samples, 'beta', args=(alpha, beta_param))\n",
    "print(f\"\\nKolmogorov-Smirnov Test:\")\n",
    "print(f\"  Statistic: {ks_statistic:.6f}\")\n",
    "print(f\"  p-value: {ks_pvalue:.6f}\")\n",
    "print(f\"  Result: {'Fail to reject H0 (samples match distribution)' if ks_pvalue > 0.05 else 'Reject H0'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency Analysis: Comparing Proposal Distributions\n",
    "\n",
    "The efficiency of rejection sampling depends critically on how well the proposal distribution $g(x)$ approximates the target $f(x)$. We compare different proposal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare efficiency with different proposals\n",
    "def calculate_M_uniform():\n",
    "    \"\"\"Calculate M for uniform proposal.\"\"\"\n",
    "    x_mode = (alpha - 1) / (alpha + beta_param - 2)\n",
    "    return target_pdf(x_mode)\n",
    "\n",
    "def calculate_M_beta_approx():\n",
    "    \"\"\"Calculate M for Beta(2, 4) proposal (closer to target).\"\"\"\n",
    "    # Using Beta(2, 4) as proposal\n",
    "    alpha_prop, beta_prop = 2.0, 4.0\n",
    "    x_test = np.linspace(0.001, 0.999, 10000)\n",
    "    ratios = stats.beta.pdf(x_test, alpha, beta_param) / stats.beta.pdf(x_test, alpha_prop, beta_prop)\n",
    "    return np.max(ratios)\n",
    "\n",
    "M_uniform = calculate_M_uniform()\n",
    "M_beta = calculate_M_beta_approx()\n",
    "\n",
    "print(\"Efficiency Comparison:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Proposal Distribution':<25} {'M':>10} {'Acceptance Rate':>15}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Uniform(0, 1)':<25} {M_uniform:>10.4f} {1/M_uniform:>15.4f}\")\n",
    "print(f\"{'Beta(2, 4)':<25} {M_beta:>10.4f} {1/M_beta:>15.4f}\")\n",
    "print(f\"\\nUsing Beta(2, 4) is {M_uniform/M_beta:.2f}x more efficient than Uniform(0, 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook demonstrated the rejection sampling algorithm, a fundamental Monte Carlo technique with the following key properties:\n",
    "\n",
    "1. **Correctness**: The accepted samples provably follow the target distribution $f(x)$\n",
    "\n",
    "2. **Simplicity**: The algorithm is easy to implement and understand\n",
    "\n",
    "3. **Generality**: It works for any bounded density function\n",
    "\n",
    "4. **Efficiency trade-offs**: The choice of proposal distribution $g(x)$ dramatically affects efficiency\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Requires finding a suitable envelope $M \\cdot g(x) \\geq f(x)$\n",
    "- Can be inefficient in high dimensions (curse of dimensionality)\n",
    "- The scaling constant $M$ may be difficult to determine for complex distributions\n",
    "\n",
    "### Extensions\n",
    "\n",
    "More advanced methods that build on rejection sampling include:\n",
    "- **Adaptive rejection sampling** for log-concave densities\n",
    "- **Importance sampling** which reweights samples instead of rejecting\n",
    "- **Markov Chain Monte Carlo (MCMC)** methods for high-dimensional problems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
