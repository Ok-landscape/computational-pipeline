{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ant Colony Optimization (ACO)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Ant Colony Optimization (ACO) is a probabilistic technique for solving computational problems that can be reduced to finding good paths through graphs. This metaheuristic algorithm was introduced by Marco Dorigo in 1992, inspired by the foraging behavior of real ants.\n",
    "\n",
    "## Biological Inspiration\n",
    "\n",
    "In nature, ants initially wander randomly. Upon finding food, they return to their colony while laying down pheromone trails. Other ants follow these trails, and if they find food, they reinforce the trails with more pheromones. Over time, shorter paths accumulate more pheromones (since ants can traverse them more quickly), leading to the emergence of optimal routes.\n",
    "\n",
    "## Mathematical Formulation\n",
    "\n",
    "### Transition Probability\n",
    "\n",
    "The probability that ant $k$ at node $i$ will move to node $j$ is given by:\n",
    "\n",
    "$$p_{ij}^k = \\frac{[\\tau_{ij}]^\\alpha \\cdot [\\eta_{ij}]^\\beta}{\\sum_{l \\in \\mathcal{N}_i^k} [\\tau_{il}]^\\alpha \\cdot [\\eta_{il}]^\\beta}$$\n",
    "\n",
    "where:\n",
    "- $\\tau_{ij}$ is the pheromone intensity on edge $(i, j)$\n",
    "- $\\eta_{ij} = \\frac{1}{d_{ij}}$ is the heuristic desirability (inverse of distance)\n",
    "- $\\alpha$ is the pheromone influence parameter\n",
    "- $\\beta$ is the heuristic influence parameter\n",
    "- $\\mathcal{N}_i^k$ is the set of feasible nodes for ant $k$ at node $i$\n",
    "\n",
    "### Pheromone Update Rule\n",
    "\n",
    "After all ants complete their tours, the pheromone levels are updated according to:\n",
    "\n",
    "$$\\tau_{ij} \\leftarrow (1 - \\rho) \\cdot \\tau_{ij} + \\sum_{k=1}^{m} \\Delta\\tau_{ij}^k$$\n",
    "\n",
    "where:\n",
    "- $\\rho \\in (0, 1]$ is the pheromone evaporation rate\n",
    "- $m$ is the number of ants\n",
    "- $\\Delta\\tau_{ij}^k$ is the pheromone deposited by ant $k$\n",
    "\n",
    "### Pheromone Deposit\n",
    "\n",
    "The amount of pheromone deposited by ant $k$ on edge $(i, j)$ is:\n",
    "\n",
    "$$\\Delta\\tau_{ij}^k = \\begin{cases} \\frac{Q}{L_k} & \\text{if ant } k \\text{ uses edge } (i, j) \\\\ 0 & \\text{otherwise} \\end{cases}$$\n",
    "\n",
    "where:\n",
    "- $Q$ is a constant\n",
    "- $L_k$ is the total length of the tour constructed by ant $k$\n",
    "\n",
    "## Application: Traveling Salesman Problem (TSP)\n",
    "\n",
    "We will demonstrate ACO on the classic Traveling Salesman Problem, where the goal is to find the shortest possible route that visits each city exactly once and returns to the origin city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntColonyOptimizer:\n",
    "    \"\"\"\n",
    "    Ant Colony Optimization for solving the Traveling Salesman Problem.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, distances, n_ants, n_iterations, alpha=1.0, beta=2.0, \n",
    "                 rho=0.5, Q=100):\n",
    "        \"\"\"\n",
    "        Initialize the ACO algorithm.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        distances : ndarray\n",
    "            Distance matrix between cities\n",
    "        n_ants : int\n",
    "            Number of ants in the colony\n",
    "        n_iterations : int\n",
    "            Number of iterations to run\n",
    "        alpha : float\n",
    "            Pheromone influence parameter\n",
    "        beta : float\n",
    "            Heuristic influence parameter\n",
    "        rho : float\n",
    "            Pheromone evaporation rate\n",
    "        Q : float\n",
    "            Pheromone deposit constant\n",
    "        \"\"\"\n",
    "        self.distances = distances\n",
    "        self.n_cities = len(distances)\n",
    "        self.n_ants = n_ants\n",
    "        self.n_iterations = n_iterations\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.rho = rho\n",
    "        self.Q = Q\n",
    "        \n",
    "        # Initialize pheromone matrix with small positive values\n",
    "        self.pheromones = np.ones((self.n_cities, self.n_cities)) * 0.1\n",
    "        \n",
    "        # Compute heuristic matrix (inverse of distance)\n",
    "        # Add small epsilon to avoid division by zero\n",
    "        self.heuristic = 1.0 / (distances + 1e-10)\n",
    "        np.fill_diagonal(self.heuristic, 0)\n",
    "        \n",
    "        # Storage for results\n",
    "        self.best_tour = None\n",
    "        self.best_distance = np.inf\n",
    "        self.history = []\n",
    "        \n",
    "    def _select_next_city(self, current_city, visited):\n",
    "        \"\"\"\n",
    "        Select the next city based on transition probabilities.\n",
    "        \"\"\"\n",
    "        unvisited = [c for c in range(self.n_cities) if c not in visited]\n",
    "        \n",
    "        if not unvisited:\n",
    "            return None\n",
    "        \n",
    "        # Calculate transition probabilities\n",
    "        pheromone_vals = self.pheromones[current_city, unvisited]\n",
    "        heuristic_vals = self.heuristic[current_city, unvisited]\n",
    "        \n",
    "        probabilities = (pheromone_vals ** self.alpha) * (heuristic_vals ** self.beta)\n",
    "        probabilities = probabilities / probabilities.sum()\n",
    "        \n",
    "        # Select next city using roulette wheel selection\n",
    "        next_city = np.random.choice(unvisited, p=probabilities)\n",
    "        return next_city\n",
    "    \n",
    "    def _construct_tour(self, start_city):\n",
    "        \"\"\"\n",
    "        Construct a complete tour starting from a given city.\n",
    "        \"\"\"\n",
    "        tour = [start_city]\n",
    "        visited = {start_city}\n",
    "        \n",
    "        while len(tour) < self.n_cities:\n",
    "            current_city = tour[-1]\n",
    "            next_city = self._select_next_city(current_city, visited)\n",
    "            tour.append(next_city)\n",
    "            visited.add(next_city)\n",
    "        \n",
    "        return tour\n",
    "    \n",
    "    def _calculate_tour_distance(self, tour):\n",
    "        \"\"\"\n",
    "        Calculate the total distance of a tour.\n",
    "        \"\"\"\n",
    "        distance = 0\n",
    "        for i in range(len(tour)):\n",
    "            distance += self.distances[tour[i], tour[(i + 1) % len(tour)]]\n",
    "        return distance\n",
    "    \n",
    "    def _update_pheromones(self, tours, distances):\n",
    "        \"\"\"\n",
    "        Update pheromone levels based on ant tours.\n",
    "        \"\"\"\n",
    "        # Evaporation\n",
    "        self.pheromones *= (1 - self.rho)\n",
    "        \n",
    "        # Deposit pheromones\n",
    "        for tour, dist in zip(tours, distances):\n",
    "            deposit = self.Q / dist\n",
    "            for i in range(len(tour)):\n",
    "                city_a = tour[i]\n",
    "                city_b = tour[(i + 1) % len(tour)]\n",
    "                self.pheromones[city_a, city_b] += deposit\n",
    "                self.pheromones[city_b, city_a] += deposit\n",
    "    \n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Run the ACO optimization algorithm.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        best_tour : list\n",
    "            The best tour found\n",
    "        best_distance : float\n",
    "            The distance of the best tour\n",
    "        \"\"\"\n",
    "        for iteration in range(self.n_iterations):\n",
    "            tours = []\n",
    "            distances = []\n",
    "            \n",
    "            # Each ant constructs a tour\n",
    "            for ant in range(self.n_ants):\n",
    "                start_city = np.random.randint(self.n_cities)\n",
    "                tour = self._construct_tour(start_city)\n",
    "                distance = self._calculate_tour_distance(tour)\n",
    "                \n",
    "                tours.append(tour)\n",
    "                distances.append(distance)\n",
    "                \n",
    "                # Update best solution\n",
    "                if distance < self.best_distance:\n",
    "                    self.best_distance = distance\n",
    "                    self.best_tour = tour.copy()\n",
    "            \n",
    "            # Update pheromones\n",
    "            self._update_pheromones(tours, distances)\n",
    "            \n",
    "            # Record history\n",
    "            self.history.append({\n",
    "                'iteration': iteration,\n",
    "                'best_distance': self.best_distance,\n",
    "                'mean_distance': np.mean(distances),\n",
    "                'min_distance': np.min(distances)\n",
    "            })\n",
    "            \n",
    "            if (iteration + 1) % 20 == 0:\n",
    "                print(f\"Iteration {iteration + 1}: Best distance = {self.best_distance:.2f}\")\n",
    "        \n",
    "        return self.best_tour, self.best_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Data\n",
    "\n",
    "We will create a set of randomly distributed cities in a 2D plane and compute the Euclidean distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random city coordinates\n",
    "n_cities = 25\n",
    "cities = np.random.rand(n_cities, 2) * 100\n",
    "\n",
    "# Compute distance matrix\n",
    "def compute_distance_matrix(cities):\n",
    "    \"\"\"Compute Euclidean distance matrix between all cities.\"\"\"\n",
    "    n = len(cities)\n",
    "    distances = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            dist = np.sqrt(np.sum((cities[i] - cities[j]) ** 2))\n",
    "            distances[i, j] = dist\n",
    "            distances[j, i] = dist\n",
    "    return distances\n",
    "\n",
    "distances = compute_distance_matrix(cities)\n",
    "print(f\"Number of cities: {n_cities}\")\n",
    "print(f\"Distance matrix shape: {distances.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ACO Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run ACO\n",
    "aco = AntColonyOptimizer(\n",
    "    distances=distances,\n",
    "    n_ants=20,\n",
    "    n_iterations=100,\n",
    "    alpha=1.0,    # Pheromone influence\n",
    "    beta=2.0,     # Heuristic influence\n",
    "    rho=0.1,      # Evaporation rate\n",
    "    Q=100         # Pheromone deposit constant\n",
    ")\n",
    "\n",
    "best_tour, best_distance = aco.optimize()\n",
    "print(f\"\\nOptimization complete!\")\n",
    "print(f\"Best tour distance: {best_distance:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let's visualize the results: the convergence history, the pheromone intensity matrix, and the optimal tour found by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Convergence history\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "iterations = [h['iteration'] for h in aco.history]\n",
    "best_distances = [h['best_distance'] for h in aco.history]\n",
    "mean_distances = [h['mean_distance'] for h in aco.history]\n",
    "\n",
    "ax1.plot(iterations, best_distances, 'b-', linewidth=2, label='Best distance')\n",
    "ax1.plot(iterations, mean_distances, 'r--', alpha=0.7, label='Mean distance')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Tour Distance')\n",
    "ax1.set_title('ACO Convergence')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Pheromone intensity heatmap\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "im = ax2.imshow(aco.pheromones, cmap='hot', interpolation='nearest')\n",
    "ax2.set_xlabel('City')\n",
    "ax2.set_ylabel('City')\n",
    "ax2.set_title('Pheromone Intensity Matrix')\n",
    "plt.colorbar(im, ax=ax2, label='Pheromone level')\n",
    "\n",
    "# Plot 3: Best tour visualization\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "\n",
    "# Plot cities\n",
    "ax3.scatter(cities[:, 0], cities[:, 1], c='blue', s=100, zorder=5)\n",
    "for i, (x, y) in enumerate(cities):\n",
    "    ax3.annotate(str(i), (x, y), xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "# Plot tour\n",
    "tour_cities = [cities[i] for i in best_tour]\n",
    "tour_cities.append(tour_cities[0])  # Close the loop\n",
    "tour_cities = np.array(tour_cities)\n",
    "\n",
    "ax3.plot(tour_cities[:, 0], tour_cities[:, 1], 'r-', linewidth=2, alpha=0.7)\n",
    "ax3.set_xlabel('X coordinate')\n",
    "ax3.set_ylabel('Y coordinate')\n",
    "ax3.set_title(f'Best Tour (Distance: {best_distance:.2f})')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Pheromone trails on graph\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "# Normalize pheromones for visualization\n",
    "pheromone_max = aco.pheromones.max()\n",
    "pheromone_min = aco.pheromones.min()\n",
    "\n",
    "# Draw edges with thickness proportional to pheromone level\n",
    "for i in range(n_cities):\n",
    "    for j in range(i + 1, n_cities):\n",
    "        pheromone_level = aco.pheromones[i, j]\n",
    "        normalized = (pheromone_level - pheromone_min) / (pheromone_max - pheromone_min + 1e-10)\n",
    "        if normalized > 0.1:  # Only draw significant trails\n",
    "            ax4.plot([cities[i, 0], cities[j, 0]], \n",
    "                    [cities[i, 1], cities[j, 1]], \n",
    "                    'g-', alpha=normalized * 0.8, linewidth=normalized * 3)\n",
    "\n",
    "ax4.scatter(cities[:, 0], cities[:, 1], c='blue', s=100, zorder=5)\n",
    "ax4.set_xlabel('X coordinate')\n",
    "ax4.set_ylabel('Y coordinate')\n",
    "ax4.set_title('Pheromone Trail Intensity')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Results\n",
    "\n",
    "The visualization above shows:\n",
    "\n",
    "1. **Convergence Plot**: The algorithm rapidly improves in early iterations and then converges to a stable solution. The gap between mean and best distances indicates the exploration-exploitation balance.\n",
    "\n",
    "2. **Pheromone Matrix**: Brighter cells indicate stronger pheromone trails between cities. The diagonal is zero (no self-loops).\n",
    "\n",
    "3. **Best Tour**: The optimal route found by the algorithm, connecting all cities with minimal total distance.\n",
    "\n",
    "4. **Pheromone Trails**: Visual representation of the learned solution structure. Stronger trails (thicker, more opaque lines) indicate preferred connections.\n",
    "\n",
    "## Key Observations\n",
    "\n",
    "- **Parameter Sensitivity**: The balance between $\\alpha$ (pheromone influence) and $\\beta$ (heuristic influence) is crucial. Higher $\\beta$ values lead to more greedy behavior, while higher $\\alpha$ values emphasize learned information.\n",
    "\n",
    "- **Evaporation Rate**: The parameter $\\rho$ controls how quickly old information is forgotten. Too high evaporation leads to loss of good solutions; too low leads to premature convergence.\n",
    "\n",
    "- **Swarm Intelligence**: No single ant finds the optimal solution. Instead, the collective behavior of the colony, mediated through pheromone communication, gradually uncovers good solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ant Colony Optimization demonstrates how simple local rules can lead to complex global optimization behavior. The algorithm's strength lies in its:\n",
    "\n",
    "- **Positive feedback**: Good solutions are reinforced through pheromone deposits\n",
    "- **Negative feedback**: Evaporation allows the system to forget poor solutions\n",
    "- **Stochastic exploration**: Random elements prevent premature convergence\n",
    "- **Distributed computation**: Multiple ants work independently, making the algorithm naturally parallelizable\n",
    "\n",
    "ACO has been successfully applied to various combinatorial optimization problems including vehicle routing, scheduling, network optimization, and protein folding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
