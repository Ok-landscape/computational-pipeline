{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Limit Theorem Demonstration\n",
    "\n",
    "## Theoretical Foundation\n",
    "\n",
    "The **Central Limit Theorem (CLT)** is one of the most fundamental results in probability theory and statistics. It establishes that the distribution of sample means approaches a normal distribution as the sample size increases, regardless of the underlying population distribution.\n",
    "\n",
    "### Formal Statement\n",
    "\n",
    "Let $X_1, X_2, \\ldots, X_n$ be a sequence of independent and identically distributed (i.i.d.) random variables with:\n",
    "- Expected value: $\\mathbb{E}[X_i] = \\mu$\n",
    "- Variance: $\\text{Var}(X_i) = \\sigma^2 < \\infty$\n",
    "\n",
    "Define the sample mean as:\n",
    "$$\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$$\n",
    "\n",
    "Then the standardized sample mean converges in distribution to a standard normal:\n",
    "$$Z_n = \\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\xrightarrow{d} \\mathcal{N}(0, 1) \\quad \\text{as } n \\to \\infty$$\n",
    "\n",
    "Equivalently, for large $n$:\n",
    "$$\\bar{X}_n \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$$\n",
    "\n",
    "### Key Implications\n",
    "\n",
    "1. **Universality**: The CLT holds for any distribution with finite mean and variance\n",
    "2. **Convergence Rate**: The approximation improves as $\\mathcal{O}(1/\\sqrt{n})$\n",
    "3. **Practical Rule**: $n \\geq 30$ is often sufficient for reasonable approximation\n",
    "\n",
    "### Mathematical Intuition\n",
    "\n",
    "The CLT can be understood through characteristic functions. If $\\phi_X(t)$ is the characteristic function of $X$, then:\n",
    "$$\\phi_{Z_n}(t) = \\left[\\phi_X\\left(\\frac{t}{\\sigma\\sqrt{n}}\\right) e^{-it\\mu/(\\sigma\\sqrt{n})}\\right]^n \\to e^{-t^2/2}$$\n",
    "\n",
    "The right-hand side is the characteristic function of $\\mathcal{N}(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.special import factorial\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for publication-quality figures\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10,\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'legend.fontsize': 9,\n",
    "    'figure.figsize': (12, 10),\n",
    "    'figure.dpi': 100\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Design\n",
    "\n",
    "We will demonstrate the CLT using three distinctly non-normal distributions:\n",
    "\n",
    "1. **Uniform Distribution**: $X \\sim \\text{Uniform}(0, 1)$\n",
    "   - $\\mu = 0.5$, $\\sigma^2 = 1/12$\n",
    "\n",
    "2. **Exponential Distribution**: $X \\sim \\text{Exp}(\\lambda = 1)$\n",
    "   - $\\mu = 1$, $\\sigma^2 = 1$\n",
    "\n",
    "3. **Poisson Distribution**: $X \\sim \\text{Poisson}(\\lambda = 3)$\n",
    "   - $\\mu = 3$, $\\sigma^2 = 3$\n",
    "\n",
    "For each distribution, we compute sample means for various sample sizes $n \\in \\{1, 5, 30, 100\\}$ and compare the resulting distributions to the theoretical normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_clt(distribution_name, sample_generator, mu, sigma, sample_sizes, n_experiments=10000):\n",
    "    \"\"\"\n",
    "    Demonstrate CLT for a given distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    distribution_name : str\n",
    "        Name of the distribution for labeling\n",
    "    sample_generator : callable\n",
    "        Function that generates samples of size n\n",
    "    mu : float\n",
    "        True population mean\n",
    "    sigma : float\n",
    "        True population standard deviation\n",
    "    sample_sizes : list\n",
    "        List of sample sizes to test\n",
    "    n_experiments : int\n",
    "        Number of sample means to compute\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing sample means for each sample size\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for n in sample_sizes:\n",
    "        # Generate n_experiments samples, each of size n\n",
    "        samples = sample_generator(size=(n_experiments, n))\n",
    "        # Compute sample means\n",
    "        sample_means = np.mean(samples, axis=1)\n",
    "        # Standardize\n",
    "        standardized = (sample_means - mu) / (sigma / np.sqrt(n))\n",
    "        results[n] = {\n",
    "            'means': sample_means,\n",
    "            'standardized': standardized\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define distributions and their parameters\n",
    "distributions = {\n",
    "    'Uniform(0, 1)': {\n",
    "        'generator': lambda size: np.random.uniform(0, 1, size),\n",
    "        'mu': 0.5,\n",
    "        'sigma': np.sqrt(1/12)\n",
    "    },\n",
    "    'Exponential(λ=1)': {\n",
    "        'generator': lambda size: np.random.exponential(1, size),\n",
    "        'mu': 1.0,\n",
    "        'sigma': 1.0\n",
    "    },\n",
    "    'Poisson(λ=3)': {\n",
    "        'generator': lambda size: np.random.poisson(3, size),\n",
    "        'mu': 3.0,\n",
    "        'sigma': np.sqrt(3)\n",
    "    }\n",
    "}\n",
    "\n",
    "sample_sizes = [1, 5, 30, 100]\n",
    "n_experiments = 10000\n",
    "\n",
    "# Run experiments\n",
    "all_results = {}\n",
    "for name, params in distributions.items():\n",
    "    all_results[name] = demonstrate_clt(\n",
    "        name,\n",
    "        params['generator'],\n",
    "        params['mu'],\n",
    "        params['sigma'],\n",
    "        sample_sizes,\n",
    "        n_experiments\n",
    "    )\n",
    "    print(f\"Completed experiments for {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Analysis\n",
    "\n",
    "We now visualize how the distribution of standardized sample means converges to the standard normal $\\mathcal{N}(0, 1)$ as $n$ increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(3, 4, figsize=(14, 10))\n",
    "fig.suptitle('Central Limit Theorem Demonstration\\n'\n",
    "             'Convergence of Standardized Sample Means to N(0, 1)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "# Standard normal for comparison\n",
    "x_norm = np.linspace(-4, 4, 1000)\n",
    "y_norm = stats.norm.pdf(x_norm)\n",
    "\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01']\n",
    "\n",
    "for i, (dist_name, results) in enumerate(all_results.items()):\n",
    "    for j, n in enumerate(sample_sizes):\n",
    "        ax = axes[i, j]\n",
    "        \n",
    "        # Plot histogram of standardized sample means\n",
    "        standardized = results[n]['standardized']\n",
    "        ax.hist(standardized, bins=50, density=True, alpha=0.7, \n",
    "                color=colors[i], edgecolor='black', linewidth=0.5,\n",
    "                label=f'Sample means\\n(n={n})')\n",
    "        \n",
    "        # Overlay standard normal\n",
    "        ax.plot(x_norm, y_norm, 'k-', linewidth=2, label='N(0, 1)')\n",
    "        \n",
    "        # Calculate and display goodness-of-fit\n",
    "        ks_stat, ks_pval = stats.kstest(standardized, 'norm')\n",
    "        \n",
    "        ax.set_xlim(-4, 4)\n",
    "        ax.set_ylim(0, 0.55)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_title(f'n = {n}', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f'{dist_name}\\nDensity', fontsize=10)\n",
    "        \n",
    "        if i == 2:\n",
    "            ax.set_xlabel('Standardized Value', fontsize=10)\n",
    "        \n",
    "        # Add KS test p-value\n",
    "        ax.text(0.95, 0.95, f'KS p={ks_pval:.3f}', \n",
    "                transform=ax.transAxes, fontsize=8,\n",
    "                verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure saved to plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Analysis: Convergence Metrics\n",
    "\n",
    "To rigorously assess convergence, we compute several statistical measures:\n",
    "\n",
    "1. **Kolmogorov-Smirnov (KS) Statistic**: Maximum deviation between empirical and theoretical CDFs\n",
    "2. **Skewness**: Third standardized moment (should approach 0)\n",
    "3. **Excess Kurtosis**: Fourth standardized moment minus 3 (should approach 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CONVERGENCE ANALYSIS: Central Limit Theorem\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for dist_name, results in all_results.items():\n",
    "    print(f\"\\n{dist_name}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'n':>6} {'KS Stat':>10} {'p-value':>10} {'Skewness':>10} {'Ex. Kurt':>10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for n in sample_sizes:\n",
    "        standardized = results[n]['standardized']\n",
    "        \n",
    "        ks_stat, ks_pval = stats.kstest(standardized, 'norm')\n",
    "        skewness = stats.skew(standardized)\n",
    "        kurtosis = stats.kurtosis(standardized)  # Excess kurtosis\n",
    "        \n",
    "        print(f\"{n:>6} {ks_stat:>10.4f} {ks_pval:>10.4f} {skewness:>10.4f} {kurtosis:>10.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Note: For N(0,1), skewness = 0 and excess kurtosis = 0\")\n",
    "print(\"KS p-value > 0.05 suggests consistency with normal distribution\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berry-Esseen Bound\n",
    "\n",
    "The **Berry-Esseen theorem** provides a quantitative bound on the rate of convergence in the CLT:\n",
    "\n",
    "$$\\sup_{x \\in \\mathbb{R}} |F_n(x) - \\Phi(x)| \\leq \\frac{C \\cdot \\rho}{\\sigma^3 \\sqrt{n}}$$\n",
    "\n",
    "where:\n",
    "- $F_n(x)$ is the CDF of the standardized sample mean\n",
    "- $\\Phi(x)$ is the standard normal CDF\n",
    "- $\\rho = \\mathbb{E}[|X - \\mu|^3]$ is the third absolute central moment\n",
    "- $C \\leq 0.4748$ is a universal constant\n",
    "\n",
    "This shows that convergence is $\\mathcal{O}(1/\\sqrt{n})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Berry-Esseen bound for Exponential distribution\n",
    "# For Exp(1): μ = 1, σ = 1, E[|X-μ|³] = 2\n",
    "\n",
    "print(\"\\nBerry-Esseen Bound Analysis (Exponential Distribution)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "C_BE = 0.4748  # Berry-Esseen constant\n",
    "rho_exp = 2  # Third absolute central moment for Exp(1)\n",
    "sigma_exp = 1\n",
    "\n",
    "print(f\"{'n':>6} {'Theoretical':>15} {'Empirical KS':>15} {'Ratio':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for n in sample_sizes:\n",
    "    # Theoretical Berry-Esseen bound\n",
    "    be_bound = C_BE * rho_exp / (sigma_exp**3 * np.sqrt(n))\n",
    "    \n",
    "    # Empirical KS statistic\n",
    "    ks_stat, _ = stats.kstest(all_results['Exponential(λ=1)'][n]['standardized'], 'norm')\n",
    "    \n",
    "    ratio = ks_stat / be_bound if be_bound > 0 else 0\n",
    "    \n",
    "    print(f\"{n:>6} {be_bound:>15.4f} {ks_stat:>15.4f} {ratio:>10.4f}\")\n",
    "\n",
    "print(\"\\nNote: Empirical KS should be less than theoretical bound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This demonstration confirms the Central Limit Theorem through empirical simulation:\n",
    "\n",
    "1. **Universality**: All three distributions (Uniform, Exponential, Poisson) show convergence to normality despite their different shapes\n",
    "\n",
    "2. **Rate of Convergence**: \n",
    "   - $n = 1$: Distribution matches original (no convergence)\n",
    "   - $n = 5$: Beginning of convergence visible\n",
    "   - $n = 30$: Good approximation to normal (\"rule of 30\")\n",
    "   - $n = 100$: Excellent agreement with $\\mathcal{N}(0, 1)$\n",
    "\n",
    "3. **Practical Implications**:\n",
    "   - Sample means are approximately normal even for small $n$\n",
    "   - This justifies the widespread use of $t$-tests and confidence intervals\n",
    "   - The CLT underpins much of classical statistical inference\n",
    "\n",
    "The CLT remains one of the most powerful tools in statistics, enabling robust inference without requiring knowledge of the underlying population distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
