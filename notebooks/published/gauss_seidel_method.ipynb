{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Gauss-Seidel Method\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The **Gauss-Seidel method** is an iterative technique for solving systems of linear equations of the form:\n",
    "\n",
    "$$\\mathbf{A}\\mathbf{x} = \\mathbf{b}$$\n",
    "\n",
    "where $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is a coefficient matrix, $\\mathbf{x} \\in \\mathbb{R}^n$ is the unknown vector, and $\\mathbf{b} \\in \\mathbb{R}^n$ is the constant vector.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### Matrix Decomposition\n",
    "\n",
    "The Gauss-Seidel method decomposes the matrix $\\mathbf{A}$ into:\n",
    "\n",
    "$$\\mathbf{A} = \\mathbf{L} + \\mathbf{D} + \\mathbf{U}$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{L}$ is the strictly lower triangular part of $\\mathbf{A}$\n",
    "- $\\mathbf{D}$ is the diagonal of $\\mathbf{A}$\n",
    "- $\\mathbf{U}$ is the strictly upper triangular part of $\\mathbf{A}$\n",
    "\n",
    "### Iteration Formula\n",
    "\n",
    "The iterative scheme is:\n",
    "\n",
    "$$(\\mathbf{L} + \\mathbf{D})\\mathbf{x}^{(k+1)} = \\mathbf{b} - \\mathbf{U}\\mathbf{x}^{(k)}$$\n",
    "\n",
    "Component-wise, this becomes:\n",
    "\n",
    "$$x_i^{(k+1)} = \\frac{1}{a_{ii}}\\left(b_i - \\sum_{j=1}^{i-1} a_{ij}x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij}x_j^{(k)}\\right)$$\n",
    "\n",
    "The key distinction from the Jacobi method is that Gauss-Seidel uses the **most recently computed values** $x_j^{(k+1)}$ for $j < i$ within the same iteration.\n",
    "\n",
    "### Convergence Criteria\n",
    "\n",
    "The method converges if any of the following conditions hold:\n",
    "\n",
    "1. **Strict diagonal dominance**: $|a_{ii}| > \\sum_{j \\neq i} |a_{ij}|$ for all $i$\n",
    "2. **Symmetric positive definite**: $\\mathbf{A} = \\mathbf{A}^T$ and all eigenvalues are positive\n",
    "3. **Spectral radius**: $\\rho(\\mathbf{G}) < 1$ where $\\mathbf{G} = -(\\mathbf{L}+\\mathbf{D})^{-1}\\mathbf{U}$ is the iteration matrix\n",
    "\n",
    "### Error Analysis\n",
    "\n",
    "The error at iteration $k$ is:\n",
    "\n",
    "$$\\mathbf{e}^{(k)} = \\mathbf{x}^{(k)} - \\mathbf{x}^*$$\n",
    "\n",
    "where $\\mathbf{x}^*$ is the true solution. The error propagates as:\n",
    "\n",
    "$$\\mathbf{e}^{(k+1)} = \\mathbf{G}\\mathbf{e}^{(k)}$$\n",
    "\n",
    "The convergence rate is determined by $\\rho(\\mathbf{G})$, with faster convergence when $\\rho(\\mathbf{G}) \\ll 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm, solve\n",
    "\n",
    "def gauss_seidel(A, b, x0=None, tol=1e-10, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Solve the system Ax = b using the Gauss-Seidel method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    A : ndarray\n",
    "        Coefficient matrix (n x n)\n",
    "    b : ndarray\n",
    "        Right-hand side vector (n,)\n",
    "    x0 : ndarray, optional\n",
    "        Initial guess (default: zeros)\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    max_iterations : int\n",
    "        Maximum number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    x : ndarray\n",
    "        Solution vector\n",
    "    residuals : list\n",
    "        History of residual norms\n",
    "    iterations : int\n",
    "        Number of iterations performed\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    x = x0.copy() if x0 is not None else np.zeros(n)\n",
    "    residuals = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        x_old = x.copy()\n",
    "        \n",
    "        for i in range(n):\n",
    "            # Sum of a_ij * x_j for j < i (using new values)\n",
    "            sum_lower = np.dot(A[i, :i], x[:i])\n",
    "            # Sum of a_ij * x_j for j > i (using old values)\n",
    "            sum_upper = np.dot(A[i, i+1:], x_old[i+1:])\n",
    "            # Update x_i\n",
    "            x[i] = (b[i] - sum_lower - sum_upper) / A[i, i]\n",
    "        \n",
    "        # Compute residual norm\n",
    "        residual = norm(b - A @ x)\n",
    "        residuals.append(residual)\n",
    "        \n",
    "        # Check convergence\n",
    "        if residual < tol:\n",
    "            return x, residuals, iteration + 1\n",
    "    \n",
    "    return x, residuals, max_iterations\n",
    "\n",
    "def is_diagonally_dominant(A):\n",
    "    \"\"\"Check if matrix A is strictly diagonally dominant.\"\"\"\n",
    "    n = A.shape[0]\n",
    "    for i in range(n):\n",
    "        diagonal = abs(A[i, i])\n",
    "        off_diagonal_sum = sum(abs(A[i, j]) for j in range(n) if j != i)\n",
    "        if diagonal <= off_diagonal_sum:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Diagonally Dominant System\n",
    "\n",
    "Consider the system:\n",
    "\n",
    "$$\\begin{pmatrix} 4 & -1 & 0 & 0 \\\\ -1 & 4 & -1 & 0 \\\\ 0 & -1 & 4 & -1 \\\\ 0 & 0 & -1 & 3 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = \\begin{pmatrix} 15 \\\\ 10 \\\\ 10 \\\\ 10 \\end{pmatrix}$$\n",
    "\n",
    "This matrix is diagonally dominant, guaranteeing convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the diagonally dominant system\n",
    "A1 = np.array([\n",
    "    [4, -1, 0, 0],\n",
    "    [-1, 4, -1, 0],\n",
    "    [0, -1, 4, -1],\n",
    "    [0, 0, -1, 3]\n",
    "], dtype=float)\n",
    "\n",
    "b1 = np.array([15, 10, 10, 10], dtype=float)\n",
    "\n",
    "# Check diagonal dominance\n",
    "print(f\"Matrix is diagonally dominant: {is_diagonally_dominant(A1)}\")\n",
    "\n",
    "# Solve using Gauss-Seidel\n",
    "x1, residuals1, iters1 = gauss_seidel(A1, b1, tol=1e-10)\n",
    "\n",
    "# Compute exact solution for comparison\n",
    "x_exact1 = solve(A1, b1)\n",
    "\n",
    "print(f\"\\nGauss-Seidel solution: {x1}\")\n",
    "print(f\"Exact solution: {x_exact1}\")\n",
    "print(f\"Error norm: {norm(x1 - x_exact1):.2e}\")\n",
    "print(f\"Iterations: {iters1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Larger System - Heat Equation Discretization\n",
    "\n",
    "A common application is solving the 1D Poisson equation:\n",
    "\n",
    "$$-\\frac{d^2 u}{dx^2} = f(x)$$\n",
    "\n",
    "Discretizing with finite differences yields a tridiagonal system with structure:\n",
    "\n",
    "$$\\frac{1}{h^2}\\begin{pmatrix} 2 & -1 & & \\\\ -1 & 2 & -1 & \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & -1 & 2 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a tridiagonal system (1D Poisson equation)\n",
    "n = 50\n",
    "A2 = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "    A2[i, i] = 2.0\n",
    "    if i > 0:\n",
    "        A2[i, i-1] = -1.0\n",
    "    if i < n-1:\n",
    "        A2[i, i+1] = -1.0\n",
    "\n",
    "# Right-hand side (source term)\n",
    "b2 = np.ones(n)\n",
    "\n",
    "# Solve\n",
    "x2, residuals2, iters2 = gauss_seidel(A2, b2, tol=1e-10)\n",
    "x_exact2 = solve(A2, b2)\n",
    "\n",
    "print(f\"System size: {n}x{n}\")\n",
    "print(f\"Error norm: {norm(x2 - x_exact2):.2e}\")\n",
    "print(f\"Iterations: {iters2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Gauss-Seidel vs Jacobi Method\n",
    "\n",
    "The Gauss-Seidel method typically converges faster than the Jacobi method because it uses updated values immediately. Let's compare their convergence rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(A, b, x0=None, tol=1e-10, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Solve Ax = b using the Jacobi method for comparison.\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    x = x0.copy() if x0 is not None else np.zeros(n)\n",
    "    residuals = []\n",
    "    \n",
    "    D_inv = 1.0 / np.diag(A)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        x_new = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            sum_off_diag = np.dot(A[i, :], x) - A[i, i] * x[i]\n",
    "            x_new[i] = (b[i] - sum_off_diag) * D_inv[i]\n",
    "        \n",
    "        x = x_new\n",
    "        residual = norm(b - A @ x)\n",
    "        residuals.append(residual)\n",
    "        \n",
    "        if residual < tol:\n",
    "            return x, residuals, iteration + 1\n",
    "    \n",
    "    return x, residuals, max_iterations\n",
    "\n",
    "# Compare on the tridiagonal system\n",
    "x_gs, res_gs, iters_gs = gauss_seidel(A2, b2, tol=1e-10)\n",
    "x_jac, res_jac, iters_jac = jacobi(A2, b2, tol=1e-10)\n",
    "\n",
    "print(f\"Gauss-Seidel iterations: {iters_gs}\")\n",
    "print(f\"Jacobi iterations: {iters_jac}\")\n",
    "print(f\"Speedup factor: {iters_jac / iters_gs:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Analysis and Visualization\n",
    "\n",
    "Let's analyze and visualize the convergence behavior of both methods, and examine how the spectral radius affects convergence rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iteration_matrix_gs(A):\n",
    "    \"\"\"Compute the Gauss-Seidel iteration matrix G = -(L+D)^{-1}U.\"\"\"\n",
    "    n = A.shape[0]\n",
    "    L = np.tril(A, -1)\n",
    "    D = np.diag(np.diag(A))\n",
    "    U = np.triu(A, 1)\n",
    "    LD_inv = np.linalg.inv(L + D)\n",
    "    return -LD_inv @ U\n",
    "\n",
    "def compute_iteration_matrix_jacobi(A):\n",
    "    \"\"\"Compute the Jacobi iteration matrix G = D^{-1}(L+U).\"\"\"\n",
    "    D_inv = np.diag(1.0 / np.diag(A))\n",
    "    L_plus_U = A - np.diag(np.diag(A))\n",
    "    return -D_inv @ L_plus_U\n",
    "\n",
    "# Compute spectral radii\n",
    "G_gs = compute_iteration_matrix_gs(A2)\n",
    "G_jac = compute_iteration_matrix_jacobi(A2)\n",
    "\n",
    "rho_gs = max(abs(np.linalg.eigvals(G_gs)))\n",
    "rho_jac = max(abs(np.linalg.eigvals(G_jac)))\n",
    "\n",
    "print(f\"Spectral radius (Gauss-Seidel): {rho_gs:.6f}\")\n",
    "print(f\"Spectral radius (Jacobi): {rho_jac:.6f}\")\n",
    "print(f\"\\nTheoretical convergence rate ratio: {np.log(rho_jac)/np.log(rho_gs):.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Convergence comparison\n",
    "ax1 = axes[0, 0]\n",
    "ax1.semilogy(res_gs, 'b-', linewidth=2, label='Gauss-Seidel')\n",
    "ax1.semilogy(res_jac, 'r--', linewidth=2, label='Jacobi')\n",
    "ax1.set_xlabel('Iteration', fontsize=12)\n",
    "ax1.set_ylabel('Residual Norm', fontsize=12)\n",
    "ax1.set_title('Convergence Comparison', fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Solution profile\n",
    "ax2 = axes[0, 1]\n",
    "x_vals = np.linspace(0, 1, n)\n",
    "ax2.plot(x_vals, x2, 'b-', linewidth=2, label='Gauss-Seidel')\n",
    "ax2.plot(x_vals, x_exact2, 'k--', linewidth=1.5, label='Exact')\n",
    "ax2.set_xlabel('x', fontsize=12)\n",
    "ax2.set_ylabel('u(x)', fontsize=12)\n",
    "ax2.set_title('Solution Profile (1D Poisson)', fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Spectral analysis - eigenvalues of iteration matrices\n",
    "ax3 = axes[1, 0]\n",
    "eig_gs = np.linalg.eigvals(G_gs)\n",
    "eig_jac = np.linalg.eigvals(G_jac)\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "ax3.plot(np.cos(theta), np.sin(theta), 'k-', linewidth=1, label='Unit circle')\n",
    "ax3.scatter(eig_gs.real, eig_gs.imag, c='blue', s=30, alpha=0.6, label='Gauss-Seidel')\n",
    "ax3.scatter(eig_jac.real, eig_jac.imag, c='red', s=30, alpha=0.6, label='Jacobi')\n",
    "ax3.set_xlabel('Real', fontsize=12)\n",
    "ax3.set_ylabel('Imaginary', fontsize=12)\n",
    "ax3.set_title('Eigenvalues of Iteration Matrices', fontsize=14)\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.set_aspect('equal')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Convergence rate vs system size\n",
    "ax4 = axes[1, 1]\n",
    "sizes = [10, 20, 30, 50, 75, 100]\n",
    "iters_gs_list = []\n",
    "iters_jac_list = []\n",
    "\n",
    "for size in sizes:\n",
    "    # Generate tridiagonal system\n",
    "    A_test = np.zeros((size, size))\n",
    "    for i in range(size):\n",
    "        A_test[i, i] = 2.0\n",
    "        if i > 0:\n",
    "            A_test[i, i-1] = -1.0\n",
    "        if i < size-1:\n",
    "            A_test[i, i+1] = -1.0\n",
    "    b_test = np.ones(size)\n",
    "    \n",
    "    _, _, it_gs = gauss_seidel(A_test, b_test, tol=1e-8, max_iterations=5000)\n",
    "    _, _, it_jac = jacobi(A_test, b_test, tol=1e-8, max_iterations=5000)\n",
    "    \n",
    "    iters_gs_list.append(it_gs)\n",
    "    iters_jac_list.append(it_jac)\n",
    "\n",
    "ax4.plot(sizes, iters_gs_list, 'b-o', linewidth=2, markersize=8, label='Gauss-Seidel')\n",
    "ax4.plot(sizes, iters_jac_list, 'r--s', linewidth=2, markersize=8, label='Jacobi')\n",
    "ax4.set_xlabel('System Size (n)', fontsize=12)\n",
    "ax4.set_ylabel('Iterations to Converge', fontsize=12)\n",
    "ax4.set_title('Iterations vs System Size', fontsize=14)\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Observations\n",
    "\n",
    "1. **Convergence Speed**: Gauss-Seidel typically converges in approximately half the iterations of Jacobi for tridiagonal systems. This is because the spectral radius satisfies $\\rho_{GS} \\approx \\rho_J^2$.\n",
    "\n",
    "2. **Memory Efficiency**: Gauss-Seidel requires only one vector for storage (in-place updates), while Jacobi needs two vectors.\n",
    "\n",
    "3. **Scalability**: Both methods show $O(n^2)$ iteration growth for tridiagonal systems, but Gauss-Seidel maintains its advantage at all scales.\n",
    "\n",
    "4. **Parallelization**: Jacobi is naturally parallelizable (all updates independent), while Gauss-Seidel has sequential dependencies.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The Gauss-Seidel method is a robust iterative solver that offers improved convergence over the Jacobi method for many linear systems. Its convergence is guaranteed for diagonally dominant and symmetric positive definite matrices, making it suitable for many scientific computing applications, particularly those arising from discretized partial differential equations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
