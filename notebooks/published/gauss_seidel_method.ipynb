{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gauss-Seidel Iterative Method for Linear Systems\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The **Gauss-Seidel method** is an iterative technique for solving systems of linear equations of the form:\n",
    "\n",
    "$$\\mathbf{A}\\mathbf{x} = \\mathbf{b}$$\n",
    "\n",
    "where $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is the coefficient matrix, $\\mathbf{x} \\in \\mathbb{R}^n$ is the solution vector, and $\\mathbf{b} \\in \\mathbb{R}^n$ is the right-hand side vector.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### Matrix Decomposition\n",
    "\n",
    "The Gauss-Seidel method decomposes the matrix $\\mathbf{A}$ as:\n",
    "\n",
    "$$\\mathbf{A} = \\mathbf{L} + \\mathbf{D} + \\mathbf{U}$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{L}$ is the strictly lower triangular part of $\\mathbf{A}$\n",
    "- $\\mathbf{D}$ is the diagonal of $\\mathbf{A}$\n",
    "- $\\mathbf{U}$ is the strictly upper triangular part of $\\mathbf{A}$\n",
    "\n",
    "### Iteration Formula\n",
    "\n",
    "The system $(\\mathbf{L} + \\mathbf{D} + \\mathbf{U})\\mathbf{x} = \\mathbf{b}$ is rearranged as:\n",
    "\n",
    "$$(\\mathbf{L} + \\mathbf{D})\\mathbf{x}^{(k+1)} = \\mathbf{b} - \\mathbf{U}\\mathbf{x}^{(k)}$$\n",
    "\n",
    "The key insight of Gauss-Seidel is that when computing $x_i^{(k+1)}$, we use the **already updated** values $x_1^{(k+1)}, x_2^{(k+1)}, \\ldots, x_{i-1}^{(k+1)}$ from the current iteration.\n",
    "\n",
    "For each component $i = 1, 2, \\ldots, n$:\n",
    "\n",
    "$$x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \\right)$$\n",
    "\n",
    "### Convergence Criteria\n",
    "\n",
    "The Gauss-Seidel method converges if any of the following conditions hold:\n",
    "\n",
    "1. **Strictly Diagonally Dominant**: $|a_{ii}| > \\sum_{j \\neq i} |a_{ij}|$ for all $i$\n",
    "\n",
    "2. **Symmetric Positive Definite**: $\\mathbf{A} = \\mathbf{A}^T$ and $\\mathbf{x}^T \\mathbf{A} \\mathbf{x} > 0$ for all $\\mathbf{x} \\neq \\mathbf{0}$\n",
    "\n",
    "3. **Spectral Radius**: $\\rho(\\mathbf{T}_{GS}) < 1$ where $\\mathbf{T}_{GS} = -(\\mathbf{L} + \\mathbf{D})^{-1}\\mathbf{U}$\n",
    "\n",
    "### Comparison with Jacobi Method\n",
    "\n",
    "Unlike the Jacobi method which uses only values from the previous iteration, Gauss-Seidel incorporates newly computed values immediately. This typically results in faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We implement the Gauss-Seidel method with convergence tracking to visualize the iterative improvement of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel(A, b, x0=None, tol=1e-10, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Solve Ax = b using the Gauss-Seidel iterative method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    A : ndarray\n",
    "        Coefficient matrix (n x n)\n",
    "    b : ndarray\n",
    "        Right-hand side vector (n,)\n",
    "    x0 : ndarray, optional\n",
    "        Initial guess (default: zeros)\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    max_iterations : int\n",
    "        Maximum number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    x : ndarray\n",
    "        Solution vector\n",
    "    residuals : list\n",
    "        Residual norm at each iteration\n",
    "    errors : list\n",
    "        Solution error norm at each iteration\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    x = np.zeros(n) if x0 is None else x0.copy()\n",
    "    \n",
    "    # Compute exact solution for error tracking\n",
    "    x_exact = np.linalg.solve(A, b)\n",
    "    \n",
    "    residuals = []\n",
    "    errors = []\n",
    "    \n",
    "    for k in range(max_iterations):\n",
    "        x_old = x.copy()\n",
    "        \n",
    "        # Gauss-Seidel iteration\n",
    "        for i in range(n):\n",
    "            # Sum of a_ij * x_j for j < i (using new values)\n",
    "            sum1 = np.dot(A[i, :i], x[:i])\n",
    "            # Sum of a_ij * x_j for j > i (using old values)\n",
    "            sum2 = np.dot(A[i, i+1:], x_old[i+1:])\n",
    "            # Update x_i\n",
    "            x[i] = (b[i] - sum1 - sum2) / A[i, i]\n",
    "        \n",
    "        # Compute residual and error\n",
    "        residual = norm(b - A @ x)\n",
    "        error = norm(x - x_exact)\n",
    "        \n",
    "        residuals.append(residual)\n",
    "        errors.append(error)\n",
    "        \n",
    "        # Check convergence\n",
    "        if residual < tol:\n",
    "            print(f\"Converged after {k+1} iterations\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Maximum iterations ({max_iterations}) reached\")\n",
    "    \n",
    "    return x, residuals, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case: Diagonally Dominant System\n",
    "\n",
    "We construct a strictly diagonally dominant matrix to ensure convergence. For a $5 \\times 5$ system, we create:\n",
    "\n",
    "$$a_{ii} = 10, \\quad |a_{ij}| \\leq 1 \\text{ for } j \\neq i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a diagonally dominant matrix\n",
    "n = 5\n",
    "A = np.random.rand(n, n)  # Random entries in [0, 1]\n",
    "A = A + A.T  # Make symmetric\n",
    "A = A + n * np.eye(n)  # Make diagonally dominant\n",
    "\n",
    "# Create right-hand side\n",
    "b = np.random.rand(n)\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nVector b:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify diagonal dominance\n",
    "def check_diagonal_dominance(A):\n",
    "    n = A.shape[0]\n",
    "    for i in range(n):\n",
    "        diag = abs(A[i, i])\n",
    "        off_diag = sum(abs(A[i, j]) for j in range(n) if j != i)\n",
    "        if diag <= off_diag:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(f\"Matrix is strictly diagonally dominant: {check_diagonal_dominance(A)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve using Gauss-Seidel\n",
    "x_gs, residuals, errors = gauss_seidel(A, b, tol=1e-12)\n",
    "\n",
    "# Compare with direct solution\n",
    "x_exact = np.linalg.solve(A, b)\n",
    "\n",
    "print(\"\\nGauss-Seidel solution:\")\n",
    "print(x_gs)\n",
    "print(\"\\nExact solution:\")\n",
    "print(x_exact)\n",
    "print(f\"\\nFinal error: {norm(x_gs - x_exact):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Analysis\n",
    "\n",
    "We visualize the convergence behavior by plotting:\n",
    "1. Residual norm $\\|\\mathbf{b} - \\mathbf{A}\\mathbf{x}^{(k)}\\|$ vs iteration\n",
    "2. Solution error $\\|\\mathbf{x}^{(k)} - \\mathbf{x}^*\\|$ vs iteration\n",
    "\n",
    "The linear decrease on a semi-log plot indicates geometric convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convergence plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Residual plot\n",
    "axes[0].semilogy(residuals, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "axes[0].set_xlabel('Iteration', fontsize=12)\n",
    "axes[0].set_ylabel(r'$\\|\\mathbf{b} - \\mathbf{A}\\mathbf{x}^{(k)}\\|$', fontsize=12)\n",
    "axes[0].set_title('Residual Convergence', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Error plot\n",
    "axes[1].semilogy(errors, 'r-', linewidth=2, marker='s', markersize=4)\n",
    "axes[1].set_xlabel('Iteration', fontsize=12)\n",
    "axes[1].set_ylabel(r'$\\|\\mathbf{x}^{(k)} - \\mathbf{x}^*\\|$', fontsize=12)\n",
    "axes[1].set_title('Solution Error Convergence', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Plot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Gauss-Seidel vs Jacobi\n",
    "\n",
    "We compare the convergence rates of Gauss-Seidel and Jacobi methods on the same system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(A, b, x0=None, tol=1e-10, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Solve Ax = b using the Jacobi iterative method.\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    x = np.zeros(n) if x0 is None else x0.copy()\n",
    "    x_exact = np.linalg.solve(A, b)\n",
    "    \n",
    "    residuals = []\n",
    "    errors = []\n",
    "    \n",
    "    for k in range(max_iterations):\n",
    "        x_new = np.zeros(n)\n",
    "        \n",
    "        # Jacobi iteration (uses only old values)\n",
    "        for i in range(n):\n",
    "            sum_term = np.dot(A[i, :], x) - A[i, i] * x[i]\n",
    "            x_new[i] = (b[i] - sum_term) / A[i, i]\n",
    "        \n",
    "        x = x_new\n",
    "        residual = norm(b - A @ x)\n",
    "        error = norm(x - x_exact)\n",
    "        \n",
    "        residuals.append(residual)\n",
    "        errors.append(error)\n",
    "        \n",
    "        if residual < tol:\n",
    "            break\n",
    "    \n",
    "    return x, residuals, errors\n",
    "\n",
    "# Solve with both methods\n",
    "x_jacobi, res_jacobi, err_jacobi = jacobi(A, b, tol=1e-12)\n",
    "\n",
    "print(f\"Gauss-Seidel iterations: {len(residuals)}\")\n",
    "print(f\"Jacobi iterations: {len(res_jacobi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(residuals, 'b-', linewidth=2, label='Gauss-Seidel')\n",
    "plt.semilogy(res_jacobi, 'r--', linewidth=2, label='Jacobi')\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Residual Norm', fontsize=12)\n",
    "plt.title('Convergence Comparison: Gauss-Seidel vs Jacobi', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nGauss-Seidel converges ~{len(res_jacobi)/len(residuals):.1f}x faster than Jacobi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large System Example\n",
    "\n",
    "We demonstrate the method on a larger sparse system arising from discretization of a 1D Poisson equation:\n",
    "\n",
    "$$-\\frac{d^2 u}{dx^2} = f(x)$$\n",
    "\n",
    "with Dirichlet boundary conditions. The finite difference discretization yields a tridiagonal system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tridiagonal Poisson matrix\n",
    "n_large = 50\n",
    "A_large = np.diag(2 * np.ones(n_large)) - np.diag(np.ones(n_large-1), 1) - np.diag(np.ones(n_large-1), -1)\n",
    "\n",
    "# Source term (e.g., f(x) = sin(pi*x))\n",
    "h = 1 / (n_large + 1)\n",
    "x_pts = np.linspace(h, 1-h, n_large)\n",
    "b_large = h**2 * np.sin(np.pi * x_pts)\n",
    "\n",
    "# Solve\n",
    "x_sol, res_large, err_large = gauss_seidel(A_large, b_large, tol=1e-10)\n",
    "\n",
    "print(f\"System size: {n_large} x {n_large}\")\n",
    "print(f\"Iterations to converge: {len(res_large)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Gauss-Seidel method is an efficient iterative solver for linear systems, particularly when:\n",
    "\n",
    "1. The matrix is **diagonally dominant** or **symmetric positive definite**\n",
    "2. The system is **large and sparse** (where direct methods are expensive)\n",
    "3. Only **moderate accuracy** is needed\n",
    "\n",
    "Key advantages:\n",
    "- Memory efficient (no matrix factorization required)\n",
    "- Simple to implement\n",
    "- Faster convergence than Jacobi due to immediate use of updated values\n",
    "\n",
    "The convergence rate depends on the spectral radius of the iteration matrix, which is influenced by the matrix structure and conditioning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
