{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Simulation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "A **Markov chain** is a stochastic process that satisfies the **Markov property**: the future state depends only on the current state, not on the sequence of events that preceded it. This \"memoryless\" property makes Markov chains powerful tools for modeling systems in physics, biology, economics, and computer science.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### Definition\n",
    "\n",
    "A discrete-time Markov chain is a sequence of random variables $X_0, X_1, X_2, \\ldots$ taking values in a finite or countable state space $S$, satisfying:\n",
    "\n",
    "$$P(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i)$$\n",
    "\n",
    "This conditional probability is called the **transition probability** and is denoted:\n",
    "\n",
    "$$p_{ij} = P(X_{n+1} = j \\mid X_n = i)$$\n",
    "\n",
    "### Transition Matrix\n",
    "\n",
    "For a Markov chain with $N$ states, the transition probabilities are organized into an $N \\times N$ **transition matrix** $\\mathbf{P}$:\n",
    "\n",
    "$$\\mathbf{P} = \\begin{pmatrix} p_{11} & p_{12} & \\cdots & p_{1N} \\\\ p_{21} & p_{22} & \\cdots & p_{2N} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ p_{N1} & p_{N2} & \\cdots & p_{NN} \\end{pmatrix}$$\n",
    "\n",
    "Each row must sum to 1 (stochastic matrix):\n",
    "\n",
    "$$\\sum_{j=1}^{N} p_{ij} = 1 \\quad \\forall i$$\n",
    "\n",
    "### Chapman-Kolmogorov Equation\n",
    "\n",
    "The $n$-step transition probability is given by:\n",
    "\n",
    "$$p_{ij}^{(n)} = P(X_{m+n} = j \\mid X_m = i) = (\\mathbf{P}^n)_{ij}$$\n",
    "\n",
    "### Stationary Distribution\n",
    "\n",
    "A probability distribution $\\boldsymbol{\\pi} = (\\pi_1, \\pi_2, \\ldots, \\pi_N)$ is a **stationary distribution** if:\n",
    "\n",
    "$$\\boldsymbol{\\pi} \\mathbf{P} = \\boldsymbol{\\pi}$$\n",
    "\n",
    "This means $\\boldsymbol{\\pi}$ is a left eigenvector of $\\mathbf{P}$ with eigenvalue 1.\n",
    "\n",
    "For an irreducible and aperiodic Markov chain, the stationary distribution exists, is unique, and:\n",
    "\n",
    "$$\\lim_{n \\to \\infty} p_{ij}^{(n)} = \\pi_j$$\n",
    "\n",
    "regardless of the initial state $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Weather Model\n",
    "\n",
    "Consider a simple weather model with three states:\n",
    "- State 0: Sunny\n",
    "- State 1: Cloudy\n",
    "- State 2: Rainy\n",
    "\n",
    "We define a transition matrix based on typical weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define states\n",
    "states = ['Sunny', 'Cloudy', 'Rainy']\n",
    "n_states = len(states)\n",
    "\n",
    "# Define transition matrix\n",
    "# P[i,j] = probability of transitioning from state i to state j\n",
    "P = np.array([\n",
    "    [0.7, 0.2, 0.1],  # From Sunny\n",
    "    [0.3, 0.4, 0.3],  # From Cloudy\n",
    "    [0.2, 0.3, 0.5]   # From Rainy\n",
    "])\n",
    "\n",
    "# Verify it's a valid stochastic matrix\n",
    "print(\"Transition Matrix P:\")\n",
    "print(P)\n",
    "print(f\"\\nRow sums: {P.sum(axis=1)}\")\n",
    "print(\"All rows sum to 1:\", np.allclose(P.sum(axis=1), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Simulation\n",
    "\n",
    "We now implement a function to simulate the Markov chain and visualize its behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_markov_chain(P, initial_state, n_steps):\n",
    "    \"\"\"\n",
    "    Simulate a Markov chain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : ndarray\n",
    "        Transition matrix (n_states x n_states)\n",
    "    initial_state : int\n",
    "        Starting state index\n",
    "    n_steps : int\n",
    "        Number of steps to simulate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    states_history : list\n",
    "        Sequence of visited states\n",
    "    \"\"\"\n",
    "    n_states = P.shape[0]\n",
    "    current_state = initial_state\n",
    "    states_history = [current_state]\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        # Sample next state from transition probabilities\n",
    "        next_state = np.random.choice(n_states, p=P[current_state])\n",
    "        states_history.append(next_state)\n",
    "        current_state = next_state\n",
    "    \n",
    "    return states_history\n",
    "\n",
    "# Simulate the chain\n",
    "n_steps = 1000\n",
    "initial_state = 0  # Start with Sunny\n",
    "trajectory = simulate_markov_chain(P, initial_state, n_steps)\n",
    "\n",
    "print(f\"First 20 states: {[states[s] for s in trajectory[:20]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Stationary Distribution\n",
    "\n",
    "### Analytical Solution\n",
    "\n",
    "We find $\\boldsymbol{\\pi}$ by solving $\\boldsymbol{\\pi} \\mathbf{P} = \\boldsymbol{\\pi}$ subject to $\\sum_i \\pi_i = 1$.\n",
    "\n",
    "This is equivalent to finding the left eigenvector of $\\mathbf{P}$ corresponding to eigenvalue 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stationary_distribution(P):\n",
    "    \"\"\"\n",
    "    Compute the stationary distribution of a Markov chain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : ndarray\n",
    "        Transition matrix\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pi : ndarray\n",
    "        Stationary distribution\n",
    "    \"\"\"\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Solve (P^T - I) * pi = 0 with constraint sum(pi) = 1\n",
    "    # Augment the system with the normalization constraint\n",
    "    A = np.vstack([P.T - np.eye(n), np.ones(n)])\n",
    "    b = np.zeros(n + 1)\n",
    "    b[-1] = 1\n",
    "    \n",
    "    # Solve using least squares\n",
    "    pi, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "    \n",
    "    return pi\n",
    "\n",
    "# Compute analytical stationary distribution\n",
    "pi_analytical = compute_stationary_distribution(P)\n",
    "print(\"Analytical Stationary Distribution:\")\n",
    "for i, state in enumerate(states):\n",
    "    print(f\"  {state}: {pi_analytical[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Estimation\n",
    "\n",
    "We can also estimate the stationary distribution from the simulation by computing the fraction of time spent in each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute empirical distribution from simulation\n",
    "trajectory_array = np.array(trajectory)\n",
    "pi_empirical = np.array([np.sum(trajectory_array == i) for i in range(n_states)]) / len(trajectory)\n",
    "\n",
    "print(\"Empirical Stationary Distribution (from simulation):\")\n",
    "for i, state in enumerate(states):\n",
    "    print(f\"  {state}: {pi_empirical[i]:.4f}\")\n",
    "\n",
    "print(f\"\\nMaximum absolute error: {np.max(np.abs(pi_analytical - pi_empirical)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Analysis\n",
    "\n",
    "We examine how the state distribution converges to the stationary distribution over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distribution_over_time(P, initial_dist, n_steps):\n",
    "    \"\"\"\n",
    "    Compute the probability distribution at each time step.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : ndarray\n",
    "        Transition matrix\n",
    "    initial_dist : ndarray\n",
    "        Initial probability distribution\n",
    "    n_steps : int\n",
    "        Number of steps\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    distributions : ndarray\n",
    "        Distribution at each time step (n_steps+1 x n_states)\n",
    "    \"\"\"\n",
    "    distributions = [initial_dist]\n",
    "    current_dist = initial_dist.copy()\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        current_dist = current_dist @ P\n",
    "        distributions.append(current_dist.copy())\n",
    "    \n",
    "    return np.array(distributions)\n",
    "\n",
    "# Start from different initial distributions\n",
    "initial_distributions = [\n",
    "    np.array([1.0, 0.0, 0.0]),  # Start in Sunny\n",
    "    np.array([0.0, 1.0, 0.0]),  # Start in Cloudy\n",
    "    np.array([0.0, 0.0, 1.0])   # Start in Rainy\n",
    "]\n",
    "\n",
    "n_convergence_steps = 50\n",
    "convergence_results = []\n",
    "\n",
    "for init_dist in initial_distributions:\n",
    "    result = compute_distribution_over_time(P, init_dist, n_convergence_steps)\n",
    "    convergence_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We create a comprehensive visualization showing:\n",
    "1. The transition matrix as a heatmap\n",
    "2. A sample trajectory\n",
    "3. Convergence to stationary distribution\n",
    "4. Comparison of analytical vs empirical distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Transition Matrix Heatmap\n",
    "ax1 = axes[0, 0]\n",
    "im = ax1.imshow(P, cmap='Blues', vmin=0, vmax=1)\n",
    "ax1.set_xticks(range(n_states))\n",
    "ax1.set_yticks(range(n_states))\n",
    "ax1.set_xticklabels(states)\n",
    "ax1.set_yticklabels(states)\n",
    "ax1.set_xlabel('To State', fontsize=12)\n",
    "ax1.set_ylabel('From State', fontsize=12)\n",
    "ax1.set_title('Transition Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(n_states):\n",
    "    for j in range(n_states):\n",
    "        text = ax1.text(j, i, f'{P[i, j]:.2f}',\n",
    "                       ha='center', va='center', fontsize=12,\n",
    "                       color='white' if P[i, j] > 0.5 else 'black')\n",
    "\n",
    "plt.colorbar(im, ax=ax1, label='Probability')\n",
    "\n",
    "# Plot 2: Sample Trajectory\n",
    "ax2 = axes[0, 1]\n",
    "plot_steps = 100\n",
    "ax2.step(range(plot_steps + 1), trajectory[:plot_steps + 1], where='mid', \n",
    "         linewidth=1.5, color='#2E86AB')\n",
    "ax2.set_yticks(range(n_states))\n",
    "ax2.set_yticklabels(states)\n",
    "ax2.set_xlabel('Time Step', fontsize=12)\n",
    "ax2.set_ylabel('State', fontsize=12)\n",
    "ax2.set_title('Sample Markov Chain Trajectory', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlim(0, plot_steps)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Convergence to Stationary Distribution\n",
    "ax3 = axes[1, 0]\n",
    "colors = ['#E74C3C', '#F39C12', '#3498DB']\n",
    "linestyles = ['-', '--', ':']\n",
    "\n",
    "for idx, (result, init_name) in enumerate(zip(convergence_results, states)):\n",
    "    for state_idx in range(n_states):\n",
    "        if idx == 0:  # Only label once\n",
    "            label = states[state_idx]\n",
    "        else:\n",
    "            label = None\n",
    "        ax3.plot(result[:, state_idx], \n",
    "                color=colors[state_idx], \n",
    "                linestyle=linestyles[idx],\n",
    "                linewidth=1.5,\n",
    "                label=label,\n",
    "                alpha=0.8)\n",
    "\n",
    "# Add horizontal lines for stationary distribution\n",
    "for state_idx in range(n_states):\n",
    "    ax3.axhline(y=pi_analytical[state_idx], color=colors[state_idx], \n",
    "               linestyle='-.', alpha=0.5, linewidth=2)\n",
    "\n",
    "ax3.set_xlabel('Time Step', fontsize=12)\n",
    "ax3.set_ylabel('Probability', fontsize=12)\n",
    "ax3.set_title('Convergence to Stationary Distribution', fontsize=14, fontweight='bold')\n",
    "ax3.legend(loc='upper right')\n",
    "ax3.set_xlim(0, n_convergence_steps)\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Comparison of Analytical vs Empirical Distribution\n",
    "ax4 = axes[1, 1]\n",
    "x = np.arange(n_states)\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax4.bar(x - width/2, pi_analytical, width, label='Analytical', \n",
    "               color='#3498DB', alpha=0.8, edgecolor='black')\n",
    "bars2 = ax4.bar(x + width/2, pi_empirical, width, label='Empirical', \n",
    "               color='#E74C3C', alpha=0.8, edgecolor='black')\n",
    "\n",
    "ax4.set_xlabel('State', fontsize=12)\n",
    "ax4.set_ylabel('Probability', fontsize=12)\n",
    "ax4.set_title('Stationary Distribution: Analytical vs Empirical', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(states)\n",
    "ax4.legend()\n",
    "ax4.set_ylim(0, 0.6)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars1, pi_analytical):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "for bar, val in zip(bars2, pi_empirical):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Verification\n",
    "\n",
    "### Verifying Stationarity\n",
    "\n",
    "We verify that $\\boldsymbol{\\pi} \\mathbf{P} = \\boldsymbol{\\pi}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify stationarity condition\n",
    "pi_P = pi_analytical @ P\n",
    "print(\"Verification of πP = π:\")\n",
    "print(f\"π:    {pi_analytical}\")\n",
    "print(f\"πP:   {pi_P}\")\n",
    "print(f\"Equal: {np.allclose(pi_analytical, pi_P)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long-term Behavior\n",
    "\n",
    "For large $n$, all rows of $\\mathbf{P}^n$ should converge to the stationary distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute P^n for large n\n",
    "P_100 = np.linalg.matrix_power(P, 100)\n",
    "\n",
    "print(\"P^100 (should have identical rows equal to π):\")\n",
    "print(P_100)\n",
    "print(f\"\\nStationary distribution π: {pi_analytical}\")\n",
    "print(f\"\\nAll rows equal to π: {np.allclose(P_100, pi_analytical)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the fundamental concepts of Markov chains:\n",
    "\n",
    "1. **Transition matrices** encode the probabilistic dynamics of the system\n",
    "2. **Simulations** can be performed by sampling from transition probabilities\n",
    "3. **Stationary distributions** can be computed analytically as eigenvectors or estimated empirically\n",
    "4. **Convergence** to the stationary distribution occurs regardless of initial conditions for irreducible, aperiodic chains\n",
    "\n",
    "The simulation results closely match the analytical predictions, validating both the implementation and the theoretical foundations of Markov chain theory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
