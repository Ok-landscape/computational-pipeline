{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Iteration Method for Eigenvalue Problems\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Inverse iteration** (also known as **inverse power method**) is a fundamental numerical algorithm for computing eigenvectors of a matrix. Given an approximation to an eigenvalue, inverse iteration rapidly converges to the corresponding eigenvector. This makes it particularly valuable when we have good eigenvalue estimates (e.g., from the QR algorithm) but need the associated eigenvectors.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### The Eigenvalue Problem\n",
    "\n",
    "For a matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$, we seek eigenvalue-eigenvector pairs $(\\lambda, \\mathbf{v})$ satisfying:\n",
    "\n",
    "$$\\mathbf{A}\\mathbf{v} = \\lambda \\mathbf{v}$$\n",
    "\n",
    "### Inverse Iteration Algorithm\n",
    "\n",
    "Given a shift $\\mu$ (an approximation to an eigenvalue $\\lambda$), inverse iteration exploits the fact that $(\\mathbf{A} - \\mu \\mathbf{I})^{-1}$ has eigenvalues:\n",
    "\n",
    "$$\\frac{1}{\\lambda_i - \\mu}$$\n",
    "\n",
    "where $\\lambda_i$ are the eigenvalues of $\\mathbf{A}$. If $\\mu \\approx \\lambda_j$, then $\\frac{1}{\\lambda_j - \\mu}$ is the dominant eigenvalue of $(\\mathbf{A} - \\mu \\mathbf{I})^{-1}$, and the power method applied to this inverse matrix converges rapidly to the eigenvector $\\mathbf{v}_j$.\n",
    "\n",
    "### Algorithm Steps\n",
    "\n",
    "1. Start with initial guess $\\mathbf{v}^{(0)}$ (typically random)\n",
    "2. For $k = 0, 1, 2, \\ldots$ until convergence:\n",
    "   - Solve $(\\mathbf{A} - \\mu \\mathbf{I})\\mathbf{w}^{(k+1)} = \\mathbf{v}^{(k)}$\n",
    "   - Normalize: $\\mathbf{v}^{(k+1)} = \\frac{\\mathbf{w}^{(k+1)}}{\\|\\mathbf{w}^{(k+1)}\\|}$\n",
    "\n",
    "### Convergence Analysis\n",
    "\n",
    "The convergence rate is determined by the ratio:\n",
    "\n",
    "$$\\rho = \\left| \\frac{\\lambda_j - \\mu}{\\lambda_{nearest} - \\mu} \\right|$$\n",
    "\n",
    "where $\\lambda_{nearest}$ is the eigenvalue second-closest to $\\mu$. When $\\mu$ is close to $\\lambda_j$, this ratio is very small, leading to rapid (often cubic) convergence.\n",
    "\n",
    "### Rayleigh Quotient Refinement\n",
    "\n",
    "The eigenvalue estimate can be refined using the Rayleigh quotient:\n",
    "\n",
    "$$\\lambda \\approx \\rho(\\mathbf{v}) = \\frac{\\mathbf{v}^T \\mathbf{A} \\mathbf{v}}{\\mathbf{v}^T \\mathbf{v}}$$\n",
    "\n",
    "This provides a more accurate eigenvalue estimate as the eigenvector converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We implement inverse iteration with LU decomposition for efficient repeated solves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_iteration(A, mu, tol=1e-10, max_iter=100):\n",
    "    \"\"\"\n",
    "    Inverse iteration to find eigenvector corresponding to eigenvalue near mu.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray\n",
    "        Square matrix (n x n)\n",
    "    mu : float\n",
    "        Shift (approximation to desired eigenvalue)\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    max_iter : int\n",
    "        Maximum number of iterations\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    eigenvalue : float\n",
    "        Refined eigenvalue estimate (Rayleigh quotient)\n",
    "    eigenvector : ndarray\n",
    "        Corresponding eigenvector\n",
    "    residuals : list\n",
    "        History of residual norms for convergence analysis\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # Initial random vector\n",
    "    v = np.random.randn(n)\n",
    "    v = v / np.linalg.norm(v)\n",
    "    \n",
    "    # Shifted matrix\n",
    "    A_shifted = A - mu * np.eye(n)\n",
    "    \n",
    "    # LU factorization for efficient repeated solves\n",
    "    lu, piv = linalg.lu_factor(A_shifted)\n",
    "    \n",
    "    residuals = []\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        # Solve (A - mu*I) * w = v\n",
    "        w = linalg.lu_solve((lu, piv), v)\n",
    "        \n",
    "        # Normalize\n",
    "        w_norm = np.linalg.norm(w)\n",
    "        v_new = w / w_norm\n",
    "        \n",
    "        # Rayleigh quotient for eigenvalue estimate\n",
    "        eigenvalue = np.dot(v_new, A @ v_new)\n",
    "        \n",
    "        # Compute residual ||Av - lambda*v||\n",
    "        residual = np.linalg.norm(A @ v_new - eigenvalue * v_new)\n",
    "        residuals.append(residual)\n",
    "        \n",
    "        # Check convergence\n",
    "        if residual < tol:\n",
    "            return eigenvalue, v_new, residuals\n",
    "        \n",
    "        v = v_new\n",
    "    \n",
    "    return eigenvalue, v, residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Symmetric Matrix\n",
    "\n",
    "We first demonstrate inverse iteration on a symmetric matrix, which has real eigenvalues and orthogonal eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a symmetric positive definite matrix\n",
    "n = 5\n",
    "B = np.random.randn(n, n)\n",
    "A_sym = B @ B.T + np.eye(n)  # Ensure positive definiteness\n",
    "\n",
    "# Get true eigenvalues for reference\n",
    "true_eigenvalues, true_eigenvectors = np.linalg.eigh(A_sym)\n",
    "print(\"True eigenvalues:\", true_eigenvalues)\n",
    "\n",
    "# Target the smallest eigenvalue\n",
    "target_idx = 0\n",
    "mu = true_eigenvalues[target_idx] + 0.1  # Slightly perturbed shift\n",
    "\n",
    "print(f\"\\nTarget eigenvalue: {true_eigenvalues[target_idx]:.6f}\")\n",
    "print(f\"Initial shift mu: {mu:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inverse iteration\n",
    "eigenvalue, eigenvector, residuals = inverse_iteration(A_sym, mu)\n",
    "\n",
    "print(f\"\\nComputed eigenvalue: {eigenvalue:.10f}\")\n",
    "print(f\"True eigenvalue:     {true_eigenvalues[target_idx]:.10f}\")\n",
    "print(f\"Absolute error:      {abs(eigenvalue - true_eigenvalues[target_idx]):.2e}\")\n",
    "\n",
    "# Check eigenvector accuracy (up to sign)\n",
    "true_vec = true_eigenvectors[:, target_idx]\n",
    "dot_product = abs(np.dot(eigenvector, true_vec))\n",
    "print(f\"\\nEigenvector alignment |v·v_true|: {dot_product:.10f}\")\n",
    "print(f\"Iterations to converge: {len(residuals)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Effect of Shift Quality\n",
    "\n",
    "We investigate how the quality of the initial shift $\\mu$ affects convergence speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test matrix\n",
    "n = 10\n",
    "B = np.random.randn(n, n)\n",
    "A_test = B @ B.T + 2 * np.eye(n)\n",
    "\n",
    "true_eigs = np.linalg.eigvalsh(A_test)\n",
    "target_eig = true_eigs[2]  # Target the 3rd smallest eigenvalue\n",
    "\n",
    "print(f\"Target eigenvalue: {target_eig:.6f}\")\n",
    "\n",
    "# Test different shift qualities\n",
    "perturbations = [0.5, 0.1, 0.01, 0.001]\n",
    "convergence_histories = {}\n",
    "\n",
    "for perturb in perturbations:\n",
    "    mu = target_eig + perturb\n",
    "    _, _, residuals = inverse_iteration(A_test, mu, tol=1e-12, max_iter=50)\n",
    "    convergence_histories[perturb] = residuals\n",
    "    print(f\"Perturbation {perturb}: converged in {len(residuals)} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Visualization\n",
    "\n",
    "We plot the convergence behavior for different shift qualities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Convergence histories\n",
    "ax1 = axes[0]\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(perturbations)))\n",
    "\n",
    "for (perturb, residuals), color in zip(convergence_histories.items(), colors):\n",
    "    ax1.semilogy(range(1, len(residuals) + 1), residuals, \n",
    "                 'o-', color=color, label=f'$|\\\\mu - \\\\lambda| = {perturb}$',\n",
    "                 markersize=4, linewidth=1.5)\n",
    "\n",
    "ax1.set_xlabel('Iteration', fontsize=12)\n",
    "ax1.set_ylabel('Residual $\\\\|A\\\\mathbf{v} - \\\\lambda\\\\mathbf{v}\\\\|$', fontsize=12)\n",
    "ax1.set_title('Inverse Iteration Convergence\\nfor Different Shift Qualities', fontsize=14)\n",
    "ax1.legend(loc='upper right', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0.5, 20)\n",
    "\n",
    "# Plot 2: Eigenvalue spectrum and shifts\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Plot all eigenvalues\n",
    "ax2.scatter(true_eigs, np.zeros_like(true_eigs), s=100, c='blue', \n",
    "            marker='o', label='Eigenvalues', zorder=5)\n",
    "\n",
    "# Highlight target eigenvalue\n",
    "ax2.scatter([target_eig], [0], s=200, c='red', marker='*', \n",
    "            label='Target $\\\\lambda$', zorder=6)\n",
    "\n",
    "# Show shifts\n",
    "for i, perturb in enumerate(perturbations):\n",
    "    shift = target_eig + perturb\n",
    "    ax2.axvline(shift, color=colors[i], linestyle='--', alpha=0.7,\n",
    "                label=f'$\\\\mu = \\\\lambda + {perturb}$')\n",
    "\n",
    "ax2.set_xlabel('Value', fontsize=12)\n",
    "ax2.set_title('Eigenvalue Spectrum and Shifts', fontsize=14)\n",
    "ax2.legend(loc='upper right', fontsize=9)\n",
    "ax2.set_yticks([])\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rayleigh Quotient Iteration\n",
    "\n",
    "An improvement over standard inverse iteration is **Rayleigh Quotient Iteration (RQI)**, which updates the shift $\\mu$ at each iteration using the current Rayleigh quotient. This achieves locally cubic convergence.\n",
    "\n",
    "$$\\mu^{(k+1)} = \\rho(\\mathbf{v}^{(k)}) = \\frac{(\\mathbf{v}^{(k)})^T \\mathbf{A} \\mathbf{v}^{(k)}}{(\\mathbf{v}^{(k)})^T \\mathbf{v}^{(k)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rayleigh_quotient_iteration(A, mu_init, tol=1e-10, max_iter=20):\n",
    "    \"\"\"\n",
    "    Rayleigh Quotient Iteration for eigenvalue/eigenvector computation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray\n",
    "        Square matrix (n x n)\n",
    "    mu_init : float\n",
    "        Initial shift\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    max_iter : int\n",
    "        Maximum iterations\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    eigenvalue : float\n",
    "        Computed eigenvalue\n",
    "    eigenvector : ndarray\n",
    "        Corresponding eigenvector\n",
    "    residuals : list\n",
    "        Convergence history\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    v = np.random.randn(n)\n",
    "    v = v / np.linalg.norm(v)\n",
    "    mu = mu_init\n",
    "    \n",
    "    residuals = []\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        # Solve (A - mu*I) * w = v\n",
    "        try:\n",
    "            w = np.linalg.solve(A - mu * np.eye(n), v)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Singular matrix means we've found exact eigenvalue\n",
    "            break\n",
    "        \n",
    "        # Normalize\n",
    "        v = w / np.linalg.norm(w)\n",
    "        \n",
    "        # Update shift with Rayleigh quotient\n",
    "        mu = np.dot(v, A @ v)\n",
    "        \n",
    "        # Compute residual\n",
    "        residual = np.linalg.norm(A @ v - mu * v)\n",
    "        residuals.append(residual)\n",
    "        \n",
    "        if residual < tol:\n",
    "            break\n",
    "    \n",
    "    return mu, v, residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare standard inverse iteration with RQI\n",
    "mu_init = target_eig + 0.3  # Moderate perturbation\n",
    "\n",
    "# Standard inverse iteration\n",
    "_, _, residuals_std = inverse_iteration(A_test, mu_init, tol=1e-14, max_iter=50)\n",
    "\n",
    "# Rayleigh quotient iteration\n",
    "_, _, residuals_rqi = rayleigh_quotient_iteration(A_test, mu_init, tol=1e-14, max_iter=50)\n",
    "\n",
    "print(f\"Standard inverse iteration: {len(residuals_std)} iterations\")\n",
    "print(f\"Rayleigh quotient iteration: {len(residuals_rqi)} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.semilogy(range(1, len(residuals_std) + 1), residuals_std, \n",
    "             'b-o', label='Standard Inverse Iteration', markersize=5)\n",
    "plt.semilogy(range(1, len(residuals_rqi) + 1), residuals_rqi, \n",
    "             'r-s', label='Rayleigh Quotient Iteration', markersize=5)\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Residual $\\\\|A\\\\mathbf{v} - \\\\lambda\\\\mathbf{v}\\\\|$', fontsize=12)\n",
    "plt.title('Convergence Comparison: Standard vs Rayleigh Quotient Iteration', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Considerations\n",
    "\n",
    "### When to Use Inverse Iteration\n",
    "\n",
    "1. **Eigenvector refinement**: When eigenvalues are known (e.g., from QR algorithm) but eigenvectors are needed\n",
    "2. **Selective computation**: When only a few specific eigenpairs are required\n",
    "3. **Sparse matrices**: Inverse iteration only requires solving linear systems, which can be done efficiently for sparse matrices\n",
    "\n",
    "### Numerical Stability\n",
    "\n",
    "- Use LU decomposition with partial pivoting for solving linear systems\n",
    "- When $\\mu$ is very close to an eigenvalue, $(A - \\mu I)$ becomes nearly singular\n",
    "- In practice, this near-singularity doesn't cause problems because the solution direction is preserved\n",
    "\n",
    "### Complexity\n",
    "\n",
    "- Each iteration requires solving an $n \\times n$ linear system: $O(n^3)$ for dense matrices\n",
    "- With LU pre-factorization: initial $O(n^3)$, then $O(n^2)$ per iteration\n",
    "- For sparse matrices, cost depends on the sparsity structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate finding multiple eigenvectors\n",
    "print(\"Finding all eigenvectors using inverse iteration:\\n\")\n",
    "\n",
    "computed_eigenvectors = []\n",
    "for i, eig in enumerate(true_eigs):\n",
    "    # Use exact eigenvalue as shift (best case)\n",
    "    eigenvalue, eigenvector, _ = inverse_iteration(A_test, eig, tol=1e-12)\n",
    "    computed_eigenvectors.append(eigenvector)\n",
    "    \n",
    "    # Verify orthogonality with previously computed eigenvectors\n",
    "    if i > 0:\n",
    "        max_dot = max(abs(np.dot(eigenvector, v)) for v in computed_eigenvectors[:-1])\n",
    "        print(f\"Eigenvalue {i+1}: {eigenvalue:.6f}, max |v_i · v_j|: {max_dot:.2e}\")\n",
    "    else:\n",
    "        print(f\"Eigenvalue {i+1}: {eigenvalue:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Inverse iteration is a powerful and efficient algorithm for computing eigenvectors when good eigenvalue approximations are available. Key takeaways:\n",
    "\n",
    "1. **Rapid convergence**: The method converges quickly when the shift is close to the target eigenvalue\n",
    "2. **Flexibility**: Can target any eigenvalue by choosing an appropriate shift\n",
    "3. **Efficiency**: Only requires solving linear systems, making it suitable for large sparse matrices\n",
    "4. **Enhancement**: Rayleigh quotient iteration further accelerates convergence by dynamically updating the shift\n",
    "\n",
    "The algorithm forms a fundamental building block in modern eigenvalue solvers and is often used in conjunction with other methods like the QR algorithm or Arnoldi iteration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
