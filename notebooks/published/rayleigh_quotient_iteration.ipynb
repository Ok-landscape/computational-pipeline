{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rayleigh Quotient Iteration\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Rayleigh Quotient Iteration (RQI) is a powerful iterative algorithm for computing an eigenvalue and its corresponding eigenvector of a matrix. It combines the **inverse iteration** method with a dynamically updated **Rayleigh quotient** shift, resulting in **cubic convergence** near an eigenvalue—one of the fastest convergence rates among eigenvalue algorithms.\n",
    "\n",
    "## Theoretical Foundation\n",
    "\n",
    "### The Rayleigh Quotient\n",
    "\n",
    "For a Hermitian (or symmetric) matrix $A \\in \\mathbb{R}^{n \\times n}$ and a non-zero vector $\\mathbf{v} \\in \\mathbb{R}^n$, the **Rayleigh quotient** is defined as:\n",
    "\n",
    "$$\\rho(\\mathbf{v}) = \\frac{\\mathbf{v}^T A \\mathbf{v}}{\\mathbf{v}^T \\mathbf{v}}$$\n",
    "\n",
    "The Rayleigh quotient has the following important properties:\n",
    "\n",
    "1. **Eigenvalue bound**: For any vector $\\mathbf{v}$, we have $\\lambda_{\\min} \\leq \\rho(\\mathbf{v}) \\leq \\lambda_{\\max}$\n",
    "2. **Stationary property**: $\\rho(\\mathbf{v})$ is stationary at eigenvectors, meaning $\\nabla \\rho = 0$ when $\\mathbf{v}$ is an eigenvector\n",
    "3. **Best approximation**: If $\\mathbf{v}$ approximates an eigenvector with error $\\mathcal{O}(\\epsilon)$, then $\\rho(\\mathbf{v})$ approximates the eigenvalue with error $\\mathcal{O}(\\epsilon^2)$\n",
    "\n",
    "### The Algorithm\n",
    "\n",
    "Rayleigh Quotient Iteration proceeds as follows:\n",
    "\n",
    "Given an initial vector $\\mathbf{v}_0$ with $\\|\\mathbf{v}_0\\| = 1$:\n",
    "\n",
    "**For** $k = 0, 1, 2, \\ldots$ **until convergence:**\n",
    "\n",
    "1. Compute the Rayleigh quotient (shift):\n",
    "   $$\\sigma_k = \\rho(\\mathbf{v}_k) = \\mathbf{v}_k^T A \\mathbf{v}_k$$\n",
    "\n",
    "2. Solve the shifted linear system:\n",
    "   $$(A - \\sigma_k I)\\mathbf{w}_{k+1} = \\mathbf{v}_k$$\n",
    "\n",
    "3. Normalize:\n",
    "   $$\\mathbf{v}_{k+1} = \\frac{\\mathbf{w}_{k+1}}{\\|\\mathbf{w}_{k+1}\\|}$$\n",
    "\n",
    "### Convergence Analysis\n",
    "\n",
    "The key insight is that near an eigenvector, the Rayleigh quotient provides an excellent approximation to the eigenvalue. If $\\mathbf{v}_k$ has error $\\epsilon_k$ from the true eigenvector:\n",
    "\n",
    "- The shift $\\sigma_k$ approximates the eigenvalue with error $\\mathcal{O}(\\epsilon_k^2)$\n",
    "- Inverse iteration with this shift reduces the error to $\\mathcal{O}(\\epsilon_k^2)$\n",
    "- Therefore, $\\epsilon_{k+1} = \\mathcal{O}(\\epsilon_k^3)$ — **cubic convergence**\n",
    "\n",
    "This means that once convergence begins, the number of correct digits approximately **triples** at each iteration.\n",
    "\n",
    "### Comparison with Other Methods\n",
    "\n",
    "| Method | Convergence Rate | Notes |\n",
    "|--------|-----------------|-------|\n",
    "| Power Iteration | Linear | $\\mathcal{O}(|\\lambda_2/\\lambda_1|^k)$ |\n",
    "| Inverse Iteration | Linear | Requires good initial shift |\n",
    "| Rayleigh Quotient Iteration | Cubic | Self-correcting shift |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Let us implement Rayleigh Quotient Iteration and demonstrate its remarkable convergence properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def rayleigh_quotient(A, v):\n",
    "    \"\"\"Compute the Rayleigh quotient of vector v with respect to matrix A.\"\"\"\n",
    "    return np.dot(v, A @ v) / np.dot(v, v)\n",
    "\n",
    "def rayleigh_quotient_iteration(A, v0, tol=1e-12, max_iter=100):\n",
    "    \"\"\"\n",
    "    Rayleigh Quotient Iteration for finding an eigenvalue/eigenvector pair.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    A : ndarray\n",
    "        Symmetric matrix\n",
    "    v0 : ndarray\n",
    "        Initial vector guess\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    max_iter : int\n",
    "        Maximum number of iterations\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    eigenvalue : float\n",
    "        Computed eigenvalue\n",
    "    eigenvector : ndarray\n",
    "        Computed eigenvector\n",
    "    history : dict\n",
    "        Convergence history\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    v = v0 / np.linalg.norm(v0)\n",
    "    \n",
    "    history = {\n",
    "        'eigenvalues': [],\n",
    "        'residuals': [],\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    # Compute true eigenvalues for error tracking\n",
    "    true_eigenvalues = np.sort(np.linalg.eigvalsh(A))\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        # Step 1: Compute Rayleigh quotient (shift)\n",
    "        sigma = rayleigh_quotient(A, v)\n",
    "        history['eigenvalues'].append(sigma)\n",
    "        \n",
    "        # Compute residual\n",
    "        residual = np.linalg.norm(A @ v - sigma * v)\n",
    "        history['residuals'].append(residual)\n",
    "        \n",
    "        # Compute error to nearest eigenvalue\n",
    "        error = np.min(np.abs(true_eigenvalues - sigma))\n",
    "        history['errors'].append(error)\n",
    "        \n",
    "        # Check convergence\n",
    "        if residual < tol:\n",
    "            break\n",
    "        \n",
    "        # Step 2: Solve (A - sigma*I)w = v\n",
    "        try:\n",
    "            w = np.linalg.solve(A - sigma * np.eye(n), v)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Matrix is singular - we've found an eigenvalue exactly\n",
    "            break\n",
    "        \n",
    "        # Step 3: Normalize\n",
    "        v = w / np.linalg.norm(w)\n",
    "    \n",
    "    return sigma, v, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration: Convergence Analysis\n",
    "\n",
    "We will create a symmetric test matrix and observe the cubic convergence of RQI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a symmetric positive definite matrix\n",
    "n = 5\n",
    "B = np.random.randn(n, n)\n",
    "A = B @ B.T + np.eye(n)  # Ensure positive definiteness\n",
    "\n",
    "# Compute true eigenvalues\n",
    "true_eigenvalues, true_eigenvectors = np.linalg.eigh(A)\n",
    "print(\"True eigenvalues:\")\n",
    "for i, ev in enumerate(true_eigenvalues):\n",
    "    print(f\"  λ_{i+1} = {ev:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run RQI with a random initial vector\n",
    "v0 = np.random.randn(n)\n",
    "eigenvalue, eigenvector, history = rayleigh_quotient_iteration(A, v0, tol=1e-14, max_iter=20)\n",
    "\n",
    "print(f\"\\nRayleigh Quotient Iteration Results:\")\n",
    "print(f\"Computed eigenvalue: {eigenvalue:.15f}\")\n",
    "print(f\"Nearest true eigenvalue: {true_eigenvalues[np.argmin(np.abs(true_eigenvalues - eigenvalue))]:.15f}\")\n",
    "print(f\"Number of iterations: {len(history['eigenvalues'])}\")\n",
    "print(f\"Final residual: {history['residuals'][-1]:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze convergence rate\n",
    "print(\"\\nConvergence History:\")\n",
    "print(f\"{'Iter':<6} {'Eigenvalue':<20} {'Error':<15} {'Ratio':<15}\")\n",
    "print(\"-\" * 56)\n",
    "\n",
    "errors = history['errors']\n",
    "for i in range(len(errors)):\n",
    "    if i == 0 or errors[i-1] == 0:\n",
    "        ratio = \"-\"\n",
    "    else:\n",
    "        # For cubic convergence, error[k+1] ≈ C * error[k]^3\n",
    "        # So log(error[k+1]) ≈ 3 * log(error[k]) + const\n",
    "        if errors[i] > 0 and errors[i-1] > 0:\n",
    "            ratio = f\"{np.log10(errors[i]) / np.log10(errors[i-1]):.2f}\"\n",
    "        else:\n",
    "            ratio = \"-\"\n",
    "    \n",
    "    print(f\"{i:<6} {history['eigenvalues'][i]:<20.12f} {errors[i]:<15.2e} {ratio:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Inverse Iteration\n",
    "\n",
    "Let us compare RQI with standard inverse iteration (using a fixed shift) to highlight the superior convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_iteration(A, sigma, v0, tol=1e-12, max_iter=100):\n",
    "    \"\"\"\n",
    "    Standard inverse iteration with fixed shift.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    v = v0 / np.linalg.norm(v0)\n",
    "    \n",
    "    history = {'eigenvalues': [], 'residuals': [], 'errors': []}\n",
    "    true_eigenvalues = np.sort(np.linalg.eigvalsh(A))\n",
    "    \n",
    "    # LU decomposition for efficiency\n",
    "    lu, piv = linalg.lu_factor(A - sigma * np.eye(n))\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        # Compute current eigenvalue estimate\n",
    "        mu = rayleigh_quotient(A, v)\n",
    "        history['eigenvalues'].append(mu)\n",
    "        \n",
    "        residual = np.linalg.norm(A @ v - mu * v)\n",
    "        history['residuals'].append(residual)\n",
    "        \n",
    "        error = np.min(np.abs(true_eigenvalues - mu))\n",
    "        history['errors'].append(error)\n",
    "        \n",
    "        if residual < tol:\n",
    "            break\n",
    "        \n",
    "        # Solve (A - sigma*I)w = v\n",
    "        w = linalg.lu_solve((lu, piv), v)\n",
    "        v = w / np.linalg.norm(w)\n",
    "    \n",
    "    return mu, v, history\n",
    "\n",
    "# Run inverse iteration with a shift close to an eigenvalue\n",
    "target_idx = 2  # Target the middle eigenvalue\n",
    "sigma_fixed = true_eigenvalues[target_idx] + 0.1  # Shift slightly off\n",
    "\n",
    "v0 = np.random.randn(n)\n",
    "_, _, history_inv = inverse_iteration(A, sigma_fixed, v0, tol=1e-14, max_iter=50)\n",
    "\n",
    "# Run RQI with same initial vector\n",
    "_, _, history_rqi = rayleigh_quotient_iteration(A, v0, tol=1e-14, max_iter=20)\n",
    "\n",
    "print(f\"Inverse Iteration iterations: {len(history_inv['eigenvalues'])}\")\n",
    "print(f\"RQI iterations: {len(history_rqi['eigenvalues'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Now we create comprehensive visualizations comparing the convergence behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Convergence of errors\n",
    "ax1 = axes[0, 0]\n",
    "iterations_rqi = range(len(history_rqi['errors']))\n",
    "iterations_inv = range(len(history_inv['errors']))\n",
    "\n",
    "ax1.semilogy(iterations_rqi, history_rqi['errors'], 'b-o', label='RQI', linewidth=2, markersize=8)\n",
    "ax1.semilogy(iterations_inv, history_inv['errors'], 'r-s', label='Inverse Iteration', linewidth=2, markersize=6)\n",
    "ax1.set_xlabel('Iteration', fontsize=12)\n",
    "ax1.set_ylabel('Error |λ - λ_true|', fontsize=12)\n",
    "ax1.set_title('Convergence Comparison: Error in Eigenvalue', fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(-0.5, max(len(iterations_rqi), len(iterations_inv)) - 0.5)\n",
    "\n",
    "# Plot 2: Residual convergence\n",
    "ax2 = axes[0, 1]\n",
    "ax2.semilogy(iterations_rqi, history_rqi['residuals'], 'b-o', label='RQI', linewidth=2, markersize=8)\n",
    "ax2.semilogy(iterations_inv, history_inv['residuals'], 'r-s', label='Inverse Iteration', linewidth=2, markersize=6)\n",
    "ax2.set_xlabel('Iteration', fontsize=12)\n",
    "ax2.set_ylabel('Residual ||Av - λv||', fontsize=12)\n",
    "ax2.set_title('Convergence Comparison: Residual Norm', fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Eigenvalue estimates evolution\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(iterations_rqi, history_rqi['eigenvalues'], 'b-o', label='RQI', linewidth=2, markersize=8)\n",
    "ax3.axhline(y=true_eigenvalues[np.argmin(np.abs(true_eigenvalues - history_rqi['eigenvalues'][-1]))], \n",
    "            color='k', linestyle='--', label='True eigenvalue', linewidth=1.5)\n",
    "ax3.set_xlabel('Iteration', fontsize=12)\n",
    "ax3.set_ylabel('Eigenvalue estimate', fontsize=12)\n",
    "ax3.set_title('Evolution of Eigenvalue Estimate (RQI)', fontsize=14)\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Convergence rate analysis\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "# For RQI, plot log(error_k+1) vs log(error_k)\n",
    "errors_rqi = np.array(history_rqi['errors'])\n",
    "valid_rqi = (errors_rqi[:-1] > 1e-15) & (errors_rqi[1:] > 1e-15)\n",
    "if np.any(valid_rqi):\n",
    "    log_errors_k = np.log10(errors_rqi[:-1][valid_rqi])\n",
    "    log_errors_k1 = np.log10(errors_rqi[1:][valid_rqi])\n",
    "    ax4.scatter(log_errors_k, log_errors_k1, c='blue', s=100, label='RQI', zorder=5)\n",
    "    \n",
    "    # Reference lines for different convergence rates\n",
    "    x_ref = np.linspace(min(log_errors_k)-1, max(log_errors_k)+1, 100)\n",
    "    ax4.plot(x_ref, x_ref, 'g--', alpha=0.5, label='Linear (slope=1)')\n",
    "    ax4.plot(x_ref, 2*x_ref, 'orange', linestyle='--', alpha=0.5, label='Quadratic (slope=2)')\n",
    "    ax4.plot(x_ref, 3*x_ref, 'r--', alpha=0.5, label='Cubic (slope=3)')\n",
    "    \n",
    "    ax4.set_xlim(min(log_errors_k)-0.5, max(log_errors_k)+0.5)\n",
    "    ax4.set_ylim(min(log_errors_k1)-2, max(log_errors_k)+0.5)\n",
    "\n",
    "ax4.set_xlabel('log₁₀(error_k)', fontsize=12)\n",
    "ax4.set_ylabel('log₁₀(error_{k+1})', fontsize=12)\n",
    "ax4.set_title('Convergence Rate Analysis', fontsize=14)\n",
    "ax4.legend(fontsize=9, loc='upper left')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Results\n",
    "\n",
    "The visualizations above demonstrate several key properties of Rayleigh Quotient Iteration:\n",
    "\n",
    "1. **Cubic Convergence**: In the convergence rate plot (bottom right), the RQI points lie close to the cubic reference line (slope ≈ 3), confirming the theoretical $\\mathcal{O}(\\epsilon_k^3)$ convergence.\n",
    "\n",
    "2. **Rapid Convergence**: RQI typically converges in just 3-5 iterations to machine precision, while inverse iteration requires many more iterations.\n",
    "\n",
    "3. **Self-Correcting Shifts**: Unlike inverse iteration which uses a fixed shift, RQI automatically adjusts its shift at each iteration, always moving toward the nearest eigenvalue.\n",
    "\n",
    "## Practical Considerations\n",
    "\n",
    "### Advantages of RQI\n",
    "- Extremely fast convergence (cubic rate)\n",
    "- No need to choose a shift a priori\n",
    "- Automatically converges to the nearest eigenvalue\n",
    "\n",
    "### Disadvantages\n",
    "- Requires solving a different linear system at each iteration (cannot reuse factorizations)\n",
    "- May converge to different eigenvalues depending on the initial vector\n",
    "- The shifted matrix $(A - \\sigma_k I)$ becomes increasingly ill-conditioned near convergence\n",
    "\n",
    "### When to Use RQI\n",
    "- When you need a single eigenvalue/eigenvector pair with high precision\n",
    "- When you have a good initial guess for the eigenvector\n",
    "- As a refinement step after obtaining approximate eigenvectors from other methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Rayleigh Quotient Iteration is a remarkably efficient algorithm for computing eigenvalues and eigenvectors. Its cubic convergence rate means that, once convergence begins, precision improves extremely rapidly—typically achieving machine precision in just a few iterations. This makes it particularly valuable as a refinement technique or when high-precision eigenvalue computation is required.\n",
    "\n",
    "The algorithm elegantly combines the power of inverse iteration with the optimality of the Rayleigh quotient, demonstrating how adaptive algorithms can achieve superior performance compared to their fixed-parameter counterparts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
