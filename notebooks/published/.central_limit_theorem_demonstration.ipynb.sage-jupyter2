{"backend_state":"running","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-aa024d4f-ffd4-4f69-aa25-beb9b570c0da.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_backend_state":1763833384146,"last_ipynb_save":1763833409273,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1763833385303,"exec_count":3,"id":"2a47b0","input":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom scipy.special import factorial\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Configure matplotlib for publication-quality figures\nplt.rcParams.update({\n    'font.size': 10,\n    'axes.labelsize': 11,\n    'axes.titlesize': 12,\n    'legend.fontsize': 9,\n    'figure.figsize': (12, 10),\n    'figure.dpi': 100\n})","kernel":"python3","pos":1,"start":1763833384162,"state":"done","type":"cell"}
{"cell_type":"code","end":1763833385316,"exec_count":4,"id":"c1d3c2","input":"def demonstrate_clt(distribution_name, sample_generator, mu, sigma, sample_sizes, n_experiments=10000):\n    \"\"\"\n    Demonstrate CLT for a given distribution.\n    \n    Parameters:\n    -----------\n    distribution_name : str\n        Name of the distribution for labeling\n    sample_generator : callable\n        Function that generates samples of size n\n    mu : float\n        True population mean\n    sigma : float\n        True population standard deviation\n    sample_sizes : list\n        List of sample sizes to test\n    n_experiments : int\n        Number of sample means to compute\n    \n    Returns:\n    --------\n    dict : Dictionary containing sample means for each sample size\n    \"\"\"\n    results = {}\n    \n    for n in sample_sizes:\n        # Generate n_experiments samples, each of size n\n        samples = sample_generator(size=(n_experiments, n))\n        # Compute sample means\n        sample_means = np.mean(samples, axis=1)\n        # Standardize\n        standardized = (sample_means - mu) / (sigma / np.sqrt(n))\n        results[n] = {\n            'means': sample_means,\n            'standardized': standardized\n        }\n    \n    return results","kernel":"python3","pos":3,"start":1763833385311,"state":"done","type":"cell"}
{"cell_type":"code","end":1763833385457,"exec_count":5,"id":"5cebbc","input":"# Define distributions and their parameters\ndistributions = {\n    'Uniform(0, 1)': {\n        'generator': lambda size: np.random.uniform(0, 1, size),\n        'mu': 0.5,\n        'sigma': np.sqrt(1/12)\n    },\n    'Exponential(λ=1)': {\n        'generator': lambda size: np.random.exponential(1, size),\n        'mu': 1.0,\n        'sigma': 1.0\n    },\n    'Poisson(λ=3)': {\n        'generator': lambda size: np.random.poisson(3, size),\n        'mu': 3.0,\n        'sigma': np.sqrt(3)\n    }\n}\n\nsample_sizes = [1, 5, 30, 100]\nn_experiments = 10000\n\n# Run experiments\nall_results = {}\nfor name, params in distributions.items():\n    all_results[name] = demonstrate_clt(\n        name,\n        params['generator'],\n        params['mu'],\n        params['sigma'],\n        sample_sizes,\n        n_experiments\n    )\n    print(f\"Completed experiments for {name}\")","kernel":"python3","output":{"0":{"name":"stdout","text":"Completed experiments for Uniform(0, 1)\nCompleted experiments for Exponential(λ=1)\nCompleted experiments for Poisson(λ=3)\n"}},"pos":4,"start":1763833385325,"state":"done","type":"cell"}
{"cell_type":"code","end":1763833388603,"exec_count":6,"id":"be86c3","input":"# Create comprehensive visualization\nfig, axes = plt.subplots(3, 4, figsize=(14, 10))\nfig.suptitle('Central Limit Theorem Demonstration\\n'\n             'Convergence of Standardized Sample Means to N(0, 1)', \n             fontsize=14, fontweight='bold', y=1.02)\n\n# Standard normal for comparison\nx_norm = np.linspace(-4, 4, 1000)\ny_norm = stats.norm.pdf(x_norm)\n\ncolors = ['#2E86AB', '#A23B72', '#F18F01']\n\nfor i, (dist_name, results) in enumerate(all_results.items()):\n    for j, n in enumerate(sample_sizes):\n        ax = axes[i, j]\n        \n        # Plot histogram of standardized sample means\n        standardized = results[n]['standardized']\n        ax.hist(standardized, bins=50, density=True, alpha=0.7, \n                color=colors[i], edgecolor='black', linewidth=0.5,\n                label=f'Sample means\\n(n={n})')\n        \n        # Overlay standard normal\n        ax.plot(x_norm, y_norm, 'k-', linewidth=2, label='N(0, 1)')\n        \n        # Calculate and display goodness-of-fit\n        ks_stat, ks_pval = stats.kstest(standardized, 'norm')\n        \n        ax.set_xlim(-4, 4)\n        ax.set_ylim(0, 0.55)\n        \n        if i == 0:\n            ax.set_title(f'n = {n}', fontsize=11, fontweight='bold')\n        \n        if j == 0:\n            ax.set_ylabel(f'{dist_name}\\nDensity', fontsize=10)\n        \n        if i == 2:\n            ax.set_xlabel('Standardized Value', fontsize=10)\n        \n        # Add KS test p-value\n        ax.text(0.95, 0.95, f'KS p={ks_pval:.3f}', \n                transform=ax.transAxes, fontsize=8,\n                verticalalignment='top', horizontalalignment='right',\n                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nplt.tight_layout()\nplt.savefig('plot.png', dpi=150, bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(\"\\nFigure saved to plot.png\")","kernel":"python3","output":{"0":{"data":{"image/png":"21cc196c934877da6a2674e2005b53347d80fd9d","text/plain":"<Figure size 1400x1000 with 12 Axes>"},"metadata":{"image/png":{"height":1025,"width":1390}}},"1":{"name":"stdout","text":"\nFigure saved to plot.png\n"}},"pos":6,"start":1763833385487,"state":"done","type":"cell"}
{"cell_type":"code","end":1763833388735,"exec_count":7,"id":"5ba2c9","input":"print(\"=\"*80)\nprint(\"CONVERGENCE ANALYSIS: Central Limit Theorem\")\nprint(\"=\"*80)\n\nfor dist_name, results in all_results.items():\n    print(f\"\\n{dist_name}\")\n    print(\"-\" * 60)\n    print(f\"{'n':>6} {'KS Stat':>10} {'p-value':>10} {'Skewness':>10} {'Ex. Kurt':>10}\")\n    print(\"-\" * 60)\n    \n    for n in sample_sizes:\n        standardized = results[n]['standardized']\n        \n        ks_stat, ks_pval = stats.kstest(standardized, 'norm')\n        skewness = stats.skew(standardized)\n        kurtosis = stats.kurtosis(standardized)  # Excess kurtosis\n        \n        print(f\"{n:>6} {ks_stat:>10.4f} {ks_pval:>10.4f} {skewness:>10.4f} {kurtosis:>10.4f}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Note: For N(0,1), skewness = 0 and excess kurtosis = 0\")\nprint(\"KS p-value > 0.05 suggests consistency with normal distribution\")\nprint(\"=\"*80)","kernel":"python3","output":{"0":{"name":"stdout","text":"================================================================================\nCONVERGENCE ANALYSIS: Central Limit Theorem\n================================================================================\n\nUniform(0, 1)\n------------------------------------------------------------\n     n    KS Stat    p-value   Skewness   Ex. Kurt\n------------------------------------------------------------\n     1     0.0635     0.0000     0.0249    -1.1892\n     5     0.0074     0.6478     0.0054    -0.2117\n    30     0.0054     0.9311     0.0228     0.0116\n   100     0.0121     0.1061    -0.0118    -0.1152\n\nExponential(λ=1)\n------------------------------------------------------------\n     n    KS Stat    p-value   Skewness   Ex. Kurt\n------------------------------------------------------------\n     1     0.1587     0.0000     2.0174     5.9976\n     5     0.0606     0.0000     0.9125     1.3776\n    30     0.0301     0.0000     0.3702     0.2444\n   100     0.0153     0.0182     0.1533     0.0207\n\nPoisson(λ=3)\n------------------------------------------------------------\n     n    KS Stat    p-value   Skewness   Ex. Kurt\n------------------------------------------------------------\n     1     0.1467     0.0000     0.5736     0.3970\n     5     0.0662     0.0000     0.2096    -0.0212\n    30     0.0252     0.0000     0.0721    -0.0299\n   100     0.0226     0.0001     0.0363     0.0404\n\n================================================================================\nNote: For N(0,1), skewness = 0 and excess kurtosis = 0\nKS p-value > 0.05 suggests consistency with normal distribution\n================================================================================\n"}},"pos":8,"start":1763833388612,"state":"done","type":"cell"}
{"cell_type":"code","end":1763833388796,"exec_count":8,"id":"8d4b26","input":"# Demonstrate Berry-Esseen bound for Exponential distribution\n# For Exp(1): μ = 1, σ = 1, E[|X-μ|³] = 2\n\nprint(\"\\nBerry-Esseen Bound Analysis (Exponential Distribution)\")\nprint(\"=\"*60)\n\nC_BE = 0.4748  # Berry-Esseen constant\nrho_exp = 2  # Third absolute central moment for Exp(1)\nsigma_exp = 1\n\nprint(f\"{'n':>6} {'Theoretical':>15} {'Empirical KS':>15} {'Ratio':>10}\")\nprint(\"-\" * 60)\n\nfor n in sample_sizes:\n    # Theoretical Berry-Esseen bound\n    be_bound = C_BE * rho_exp / (sigma_exp**3 * np.sqrt(n))\n    \n    # Empirical KS statistic\n    ks_stat, _ = stats.kstest(all_results['Exponential(λ=1)'][n]['standardized'], 'norm')\n    \n    ratio = ks_stat / be_bound if be_bound > 0 else 0\n    \n    print(f\"{n:>6} {be_bound:>15.4f} {ks_stat:>15.4f} {ratio:>10.4f}\")\n\nprint(\"\\nNote: Empirical KS should be less than theoretical bound\")","kernel":"python3","output":{"0":{"name":"stdout","text":"\nBerry-Esseen Bound Analysis (Exponential Distribution)\n============================================================\n     n     Theoretical    Empirical KS      Ratio\n------------------------------------------------------------\n     1          0.9496          0.1587     0.1671\n     5          0.4247          0.0606     0.1427\n    30          0.1734          0.0301     0.1737\n   100          0.0950          0.0153     0.1613\n\nNote: Empirical KS should be less than theoretical bound\n"}},"pos":10,"start":1763833388754,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"092dd8","input":"# Central Limit Theorem Demonstration\n\n## Theoretical Foundation\n\nThe **Central Limit Theorem (CLT)** is one of the most fundamental results in probability theory and statistics. It establishes that the distribution of sample means approaches a normal distribution as the sample size increases, regardless of the underlying population distribution.\n\n### Formal Statement\n\nLet $X_1, X_2, \\ldots, X_n$ be a sequence of independent and identically distributed (i.i.d.) random variables with:\n- Expected value: $\\mathbb{E}[X_i] = \\mu$\n- Variance: $\\text{Var}(X_i) = \\sigma^2 < \\infty$\n\nDefine the sample mean as:\n$$\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$$\n\nThen the standardized sample mean converges in distribution to a standard normal:\n$$Z_n = \\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\xrightarrow{d} \\mathcal{N}(0, 1) \\quad \\text{as } n \\to \\infty$$\n\nEquivalently, for large $n$:\n$$\\bar{X}_n \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$$\n\n### Key Implications\n\n1. **Universality**: The CLT holds for any distribution with finite mean and variance\n2. **Convergence Rate**: The approximation improves as $\\mathcal{O}(1/\\sqrt{n})$\n3. **Practical Rule**: $n \\geq 30$ is often sufficient for reasonable approximation\n\n### Mathematical Intuition\n\nThe CLT can be understood through characteristic functions. If $\\phi_X(t)$ is the characteristic function of $X$, then:\n$$\\phi_{Z_n}(t) = \\left[\\phi_X\\left(\\frac{t}{\\sigma\\sqrt{n}}\\right) e^{-it\\mu/(\\sigma\\sqrt{n})}\\right]^n \\to e^{-t^2/2}$$\n\nThe right-hand side is the characteristic function of $\\mathcal{N}(0,1)$.","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"1b6531","input":"## Quantitative Analysis: Convergence Metrics\n\nTo rigorously assess convergence, we compute several statistical measures:\n\n1. **Kolmogorov-Smirnov (KS) Statistic**: Maximum deviation between empirical and theoretical CDFs\n2. **Skewness**: Third standardized moment (should approach 0)\n3. **Excess Kurtosis**: Fourth standardized moment minus 3 (should approach 0)","pos":7,"type":"cell"}
{"cell_type":"markdown","id":"37abb5","input":"## Berry-Esseen Bound\n\nThe **Berry-Esseen theorem** provides a quantitative bound on the rate of convergence in the CLT:\n\n$$\\sup_{x \\in \\mathbb{R}} |F_n(x) - \\Phi(x)| \\leq \\frac{C \\cdot \\rho}{\\sigma^3 \\sqrt{n}}$$\n\nwhere:\n- $F_n(x)$ is the CDF of the standardized sample mean\n- $\\Phi(x)$ is the standard normal CDF\n- $\\rho = \\mathbb{E}[|X - \\mu|^3]$ is the third absolute central moment\n- $C \\leq 0.4748$ is a universal constant\n\nThis shows that convergence is $\\mathcal{O}(1/\\sqrt{n})$.","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"b33376","input":"## Experimental Design\n\nWe will demonstrate the CLT using three distinctly non-normal distributions:\n\n1. **Uniform Distribution**: $X \\sim \\text{Uniform}(0, 1)$\n   - $\\mu = 0.5$, $\\sigma^2 = 1/12$\n\n2. **Exponential Distribution**: $X \\sim \\text{Exp}(\\lambda = 1)$\n   - $\\mu = 1$, $\\sigma^2 = 1$\n\n3. **Poisson Distribution**: $X \\sim \\text{Poisson}(\\lambda = 3)$\n   - $\\mu = 3$, $\\sigma^2 = 3$\n\nFor each distribution, we compute sample means for various sample sizes $n \\in \\{1, 5, 30, 100\\}$ and compare the resulting distributions to the theoretical normal.","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"c301f5","input":"## Visualization and Analysis\n\nWe now visualize how the distribution of standardized sample means converges to the standard normal $\\mathcal{N}(0, 1)$ as $n$ increases.","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"d59154","input":"## Conclusion\n\nThis demonstration confirms the Central Limit Theorem through empirical simulation:\n\n1. **Universality**: All three distributions (Uniform, Exponential, Poisson) show convergence to normality despite their different shapes\n\n2. **Rate of Convergence**: \n   - $n = 1$: Distribution matches original (no convergence)\n   - $n = 5$: Beginning of convergence visible\n   - $n = 30$: Good approximation to normal (\"rule of 30\")\n   - $n = 100$: Excellent agreement with $\\mathcal{N}(0, 1)$\n\n3. **Practical Implications**:\n   - Sample means are approximately normal even for small $n$\n   - This justifies the widespread use of $t$-tests and confidence intervals\n   - The CLT underpins much of classical statistical inference\n\nThe CLT remains one of the most powerful tools in statistics, enabling robust inference without requiring knowledge of the underlying population distribution.","pos":11,"type":"cell"}
{"id":0,"time":1763833377516,"type":"user"}
{"last_load":1763833377930,"type":"file"}