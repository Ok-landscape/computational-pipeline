{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Estimation of Pi\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The Monte Carlo method is a powerful computational technique that uses random sampling to obtain numerical results. One classic application is estimating the value of $\\pi$ through a geometric probability argument.\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "Consider a square with side length 2 centered at the origin, containing a unit circle of radius 1. The area ratio between these shapes provides our estimation framework:\n",
    "\n",
    "$$A_{\\text{circle}} = \\pi r^2 = \\pi$$\n",
    "\n",
    "$$A_{\\text{square}} = (2r)^2 = 4$$\n",
    "\n",
    "The probability that a randomly selected point within the square falls inside the circle is:\n",
    "\n",
    "$$P(\\text{inside circle}) = \\frac{A_{\\text{circle}}}{A_{\\text{square}}} = \\frac{\\pi}{4}$$\n",
    "\n",
    "Therefore, by generating $N$ random points and counting how many fall within the circle ($N_{\\text{inside}}$), we can estimate $\\pi$ as:\n",
    "\n",
    "$$\\pi \\approx 4 \\cdot \\frac{N_{\\text{inside}}}{N}$$\n",
    "\n",
    "## Convergence Analysis\n",
    "\n",
    "By the Law of Large Numbers, the estimate converges to the true value as $N \\to \\infty$. The standard error of the Monte Carlo estimate decreases as:\n",
    "\n",
    "$$\\sigma_{\\hat{\\pi}} \\propto \\frac{1}{\\sqrt{N}}$$\n",
    "\n",
    "This $O(N^{-1/2})$ convergence rate is characteristic of Monte Carlo methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_pi(n_samples):\n",
    "    \"\"\"\n",
    "    Estimate pi using Monte Carlo method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Number of random points to generate\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (pi_estimate, x_coords, y_coords, inside_mask)\n",
    "    \"\"\"\n",
    "    # Generate random points in [-1, 1] x [-1, 1]\n",
    "    x = np.random.uniform(-1, 1, n_samples)\n",
    "    y = np.random.uniform(-1, 1, n_samples)\n",
    "    \n",
    "    # Check if points are inside the unit circle: x^2 + y^2 <= 1\n",
    "    distances_squared = x**2 + y**2\n",
    "    inside = distances_squared <= 1\n",
    "    \n",
    "    # Estimate pi\n",
    "    n_inside = np.sum(inside)\n",
    "    pi_estimate = 4 * n_inside / n_samples\n",
    "    \n",
    "    return pi_estimate, x, y, inside\n",
    "\n",
    "# Test with a small sample\n",
    "test_pi, _, _, _ = monte_carlo_pi(1000)\n",
    "print(f\"Quick test with 1,000 samples: pi ≈ {test_pi:.4f}\")\n",
    "print(f\"True value of pi: {np.pi:.4f}\")\n",
    "print(f\"Absolute error: {abs(test_pi - np.pi):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergence_analysis(max_samples=100000, n_points=100):\n",
    "    \"\"\"\n",
    "    Analyze convergence of Monte Carlo pi estimation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    max_samples : int\n",
    "        Maximum number of samples to use\n",
    "    n_points : int\n",
    "        Number of data points to plot\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (sample_sizes, estimates, errors)\n",
    "    \"\"\"\n",
    "    sample_sizes = np.logspace(1, np.log10(max_samples), n_points, dtype=int)\n",
    "    sample_sizes = np.unique(sample_sizes)  # Remove duplicates\n",
    "    \n",
    "    estimates = []\n",
    "    errors = []\n",
    "    \n",
    "    for n in sample_sizes:\n",
    "        pi_est, _, _, _ = monte_carlo_pi(n)\n",
    "        estimates.append(pi_est)\n",
    "        errors.append(abs(pi_est - np.pi))\n",
    "    \n",
    "    return sample_sizes, np.array(estimates), np.array(errors)\n",
    "\n",
    "# Run convergence analysis\n",
    "sample_sizes, estimates, errors = convergence_analysis()\n",
    "print(f\"Convergence analysis complete with {len(sample_sizes)} data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Monte Carlo visualization with 5000 points\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "n_visual = 5000\n",
    "pi_est, x, y, inside = monte_carlo_pi(n_visual)\n",
    "\n",
    "# Plot points - inside circle in blue, outside in red\n",
    "ax1.scatter(x[inside], y[inside], c='blue', s=1, alpha=0.5, label='Inside')\n",
    "ax1.scatter(x[~inside], y[~inside], c='red', s=1, alpha=0.5, label='Outside')\n",
    "\n",
    "# Draw the unit circle\n",
    "circle = Circle((0, 0), 1, fill=False, color='black', linewidth=2)\n",
    "ax1.add_patch(circle)\n",
    "\n",
    "ax1.set_xlim(-1.1, 1.1)\n",
    "ax1.set_ylim(-1.1, 1.1)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title(f'Monte Carlo Sampling (N={n_visual})\\n$\\\\pi$ ≈ {pi_est:.4f}')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Convergence of estimate\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax2.semilogx(sample_sizes, estimates, 'b-', linewidth=1, alpha=0.7)\n",
    "ax2.axhline(y=np.pi, color='r', linestyle='--', linewidth=2, label=f'True $\\\\pi$ = {np.pi:.6f}')\n",
    "ax2.fill_between(sample_sizes, np.pi - 0.1, np.pi + 0.1, alpha=0.2, color='red')\n",
    "ax2.set_xlabel('Number of Samples (N)')\n",
    "ax2.set_ylabel('Estimated $\\\\pi$')\n",
    "ax2.set_title('Convergence of $\\\\pi$ Estimate')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Error decay (log-log)\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax3.loglog(sample_sizes, errors, 'b.', markersize=3, alpha=0.6, label='Observed error')\n",
    "\n",
    "# Theoretical 1/sqrt(N) convergence\n",
    "theoretical_error = 1.0 / np.sqrt(sample_sizes)\n",
    "# Scale to match observed errors\n",
    "scale_factor = np.median(errors * np.sqrt(sample_sizes))\n",
    "ax3.loglog(sample_sizes, scale_factor / np.sqrt(sample_sizes), 'r--', \n",
    "           linewidth=2, label=r'$O(N^{-1/2})$ theoretical')\n",
    "\n",
    "ax3.set_xlabel('Number of Samples (N)')\n",
    "ax3.set_ylabel('Absolute Error $|\\\\hat{\\\\pi} - \\\\pi|$')\n",
    "ax3.set_title('Error Decay Rate')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Distribution of estimates from multiple runs\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "n_runs = 1000\n",
    "samples_per_run = 1000\n",
    "pi_estimates = [monte_carlo_pi(samples_per_run)[0] for _ in range(n_runs)]\n",
    "\n",
    "ax4.hist(pi_estimates, bins=50, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax4.axvline(x=np.pi, color='red', linestyle='--', linewidth=2, label=f'True $\\\\pi$')\n",
    "ax4.axvline(x=np.mean(pi_estimates), color='green', linestyle=':', \n",
    "            linewidth=2, label=f'Mean = {np.mean(pi_estimates):.4f}')\n",
    "\n",
    "# Add standard deviation annotation\n",
    "std_pi = np.std(pi_estimates)\n",
    "ax4.set_xlabel('Estimated $\\\\pi$')\n",
    "ax4.set_ylabel('Probability Density')\n",
    "ax4.set_title(f'Distribution of Estimates (N={samples_per_run}, {n_runs} runs)\\nStd Dev = {std_pi:.4f}')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final high-precision estimate\n",
    "final_n = 1000000\n",
    "final_pi, _, _, _ = monte_carlo_pi(final_n)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Number of samples: {final_n:,}\")\n",
    "print(f\"Monte Carlo estimate: {final_pi:.6f}\")\n",
    "print(f\"True value of pi:     {np.pi:.6f}\")\n",
    "print(f\"Absolute error:       {abs(final_pi - np.pi):.6f}\")\n",
    "print(f\"Relative error:       {100*abs(final_pi - np.pi)/np.pi:.4f}%\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Theoretical standard error\n",
    "theoretical_std = np.sqrt(np.pi * (4 - np.pi) / final_n)\n",
    "print(f\"\\nTheoretical std error: {theoretical_std:.6f}\")\n",
    "print(f\"Expected 95% CI: [{np.pi - 1.96*theoretical_std:.6f}, {np.pi + 1.96*theoretical_std:.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the Monte Carlo method for estimating $\\pi$ through:\n",
    "\n",
    "1. **Geometric Probability**: Using the ratio of circle area to square area\n",
    "2. **Random Sampling**: Generating uniform random points and checking inclusion\n",
    "3. **Convergence Analysis**: Verifying the theoretical $O(N^{-1/2})$ error decay\n",
    "4. **Statistical Distribution**: Showing the Central Limit Theorem in action\n",
    "\n",
    "The Monte Carlo method, while simple for this application, forms the foundation for solving complex integration problems in higher dimensions where analytical solutions are intractable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
