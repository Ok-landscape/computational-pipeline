{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Matrix Operations\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Sparse matrices are matrices in which most elements are zero. They arise naturally in numerous scientific and engineering applications, including:\n",
    "\n",
    "- Finite element analysis\n",
    "- Graph algorithms and network analysis\n",
    "- Natural language processing (term-document matrices)\n",
    "- Recommendation systems\n",
    "- Solution of partial differential equations\n",
    "\n",
    "## Mathematical Background\n",
    "\n",
    "### Definition\n",
    "\n",
    "A matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ is considered **sparse** if the number of non-zero elements $\\text{nnz}(\\mathbf{A})$ satisfies:\n",
    "\n",
    "$$\\text{nnz}(\\mathbf{A}) \\ll m \\times n$$\n",
    "\n",
    "The **sparsity** of a matrix is defined as:\n",
    "\n",
    "$$\\text{sparsity} = 1 - \\frac{\\text{nnz}(\\mathbf{A})}{m \\times n}$$\n",
    "\n",
    "### Storage Formats\n",
    "\n",
    "#### Compressed Sparse Row (CSR) Format\n",
    "\n",
    "The CSR format stores a sparse matrix using three arrays:\n",
    "\n",
    "1. **data**: Contains all non-zero values\n",
    "2. **indices**: Column indices of non-zero values\n",
    "3. **indptr**: Index pointers that delimit rows\n",
    "\n",
    "For row $i$, the non-zero elements are stored in:\n",
    "$$\\texttt{data}[\\texttt{indptr}[i]:\\texttt{indptr}[i+1]]$$\n",
    "\n",
    "#### Compressed Sparse Column (CSC) Format\n",
    "\n",
    "Similar to CSR, but compressed by columns instead of rows. Efficient for column slicing and arithmetic operations.\n",
    "\n",
    "### Computational Complexity\n",
    "\n",
    "For a sparse matrix with $k$ non-zero elements:\n",
    "\n",
    "| Operation | Dense | Sparse |\n",
    "|-----------|-------|--------|\n",
    "| Storage | $O(mn)$ | $O(k)$ |\n",
    "| Matrix-vector product | $O(mn)$ | $O(k)$ |\n",
    "| Matrix addition | $O(mn)$ | $O(k_1 + k_2)$ |\n",
    "\n",
    "## Key Operations\n",
    "\n",
    "### Sparse Matrix-Vector Multiplication\n",
    "\n",
    "Given sparse matrix $\\mathbf{A}$ and dense vector $\\mathbf{x}$, the product $\\mathbf{y} = \\mathbf{A}\\mathbf{x}$ is computed as:\n",
    "\n",
    "$$y_i = \\sum_{j: A_{ij} \\neq 0} A_{ij} x_j$$\n",
    "\n",
    "### Sparse Linear Systems\n",
    "\n",
    "Solving $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ where $\\mathbf{A}$ is sparse typically uses iterative methods like:\n",
    "\n",
    "- Conjugate Gradient (for symmetric positive definite matrices)\n",
    "- GMRES (for general matrices)\n",
    "- BiCGSTAB (for non-symmetric matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.sparse import linalg as splinalg\n",
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sparse Matrices\n",
    "\n",
    "We'll demonstrate various methods for creating sparse matrices and explore their internal structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sparse matrix from dense array\n",
    "dense_matrix = np.array([\n",
    "    [1, 0, 0, 2],\n",
    "    [0, 0, 3, 0],\n",
    "    [4, 0, 5, 0],\n",
    "    [0, 6, 0, 0]\n",
    "])\n",
    "\n",
    "# Convert to CSR format\n",
    "csr_matrix = sparse.csr_matrix(dense_matrix)\n",
    "\n",
    "print(\"Original Dense Matrix:\")\n",
    "print(dense_matrix)\n",
    "print(f\"\\nCSR Representation:\")\n",
    "print(f\"  data:    {csr_matrix.data}\")\n",
    "print(f\"  indices: {csr_matrix.indices}\")\n",
    "print(f\"  indptr:  {csr_matrix.indptr}\")\n",
    "print(f\"\\nSparsity: {1 - csr_matrix.nnz / (csr_matrix.shape[0] * csr_matrix.shape[1]):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Random Sparse Matrices\n",
    "\n",
    "For testing and benchmarking, we often need to generate random sparse matrices with controlled density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random sparse matrices of varying sizes and densities\n",
    "n = 1000  # Matrix dimension\n",
    "densities = [0.001, 0.01, 0.05, 0.1]\n",
    "\n",
    "print(f\"Random sparse matrices of size {n}x{n}:\\n\")\n",
    "for density in densities:\n",
    "    A = sparse.random(n, n, density=density, format='csr')\n",
    "    memory_sparse = A.data.nbytes + A.indices.nbytes + A.indptr.nbytes\n",
    "    memory_dense = n * n * 8  # 8 bytes per float64\n",
    "    \n",
    "    print(f\"Density: {density:.1%}\")\n",
    "    print(f\"  Non-zeros: {A.nnz:,}\")\n",
    "    print(f\"  Sparse memory: {memory_sparse/1024:.1f} KB\")\n",
    "    print(f\"  Dense memory:  {memory_dense/1024:.1f} KB\")\n",
    "    print(f\"  Compression ratio: {memory_dense/memory_sparse:.1f}x\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Sparse Matrix Patterns\n",
    "\n",
    "Many scientific applications produce matrices with specific sparsity patterns. Let's examine some common structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "\n",
    "# Tridiagonal matrix (1D Laplacian)\n",
    "diagonals = [np.ones(n-1), -2*np.ones(n), np.ones(n-1)]\n",
    "tridiag = sparse.diags(diagonals, [-1, 0, 1], format='csr')\n",
    "\n",
    "# Block diagonal matrix\n",
    "blocks = [np.random.randn(5, 5) for _ in range(10)]\n",
    "block_diag = sparse.block_diag(blocks, format='csr')\n",
    "\n",
    "# 2D Laplacian (5-point stencil)\n",
    "n_2d = 7\n",
    "laplacian_2d = sparse.diags(\n",
    "    [1, 1, -4, 1, 1],\n",
    "    [-n_2d, -1, 0, 1, n_2d],\n",
    "    shape=(n_2d**2, n_2d**2),\n",
    "    format='csr'\n",
    ")\n",
    "\n",
    "# Visualize sparsity patterns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "axes[0].spy(tridiag, markersize=2)\n",
    "axes[0].set_title('Tridiagonal Matrix\\n(1D Laplacian)')\n",
    "axes[0].set_xlabel('Column index')\n",
    "axes[0].set_ylabel('Row index')\n",
    "\n",
    "axes[1].spy(block_diag, markersize=1)\n",
    "axes[1].set_title('Block Diagonal Matrix')\n",
    "axes[1].set_xlabel('Column index')\n",
    "axes[1].set_ylabel('Row index')\n",
    "\n",
    "axes[2].spy(laplacian_2d, markersize=3)\n",
    "axes[2].set_title('2D Laplacian\\n(5-point stencil)')\n",
    "axes[2].set_xlabel('Column index')\n",
    "axes[2].set_ylabel('Row index')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sparsity_patterns.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison: Sparse vs Dense Operations\n",
    "\n",
    "Let's benchmark the performance advantage of sparse matrix operations compared to their dense counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_matvec(sizes, density=0.01, n_trials=5):\n",
    "    \"\"\"Benchmark matrix-vector multiplication for sparse and dense matrices.\"\"\"\n",
    "    results = {'size': [], 'sparse_time': [], 'dense_time': [], 'speedup': []}\n",
    "    \n",
    "    for n in sizes:\n",
    "        # Create sparse matrix and vector\n",
    "        A_sparse = sparse.random(n, n, density=density, format='csr')\n",
    "        A_dense = A_sparse.toarray()\n",
    "        x = np.random.randn(n)\n",
    "        \n",
    "        # Benchmark sparse multiplication\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(n_trials):\n",
    "            y_sparse = A_sparse @ x\n",
    "        sparse_time = (time.perf_counter() - start) / n_trials\n",
    "        \n",
    "        # Benchmark dense multiplication\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(n_trials):\n",
    "            y_dense = A_dense @ x\n",
    "        dense_time = (time.perf_counter() - start) / n_trials\n",
    "        \n",
    "        results['size'].append(n)\n",
    "        results['sparse_time'].append(sparse_time * 1000)  # Convert to ms\n",
    "        results['dense_time'].append(dense_time * 1000)\n",
    "        results['speedup'].append(dense_time / sparse_time)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run benchmarks\n",
    "sizes = [100, 500, 1000, 2000, 3000, 4000, 5000]\n",
    "results = benchmark_matvec(sizes, density=0.01)\n",
    "\n",
    "# Display results\n",
    "print(\"Matrix-Vector Multiplication Benchmark (density=1%)\\n\")\n",
    "print(f\"{'Size':>6} {'Sparse (ms)':>12} {'Dense (ms)':>12} {'Speedup':>10}\")\n",
    "print(\"-\" * 44)\n",
    "for i in range(len(sizes)):\n",
    "    print(f\"{results['size'][i]:>6} {results['sparse_time'][i]:>12.3f} \"\n",
    "          f\"{results['dense_time'][i]:>12.3f} {results['speedup'][i]:>10.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize benchmark results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Timing comparison\n",
    "axes[0].plot(results['size'], results['sparse_time'], 'b-o', label='Sparse', linewidth=2)\n",
    "axes[0].plot(results['size'], results['dense_time'], 'r-s', label='Dense', linewidth=2)\n",
    "axes[0].set_xlabel('Matrix Size (n)', fontsize=12)\n",
    "axes[0].set_ylabel('Time (ms)', fontsize=12)\n",
    "axes[0].set_title('Matrix-Vector Multiplication Time', fontsize=14)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Speedup\n",
    "axes[1].plot(results['size'], results['speedup'], 'g-^', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Matrix Size (n)', fontsize=12)\n",
    "axes[1].set_ylabel('Speedup (Dense/Sparse)', fontsize=12)\n",
    "axes[1].set_title('Sparse Matrix Speedup', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(y=1, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('benchmark_matvec.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Sparse Linear Systems\n",
    "\n",
    "One of the most important applications of sparse matrices is solving large linear systems $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poisson_matrix(n):\n",
    "    \"\"\"Create a 2D Poisson equation discretization matrix.\"\"\"\n",
    "    # 5-point stencil for 2D Laplacian\n",
    "    N = n * n\n",
    "    main_diag = 4 * np.ones(N)\n",
    "    side_diag = -np.ones(N - 1)\n",
    "    far_diag = -np.ones(N - n)\n",
    "    \n",
    "    # Handle boundary conditions (remove connections at edges)\n",
    "    for i in range(1, n):\n",
    "        side_diag[i * n - 1] = 0\n",
    "    \n",
    "    diagonals = [far_diag, side_diag, main_diag, side_diag, far_diag]\n",
    "    offsets = [-n, -1, 0, 1, n]\n",
    "    \n",
    "    return sparse.diags(diagonals, offsets, shape=(N, N), format='csr')\n",
    "\n",
    "# Create test problem\n",
    "n_grid = 50\n",
    "A = create_poisson_matrix(n_grid)\n",
    "N = n_grid ** 2\n",
    "\n",
    "# Right-hand side (manufactured solution)\n",
    "x_true = np.random.randn(N)\n",
    "b = A @ x_true\n",
    "\n",
    "print(f\"Poisson system size: {N}x{N}\")\n",
    "print(f\"Non-zeros: {A.nnz:,}\")\n",
    "print(f\"Sparsity: {1 - A.nnz/(N*N):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different sparse solvers\n",
    "solvers = {\n",
    "    'Direct (spsolve)': lambda A, b: splinalg.spsolve(A, b),\n",
    "    'Conjugate Gradient': lambda A, b: splinalg.cg(A, b, atol=1e-10)[0],\n",
    "    'GMRES': lambda A, b: splinalg.gmres(A, b, atol=1e-10)[0],\n",
    "    'BiCGSTAB': lambda A, b: splinalg.bicgstab(A, b, atol=1e-10)[0]\n",
    "}\n",
    "\n",
    "results_solvers = {}\n",
    "\n",
    "print(\"Solver Comparison\\n\")\n",
    "print(f\"{'Solver':<25} {'Time (ms)':>12} {'Rel. Error':>15}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for name, solver in solvers.items():\n",
    "    start = time.perf_counter()\n",
    "    x_computed = solver(A, b)\n",
    "    elapsed = (time.perf_counter() - start) * 1000\n",
    "    \n",
    "    rel_error = np.linalg.norm(x_computed - x_true) / np.linalg.norm(x_true)\n",
    "    results_solvers[name] = {'time': elapsed, 'error': rel_error}\n",
    "    \n",
    "    print(f\"{name:<25} {elapsed:>12.3f} {rel_error:>15.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrix Eigenvalue Problems\n",
    "\n",
    "Computing eigenvalues of large sparse matrices is crucial in many applications. We'll use ARPACK via scipy's `eigsh` for symmetric matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create a symmetric sparse matrix (graph Laplacian)\nn = 500\ndensity = 0.02\n\n# Generate random symmetric sparse matrix\nA_rand = sparse.random(n, n, density=density, format='csr')\nA_sym = (A_rand + A_rand.T) / 2  # Make symmetric\n\n# Add a small shift to diagonal to ensure matrix is positive definite\n# This helps with convergence when finding smallest eigenvalues\nA_sym = A_sym + sparse.eye(n) * 0.1\n\n# Compute a few eigenvalues\nk = 10  # Number of eigenvalues to compute\n\n# Largest eigenvalues\nstart = time.perf_counter()\neigenvalues_large, eigenvectors_large = splinalg.eigsh(A_sym, k=k, which='LM')\ntime_large = time.perf_counter() - start\n\n# Smallest eigenvalues - use shift-invert mode for better convergence\n# sigma=0 transforms the problem to find eigenvalues near 0\nstart = time.perf_counter()\neigenvalues_small, eigenvectors_small = splinalg.eigsh(A_sym, k=k, which='LM', sigma=0)\ntime_small = time.perf_counter() - start\n\nprint(f\"Eigenvalue computation for {n}x{n} matrix:\\n\")\nprint(f\"Largest {k} eigenvalues (computed in {time_large*1000:.1f} ms):\")\nprint(np.sort(eigenvalues_large)[::-1])\nprint(f\"\\nSmallest {k} eigenvalues (computed in {time_small*1000:.1f} ms):\")\nprint(np.sort(eigenvalues_small))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Density on Performance\n",
    "\n",
    "Let's systematically study how matrix density affects the performance of sparse operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_density(n, densities, n_trials=3):\n",
    "    \"\"\"Benchmark sparse operations across different densities.\"\"\"\n",
    "    results = {\n",
    "        'density': [],\n",
    "        'matvec_time': [],\n",
    "        'matmat_time': [],\n",
    "        'memory': []\n",
    "    }\n",
    "    \n",
    "    for density in densities:\n",
    "        A = sparse.random(n, n, density=density, format='csr')\n",
    "        x = np.random.randn(n)\n",
    "        B = sparse.random(n, n, density=density, format='csr')\n",
    "        \n",
    "        # Matrix-vector multiplication\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(n_trials):\n",
    "            y = A @ x\n",
    "        matvec_time = (time.perf_counter() - start) / n_trials * 1000\n",
    "        \n",
    "        # Matrix-matrix multiplication\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(n_trials):\n",
    "            C = A @ B\n",
    "        matmat_time = (time.perf_counter() - start) / n_trials * 1000\n",
    "        \n",
    "        # Memory usage\n",
    "        memory = (A.data.nbytes + A.indices.nbytes + A.indptr.nbytes) / 1024\n",
    "        \n",
    "        results['density'].append(density * 100)\n",
    "        results['matvec_time'].append(matvec_time)\n",
    "        results['matmat_time'].append(matmat_time)\n",
    "        results['memory'].append(memory)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run density benchmark\n",
    "n = 2000\n",
    "densities = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.15, 0.2]\n",
    "density_results = benchmark_density(n, densities)\n",
    "\n",
    "print(f\"Density Impact Benchmark (n={n})\\n\")\n",
    "print(f\"{'Density (%)':>12} {'Mat-Vec (ms)':>14} {'Mat-Mat (ms)':>14} {'Memory (KB)':>12}\")\n",
    "print(\"-\" * 56)\n",
    "for i in range(len(densities)):\n",
    "    print(f\"{density_results['density'][i]:>12.1f} {density_results['matvec_time'][i]:>14.2f} \"\n",
    "          f\"{density_results['matmat_time'][i]:>14.2f} {density_results['memory'][i]:>12.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Sparsity pattern of 2D Laplacian\n",
    "n_lap = 15\n",
    "laplacian = create_poisson_matrix(n_lap)\n",
    "axes[0, 0].spy(laplacian, markersize=1.5)\n",
    "axes[0, 0].set_title(f'2D Poisson Matrix Sparsity Pattern\\n({n_lap**2}×{n_lap**2})', fontsize=12)\n",
    "axes[0, 0].set_xlabel('Column index')\n",
    "axes[0, 0].set_ylabel('Row index')\n",
    "\n",
    "# Plot 2: Performance vs density (Mat-Vec)\n",
    "axes[0, 1].plot(density_results['density'], density_results['matvec_time'], \n",
    "                'b-o', linewidth=2, markersize=8, label='Matrix-Vector')\n",
    "axes[0, 1].plot(density_results['density'], density_results['matmat_time'], \n",
    "                'r-s', linewidth=2, markersize=8, label='Matrix-Matrix')\n",
    "axes[0, 1].set_xlabel('Density (%)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Time (ms)', fontsize=12)\n",
    "axes[0, 1].set_title('Operation Time vs Matrix Density', fontsize=12)\n",
    "axes[0, 1].legend(fontsize=10)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Memory usage vs density\n",
    "axes[1, 0].plot(density_results['density'], density_results['memory'], \n",
    "                'g-^', linewidth=2, markersize=8)\n",
    "dense_memory = n * n * 8 / 1024  # KB\n",
    "axes[1, 0].axhline(y=dense_memory, color='r', linestyle='--', \n",
    "                   label=f'Dense: {dense_memory:.0f} KB')\n",
    "axes[1, 0].set_xlabel('Density (%)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Memory (KB)', fontsize=12)\n",
    "axes[1, 0].set_title('Sparse Matrix Memory Usage', fontsize=12)\n",
    "axes[1, 0].legend(fontsize=10)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Solver comparison bar chart\n",
    "solver_names = list(results_solvers.keys())\n",
    "solver_times = [results_solvers[name]['time'] for name in solver_names]\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(solver_names)))\n",
    "\n",
    "bars = axes[1, 1].bar(range(len(solver_names)), solver_times, color=colors)\n",
    "axes[1, 1].set_xticks(range(len(solver_names)))\n",
    "axes[1, 1].set_xticklabels([name.replace(' ', '\\n') for name in solver_names], fontsize=9)\n",
    "axes[1, 1].set_ylabel('Time (ms)', fontsize=12)\n",
    "axes[1, 1].set_title(f'Sparse Linear Solver Comparison\\n({n_grid**2}×{n_grid**2} system)', fontsize=12)\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, time_val in zip(bars, solver_times):\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    f'{time_val:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFinal visualization saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Storage Efficiency**: Sparse matrix formats (CSR, CSC) achieve significant memory savings for matrices with low density. The compression ratio scales inversely with density.\n",
    "\n",
    "2. **Computational Performance**: Sparse matrix-vector multiplication achieves $O(k)$ complexity versus $O(n^2)$ for dense matrices, where $k$ is the number of non-zeros.\n",
    "\n",
    "3. **Solver Selection**: \n",
    "   - Direct solvers (`spsolve`) are robust but may be slower for very large systems\n",
    "   - Iterative solvers (CG, GMRES, BiCGSTAB) scale better for large sparse systems\n",
    "   - Conjugate Gradient is optimal for symmetric positive definite matrices\n",
    "\n",
    "4. **Practical Guidelines**:\n",
    "   - Use sparse formats when sparsity exceeds ~95%\n",
    "   - Choose CSR for row operations, CSC for column operations\n",
    "   - Profile your specific use case to select optimal solver\n",
    "\n",
    "### Applications\n",
    "\n",
    "Sparse matrix techniques are fundamental to:\n",
    "- Finite element/difference methods for PDEs\n",
    "- Large-scale optimization\n",
    "- Graph algorithms (PageRank, community detection)\n",
    "- Machine learning (sparse features, regularization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}