{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering: Theory and Implementation\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "K-Means clustering is one of the most fundamental unsupervised machine learning algorithms, used to partition a dataset into $K$ distinct, non-overlapping clusters. The algorithm aims to minimize the within-cluster variance, making it particularly effective for discovering natural groupings in data.\n",
    "\n",
    "## 2. Mathematical Foundation\n",
    "\n",
    "### 2.1 Problem Formulation\n",
    "\n",
    "Given a dataset $\\mathbf{X} = \\{\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n\\}$ where each $\\mathbf{x}_i \\in \\mathbb{R}^d$, the K-Means algorithm seeks to partition these $n$ observations into $K$ clusters $\\mathcal{C} = \\{C_1, C_2, \\ldots, C_K\\}$.\n",
    "\n",
    "### 2.2 Objective Function\n",
    "\n",
    "The algorithm minimizes the **Within-Cluster Sum of Squares (WCSS)**, also known as the inertia:\n",
    "\n",
    "$$J = \\sum_{k=1}^{K} \\sum_{\\mathbf{x}_i \\in C_k} \\|\\mathbf{x}_i - \\boldsymbol{\\mu}_k\\|^2$$\n",
    "\n",
    "where $\\boldsymbol{\\mu}_k$ is the centroid (mean) of cluster $C_k$:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_k = \\frac{1}{|C_k|} \\sum_{\\mathbf{x}_i \\in C_k} \\mathbf{x}_i$$\n",
    "\n",
    "### 2.3 Lloyd's Algorithm\n",
    "\n",
    "The standard K-Means algorithm follows an iterative two-step procedure:\n",
    "\n",
    "**Step 1: Assignment** - Assign each point to the nearest centroid:\n",
    "$$C_k^{(t)} = \\{\\mathbf{x}_i : \\|\\mathbf{x}_i - \\boldsymbol{\\mu}_k^{(t)}\\|^2 \\leq \\|\\mathbf{x}_i - \\boldsymbol{\\mu}_j^{(t)}\\|^2 \\ \\forall j\\}$$\n",
    "\n",
    "**Step 2: Update** - Recalculate centroids:\n",
    "$$\\boldsymbol{\\mu}_k^{(t+1)} = \\frac{1}{|C_k^{(t)}|} \\sum_{\\mathbf{x}_i \\in C_k^{(t)}} \\mathbf{x}_i$$\n",
    "\n",
    "### 2.4 Convergence Properties\n",
    "\n",
    "The algorithm is guaranteed to converge because:\n",
    "1. The objective function $J$ is bounded below by zero\n",
    "2. Each step (assignment and update) can only decrease or maintain $J$\n",
    "3. There are finitely many possible partitions\n",
    "\n",
    "However, convergence is only to a **local minimum**, not necessarily the global optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for publication-quality figures\n",
    "plt.rcParams['figure.figsize'] = (12, 10)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Generation\n",
    "\n",
    "We generate synthetic data from a mixture of Gaussian distributions to create well-separated clusters. Each cluster follows:\n",
    "\n",
    "$$\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma}_k)$$\n",
    "\n",
    "where $\\boldsymbol{\\Sigma}_k = \\sigma^2 \\mathbf{I}$ for isotropic clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clustered_data(n_samples=300, n_clusters=4, cluster_std=0.6):\n",
    "    \"\"\"\n",
    "    Generate synthetic clustered data from Gaussian distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Total number of data points\n",
    "    n_clusters : int\n",
    "        Number of clusters to generate\n",
    "    cluster_std : float\n",
    "        Standard deviation of each cluster\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X : ndarray of shape (n_samples, 2)\n",
    "        Generated data points\n",
    "    true_labels : ndarray of shape (n_samples,)\n",
    "        True cluster assignments\n",
    "    true_centers : ndarray of shape (n_clusters, 2)\n",
    "        True cluster centers\n",
    "    \"\"\"\n",
    "    samples_per_cluster = n_samples // n_clusters\n",
    "    \n",
    "    # Define cluster centers in a grid pattern\n",
    "    true_centers = np.array([\n",
    "        [2.0, 2.0],\n",
    "        [8.0, 2.0],\n",
    "        [2.0, 8.0],\n",
    "        [8.0, 8.0]\n",
    "    ])[:n_clusters]\n",
    "    \n",
    "    X = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for k in range(n_clusters):\n",
    "        # Generate points from Gaussian distribution\n",
    "        cluster_points = np.random.randn(samples_per_cluster, 2) * cluster_std + true_centers[k]\n",
    "        X.append(cluster_points)\n",
    "        true_labels.extend([k] * samples_per_cluster)\n",
    "    \n",
    "    X = np.vstack(X)\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    # Shuffle data\n",
    "    shuffle_idx = np.random.permutation(len(X))\n",
    "    X = X[shuffle_idx]\n",
    "    true_labels = true_labels[shuffle_idx]\n",
    "    \n",
    "    return X, true_labels, true_centers\n",
    "\n",
    "# Generate dataset\n",
    "X, true_labels, true_centers = generate_clustered_data(n_samples=300, n_clusters=4, cluster_std=0.7)\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of clusters: {len(true_centers)}\")\n",
    "print(f\"True cluster centers:\\n{true_centers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Means Implementation\n",
    "\n",
    "We implement the K-Means algorithm from scratch to understand its inner workings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    \"\"\"\n",
    "    K-Means clustering algorithm implementation.\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    n_clusters : int\n",
    "        Number of clusters\n",
    "    max_iter : int\n",
    "        Maximum number of iterations\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    centroids : ndarray\n",
    "        Cluster centroids after fitting\n",
    "    labels : ndarray\n",
    "        Cluster assignments for each point\n",
    "    inertia_history : list\n",
    "        WCSS values at each iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_clusters=3, max_iter=100, tol=1e-4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "        self.inertia_history = []\n",
    "        self.centroid_history = []\n",
    "        \n",
    "    def _init_centroids(self, X):\n",
    "        \"\"\"Initialize centroids using K-Means++ method.\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        centroids = []\n",
    "        \n",
    "        # Choose first centroid randomly\n",
    "        idx = np.random.randint(n_samples)\n",
    "        centroids.append(X[idx])\n",
    "        \n",
    "        # Choose remaining centroids with probability proportional to D(x)^2\n",
    "        for _ in range(1, self.n_clusters):\n",
    "            distances = np.array([min(np.sum((x - c)**2) for c in centroids) for x in X])\n",
    "            probabilities = distances / distances.sum()\n",
    "            idx = np.random.choice(n_samples, p=probabilities)\n",
    "            centroids.append(X[idx])\n",
    "            \n",
    "        return np.array(centroids)\n",
    "    \n",
    "    def _assign_clusters(self, X):\n",
    "        \"\"\"Assign each point to the nearest centroid.\"\"\"\n",
    "        distances = np.zeros((X.shape[0], self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            distances[:, k] = np.sum((X - self.centroids[k])**2, axis=1)\n",
    "        return np.argmin(distances, axis=1)\n",
    "    \n",
    "    def _update_centroids(self, X):\n",
    "        \"\"\"Update centroids as the mean of assigned points.\"\"\"\n",
    "        new_centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "        for k in range(self.n_clusters):\n",
    "            cluster_points = X[self.labels == k]\n",
    "            if len(cluster_points) > 0:\n",
    "                new_centroids[k] = cluster_points.mean(axis=0)\n",
    "            else:\n",
    "                # Handle empty cluster by reinitializing\n",
    "                new_centroids[k] = X[np.random.randint(X.shape[0])]\n",
    "        return new_centroids\n",
    "    \n",
    "    def _compute_inertia(self, X):\n",
    "        \"\"\"Compute Within-Cluster Sum of Squares.\"\"\"\n",
    "        inertia = 0\n",
    "        for k in range(self.n_clusters):\n",
    "            cluster_points = X[self.labels == k]\n",
    "            if len(cluster_points) > 0:\n",
    "                inertia += np.sum((cluster_points - self.centroids[k])**2)\n",
    "        return inertia\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit K-Means to the data.\"\"\"\n",
    "        # Initialize centroids\n",
    "        self.centroids = self._init_centroids(X)\n",
    "        self.centroid_history = [self.centroids.copy()]\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            # Assignment step\n",
    "            self.labels = self._assign_clusters(X)\n",
    "            \n",
    "            # Update step\n",
    "            new_centroids = self._update_centroids(X)\n",
    "            \n",
    "            # Compute inertia\n",
    "            inertia = self._compute_inertia(X)\n",
    "            self.inertia_history.append(inertia)\n",
    "            \n",
    "            # Check convergence\n",
    "            centroid_shift = np.sum((new_centroids - self.centroids)**2)\n",
    "            self.centroids = new_centroids\n",
    "            self.centroid_history.append(self.centroids.copy())\n",
    "            \n",
    "            if centroid_shift < self.tol:\n",
    "                print(f\"Converged after {iteration + 1} iterations\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Reached maximum iterations ({self.max_iter})\")\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict cluster labels for new data.\"\"\"\n",
    "        return self._assign_clusters(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K-Means to the data\n",
    "kmeans = KMeans(n_clusters=4, max_iter=100, tol=1e-6)\n",
    "kmeans.fit(X)\n",
    "\n",
    "print(f\"\\nFinal inertia (WCSS): {kmeans.inertia_history[-1]:.2f}\")\n",
    "print(f\"\\nLearned centroids:\\n{kmeans.centroids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "\n",
    "We create a comprehensive visualization showing:\n",
    "1. Original data with true labels\n",
    "2. K-Means clustering results\n",
    "3. Convergence of inertia\n",
    "4. Centroid movement during optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Color maps\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Plot 1: Original data with true labels\n",
    "ax1 = axes[0, 0]\n",
    "scatter1 = ax1.scatter(X[:, 0], X[:, 1], c=true_labels, cmap=cmap, \n",
    "                       alpha=0.6, s=50, edgecolors='k', linewidth=0.5)\n",
    "ax1.scatter(true_centers[:, 0], true_centers[:, 1], c='black', \n",
    "            marker='*', s=300, edgecolors='white', linewidth=2, label='True Centers')\n",
    "ax1.set_xlabel('$x_1$')\n",
    "ax1.set_ylabel('$x_2$')\n",
    "ax1.set_title('Original Data with True Labels')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: K-Means clustering results\n",
    "ax2 = axes[0, 1]\n",
    "scatter2 = ax2.scatter(X[:, 0], X[:, 1], c=kmeans.labels, cmap=cmap, \n",
    "                       alpha=0.6, s=50, edgecolors='k', linewidth=0.5)\n",
    "ax2.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1], c='black', \n",
    "            marker='X', s=300, edgecolors='white', linewidth=2, label='Learned Centroids')\n",
    "ax2.set_xlabel('$x_1$')\n",
    "ax2.set_ylabel('$x_2$')\n",
    "ax2.set_title('K-Means Clustering Results')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Inertia convergence\n",
    "ax3 = axes[1, 0]\n",
    "iterations = range(1, len(kmeans.inertia_history) + 1)\n",
    "ax3.plot(iterations, kmeans.inertia_history, 'b-o', linewidth=2, markersize=6)\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('Inertia (WCSS)')\n",
    "ax3.set_title('Convergence of Objective Function')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_xlim(0, len(kmeans.inertia_history) + 1)\n",
    "\n",
    "# Add annotation for final inertia\n",
    "final_inertia = kmeans.inertia_history[-1]\n",
    "ax3.annotate(f'Final: {final_inertia:.1f}', \n",
    "             xy=(len(kmeans.inertia_history), final_inertia),\n",
    "             xytext=(len(kmeans.inertia_history) - 2, final_inertia + 50),\n",
    "             arrowprops=dict(arrowstyle='->', color='red'),\n",
    "             fontsize=10, color='red')\n",
    "\n",
    "# Plot 4: Centroid movement\n",
    "ax4 = axes[1, 1]\n",
    "ax4.scatter(X[:, 0], X[:, 1], c='lightgray', alpha=0.3, s=30)\n",
    "\n",
    "# Plot centroid trajectories\n",
    "centroid_history = np.array(kmeans.centroid_history)\n",
    "for k in range(kmeans.n_clusters):\n",
    "    trajectory = centroid_history[:, k, :]\n",
    "    ax4.plot(trajectory[:, 0], trajectory[:, 1], '-', \n",
    "             color=colors[k], linewidth=2, alpha=0.7)\n",
    "    # Plot initial position\n",
    "    ax4.scatter(trajectory[0, 0], trajectory[0, 1], \n",
    "                c=colors[k], marker='o', s=150, edgecolors='black', \n",
    "                linewidth=2, zorder=5)\n",
    "    # Plot final position\n",
    "    ax4.scatter(trajectory[-1, 0], trajectory[-1, 1], \n",
    "                c=colors[k], marker='X', s=200, edgecolors='black', \n",
    "                linewidth=2, zorder=5)\n",
    "\n",
    "ax4.set_xlabel('$x_1$')\n",
    "ax4.set_ylabel('$x_2$')\n",
    "ax4.set_title('Centroid Movement During Optimization')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend for centroid markers\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', \n",
    "           markersize=10, label='Initial'),\n",
    "    Line2D([0], [0], marker='X', color='w', markerfacecolor='gray', \n",
    "           markersize=12, label='Final')\n",
    "]\n",
    "ax4.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis and Evaluation\n",
    "\n",
    "### 7.1 Clustering Quality Metrics\n",
    "\n",
    "We can evaluate clustering quality using several metrics:\n",
    "\n",
    "**Silhouette Score:** Measures how similar a point is to its own cluster compared to other clusters:\n",
    "\n",
    "$$s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}$$\n",
    "\n",
    "where $a(i)$ is the mean intra-cluster distance and $b(i)$ is the mean nearest-cluster distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_score(X, labels):\n",
    "    \"\"\"\n",
    "    Compute the mean silhouette score for all samples.\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    \n",
    "    silhouette_vals = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Compute a(i): mean distance to points in same cluster\n",
    "        same_cluster = X[labels == labels[i]]\n",
    "        if len(same_cluster) > 1:\n",
    "            a_i = np.mean([np.linalg.norm(X[i] - x) for x in same_cluster if not np.array_equal(x, X[i])])\n",
    "        else:\n",
    "            a_i = 0\n",
    "        \n",
    "        # Compute b(i): min mean distance to points in other clusters\n",
    "        b_i = np.inf\n",
    "        for k in range(n_clusters):\n",
    "            if k != labels[i]:\n",
    "                other_cluster = X[labels == k]\n",
    "                if len(other_cluster) > 0:\n",
    "                    mean_dist = np.mean([np.linalg.norm(X[i] - x) for x in other_cluster])\n",
    "                    b_i = min(b_i, mean_dist)\n",
    "        \n",
    "        # Compute silhouette\n",
    "        if max(a_i, b_i) > 0:\n",
    "            s_i = (b_i - a_i) / max(a_i, b_i)\n",
    "        else:\n",
    "            s_i = 0\n",
    "        \n",
    "        silhouette_vals.append(s_i)\n",
    "    \n",
    "    return np.mean(silhouette_vals)\n",
    "\n",
    "# Calculate metrics\n",
    "sil_score = silhouette_score(X, kmeans.labels)\n",
    "print(f\"Silhouette Score: {sil_score:.3f}\")\n",
    "print(f\"(Range: -1 to 1, higher is better)\")\n",
    "\n",
    "# Compare centroid distances\n",
    "print(f\"\\nCentroid Comparison:\")\n",
    "print(f\"{'Cluster':<10} {'True Center':<25} {'Learned Centroid':<25} {'Distance':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Match learned centroids to true centers (greedy matching)\n",
    "used = set()\n",
    "for k in range(len(true_centers)):\n",
    "    min_dist = np.inf\n",
    "    best_match = 0\n",
    "    for j in range(kmeans.n_clusters):\n",
    "        if j not in used:\n",
    "            dist = np.linalg.norm(true_centers[k] - kmeans.centroids[j])\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_match = j\n",
    "    used.add(best_match)\n",
    "    print(f\"{k:<10} {str(true_centers[k]):<25} {str(np.round(kmeans.centroids[best_match], 2)):<25} {min_dist:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. The Elbow Method\n",
    "\n",
    "The elbow method helps determine the optimal number of clusters by plotting inertia against $K$ and finding the \"elbow\" point where adding more clusters yields diminishing returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method analysis\n",
    "K_range = range(1, 9)\n",
    "inertias = []\n",
    "\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, max_iter=100, tol=1e-6)\n",
    "    km.fit(X)\n",
    "    inertias.append(km.inertia_history[-1])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axvline(x=4, color='r', linestyle='--', label='Optimal K=4')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (WCSS)')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(K_range)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInertia values for different K:\")\n",
    "for k, inertia in zip(K_range, inertias):\n",
    "    print(f\"K={k}: {inertia:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Algorithm Performance**: K-Means successfully identified the 4 clusters in our synthetic dataset, with learned centroids closely matching the true cluster centers.\n",
    "\n",
    "2. **Convergence**: The algorithm converged quickly, with the objective function $J$ (inertia) decreasing monotonically and stabilizing within a few iterations.\n",
    "\n",
    "3. **Initialization Importance**: The K-Means++ initialization strategy helped achieve good results by spreading initial centroids apart.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- **Assumes spherical clusters**: K-Means works best with convex, isotropic clusters\n",
    "- **Sensitive to outliers**: Outliers can significantly affect centroid positions\n",
    "- **Local optima**: Different initializations may yield different results\n",
    "- **Requires $K$ specification**: The number of clusters must be determined beforehand\n",
    "\n",
    "### Extensions\n",
    "\n",
    "- **K-Means++**: Better initialization (implemented here)\n",
    "- **Mini-batch K-Means**: For large datasets\n",
    "- **Soft K-Means (GMM)**: Probabilistic cluster assignments\n",
    "- **Kernel K-Means**: For non-linearly separable data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
