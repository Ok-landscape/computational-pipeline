{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobi Iterative Method for Solving Linear Systems\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The **Jacobi iterative method** is a classical algorithm for solving systems of linear equations of the form:\n",
    "\n",
    "$$\\mathbf{A}\\mathbf{x} = \\mathbf{b}$$\n",
    "\n",
    "where $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is a square matrix, $\\mathbf{x} \\in \\mathbb{R}^n$ is the unknown vector, and $\\mathbf{b} \\in \\mathbb{R}^n$ is the right-hand side vector.\n",
    "\n",
    "## Mathematical Formulation\n",
    "\n",
    "### Matrix Decomposition\n",
    "\n",
    "The Jacobi method decomposes the matrix $\\mathbf{A}$ into its diagonal and off-diagonal components:\n",
    "\n",
    "$$\\mathbf{A} = \\mathbf{D} + \\mathbf{R}$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{D}$ is the diagonal matrix containing only the diagonal elements of $\\mathbf{A}$\n",
    "- $\\mathbf{R} = \\mathbf{L} + \\mathbf{U}$ contains the lower and upper triangular parts (excluding diagonal)\n",
    "\n",
    "### Iterative Formula\n",
    "\n",
    "The system $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ can be rewritten as:\n",
    "\n",
    "$$\\mathbf{D}\\mathbf{x} = \\mathbf{b} - \\mathbf{R}\\mathbf{x}$$\n",
    "\n",
    "Leading to the iteration scheme:\n",
    "\n",
    "$$\\mathbf{x}^{(k+1)} = \\mathbf{D}^{-1}(\\mathbf{b} - \\mathbf{R}\\mathbf{x}^{(k)})$$\n",
    "\n",
    "### Component-wise Form\n",
    "\n",
    "For each component $i$, the update rule is:\n",
    "\n",
    "$$x_i^{(k+1)} = \\frac{1}{a_{ii}}\\left(b_i - \\sum_{j \\neq i} a_{ij}x_j^{(k)}\\right)$$\n",
    "\n",
    "## Convergence Criteria\n",
    "\n",
    "The Jacobi method converges if:\n",
    "\n",
    "1. **Strict diagonal dominance**: $|a_{ii}| > \\sum_{j \\neq i} |a_{ij}|$ for all $i$\n",
    "2. **Spectral radius condition**: $\\rho(\\mathbf{D}^{-1}\\mathbf{R}) < 1$\n",
    "\n",
    "The convergence rate depends on the spectral radius of the iteration matrix $\\mathbf{G} = \\mathbf{D}^{-1}\\mathbf{R}$.\n",
    "\n",
    "## Error Analysis\n",
    "\n",
    "The error at iteration $k$ satisfies:\n",
    "\n",
    "$$\\|\\mathbf{e}^{(k)}\\| \\leq \\|\\mathbf{G}\\|^k \\|\\mathbf{e}^{(0)}\\|$$\n",
    "\n",
    "where $\\mathbf{e}^{(k)} = \\mathbf{x}^{(k)} - \\mathbf{x}^*$ is the error vector and $\\mathbf{x}^*$ is the true solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "### Jacobi Iteration Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_iteration(A, b, x0=None, tol=1e-10, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Solve Ax = b using the Jacobi iterative method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    A : ndarray\n",
    "        Coefficient matrix (n x n)\n",
    "    b : ndarray\n",
    "        Right-hand side vector (n,)\n",
    "    x0 : ndarray, optional\n",
    "        Initial guess (default: zeros)\n",
    "    tol : float\n",
    "        Convergence tolerance\n",
    "    max_iter : int\n",
    "        Maximum number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    x : ndarray\n",
    "        Solution vector\n",
    "    residuals : list\n",
    "        History of residual norms\n",
    "    errors : list\n",
    "        History of error norms (if true solution known)\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    \n",
    "    if x0 is None:\n",
    "        x = np.zeros(n)\n",
    "    else:\n",
    "        x = x0.copy()\n",
    "    \n",
    "    # Extract diagonal and compute D^{-1}\n",
    "    D = np.diag(A)\n",
    "    R = A - np.diag(D)\n",
    "    \n",
    "    residuals = []\n",
    "    x_history = [x.copy()]\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        # Jacobi iteration: x^{k+1} = D^{-1}(b - Rx^k)\n",
    "        x_new = (b - R @ x) / D\n",
    "        \n",
    "        # Compute residual\n",
    "        residual = norm(A @ x_new - b)\n",
    "        residuals.append(residual)\n",
    "        \n",
    "        # Check convergence\n",
    "        if norm(x_new - x) < tol:\n",
    "            x = x_new\n",
    "            x_history.append(x.copy())\n",
    "            break\n",
    "        \n",
    "        x = x_new\n",
    "        x_history.append(x.copy())\n",
    "    \n",
    "    return x, residuals, x_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diagonally_dominant_matrix(n, dominance_factor=3.0):\n",
    "    \"\"\"\n",
    "    Create a strictly diagonally dominant matrix to ensure convergence.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n : int\n",
    "        Matrix dimension\n",
    "    dominance_factor : float\n",
    "        Factor by which diagonal exceeds row sum\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    A : ndarray\n",
    "        Diagonally dominant matrix\n",
    "    \"\"\"\n",
    "    # Create random off-diagonal elements\n",
    "    A = np.random.randn(n, n)\n",
    "    \n",
    "    # Make diagonally dominant\n",
    "    for i in range(n):\n",
    "        row_sum = np.sum(np.abs(A[i, :])) - np.abs(A[i, i])\n",
    "        A[i, i] = dominance_factor * row_sum\n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "def compute_spectral_radius(A):\n",
    "    \"\"\"\n",
    "    Compute the spectral radius of the Jacobi iteration matrix.\n",
    "    \n",
    "    The iteration matrix is G = D^{-1}R where D is diagonal\n",
    "    and R contains off-diagonal elements.\n",
    "    \"\"\"\n",
    "    D = np.diag(np.diag(A))\n",
    "    R = A - D\n",
    "    D_inv = np.diag(1.0 / np.diag(A))\n",
    "    G = D_inv @ R\n",
    "    \n",
    "    eigenvalues = np.linalg.eigvals(G)\n",
    "    spectral_radius = np.max(np.abs(eigenvalues))\n",
    "    \n",
    "    return spectral_radius, eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple 3×3 System\n",
    "\n",
    "Consider the diagonally dominant system:\n",
    "\n",
    "$$\\begin{pmatrix} 4 & -1 & 0 \\\\ -1 & 4 & -1 \\\\ 0 & -1 & 4 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 15 \\\\ 10 \\\\ 10 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system\n",
    "A1 = np.array([[4, -1, 0],\n",
    "               [-1, 4, -1],\n",
    "               [0, -1, 4]], dtype=float)\n",
    "\n",
    "b1 = np.array([15, 10, 10], dtype=float)\n",
    "\n",
    "# Compute exact solution for comparison\n",
    "x_exact = np.linalg.solve(A1, b1)\n",
    "print(\"Exact solution:\", x_exact)\n",
    "\n",
    "# Check spectral radius\n",
    "rho, _ = compute_spectral_radius(A1)\n",
    "print(f\"Spectral radius ρ(G) = {rho:.4f}\")\n",
    "print(f\"Convergence guaranteed: {rho < 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve using Jacobi iteration\n",
    "x_jacobi, residuals1, history1 = jacobi_iteration(A1, b1, tol=1e-10)\n",
    "\n",
    "print(f\"\\nJacobi solution: {x_jacobi}\")\n",
    "print(f\"Number of iterations: {len(residuals1)}\")\n",
    "print(f\"Final residual: {residuals1[-1]:.2e}\")\n",
    "print(f\"Error norm: {norm(x_jacobi - x_exact):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Larger System with Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger diagonally dominant system\n",
    "n = 50\n",
    "A2 = create_diagonally_dominant_matrix(n, dominance_factor=2.5)\n",
    "\n",
    "# Create known solution and compute b\n",
    "x_true = np.random.randn(n)\n",
    "b2 = A2 @ x_true\n",
    "\n",
    "# Check spectral radius\n",
    "rho2, eigenvalues = compute_spectral_radius(A2)\n",
    "print(f\"Matrix dimension: {n}×{n}\")\n",
    "print(f\"Spectral radius ρ(G) = {rho2:.4f}\")\n",
    "print(f\"Expected convergence rate: {-1/np.log10(rho2):.1f} iterations per digit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the system\n",
    "x_sol, residuals2, history2 = jacobi_iteration(A2, b2, tol=1e-12, max_iter=500)\n",
    "\n",
    "# Compute error history\n",
    "errors2 = [norm(h - x_true) for h in history2]\n",
    "\n",
    "print(f\"\\nConverged in {len(residuals2)} iterations\")\n",
    "print(f\"Final error: {errors2[-1]:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Residual convergence for small system\n",
    "ax1 = axes[0, 0]\n",
    "ax1.semilogy(residuals1, 'b-o', markersize=4, label='Residual $\\\\|Ax^{(k)} - b\\\\|$')\n",
    "ax1.set_xlabel('Iteration $k$', fontsize=11)\n",
    "ax1.set_ylabel('Residual Norm', fontsize=11)\n",
    "ax1.set_title('Convergence: 3×3 Tridiagonal System', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Component evolution for small system\n",
    "ax2 = axes[0, 1]\n",
    "history_array = np.array(history1)\n",
    "for i in range(3):\n",
    "    ax2.plot(history_array[:, i], '-o', markersize=4, label=f'$x_{i+1}$')\n",
    "    ax2.axhline(y=x_exact[i], color=f'C{i}', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Iteration $k$', fontsize=11)\n",
    "ax2.set_ylabel('Component Value', fontsize=11)\n",
    "ax2.set_title('Solution Components Evolution', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: Residual and error for large system\n",
    "ax3 = axes[1, 0]\n",
    "iterations = range(len(residuals2))\n",
    "ax3.semilogy(iterations, residuals2, 'b-', linewidth=1.5, label='Residual')\n",
    "ax3.semilogy(range(len(errors2)), errors2, 'r--', linewidth=1.5, label='Error $\\\\|x^{(k)} - x^*\\\\|$')\n",
    "\n",
    "# Add theoretical convergence rate\n",
    "k_theory = np.arange(len(errors2))\n",
    "theoretical = errors2[0] * (rho2 ** k_theory)\n",
    "ax3.semilogy(k_theory, theoretical, 'g:', linewidth=1, label=f'Theoretical $\\\\rho^k$ (ρ={rho2:.3f})')\n",
    "\n",
    "ax3.set_xlabel('Iteration $k$', fontsize=11)\n",
    "ax3.set_ylabel('Norm', fontsize=11)\n",
    "ax3.set_title(f'Convergence: {n}×{n} System', fontsize=12)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "# Plot 4: Eigenvalue distribution of iteration matrix\n",
    "ax4 = axes[1, 1]\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "ax4.plot(np.cos(theta), np.sin(theta), 'k--', alpha=0.3, label='Unit circle')\n",
    "ax4.scatter(eigenvalues.real, eigenvalues.imag, c='blue', s=20, alpha=0.6, label='Eigenvalues of $G$')\n",
    "ax4.scatter([rho2], [0], c='red', s=100, marker='*', label=f'ρ(G) = {rho2:.3f}')\n",
    "ax4.set_xlabel('Real', fontsize=11)\n",
    "ax4.set_ylabel('Imaginary', fontsize=11)\n",
    "ax4.set_title('Eigenvalues of Iteration Matrix $G = D^{-1}R$', fontsize=12)\n",
    "ax4.set_aspect('equal')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.legend(loc='upper right')\n",
    "ax4.set_xlim(-1.2, 1.2)\n",
    "ax4.set_ylim(-1.2, 1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to 'plot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Effect of Diagonal Dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare convergence for different levels of diagonal dominance\n",
    "dominance_factors = [1.5, 2.0, 3.0, 5.0]\n",
    "n_test = 30\n",
    "\n",
    "print(\"Effect of Diagonal Dominance on Convergence\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Factor':<10} {'ρ(G)':<10} {'Iterations':<12} {'Final Error':<12}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for factor in dominance_factors:\n",
    "    A_test = create_diagonally_dominant_matrix(n_test, dominance_factor=factor)\n",
    "    x_true_test = np.ones(n_test)\n",
    "    b_test = A_test @ x_true_test\n",
    "    \n",
    "    rho_test, _ = compute_spectral_radius(A_test)\n",
    "    x_sol_test, res_test, _ = jacobi_iteration(A_test, b_test, tol=1e-10)\n",
    "    \n",
    "    error = norm(x_sol_test - x_true_test)\n",
    "    print(f\"{factor:<10.1f} {rho_test:<10.4f} {len(res_test):<12} {error:<12.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The Jacobi iterative method demonstrates several key properties:\n",
    "\n",
    "1. **Linear Convergence**: The error decreases geometrically with rate governed by $\\rho(\\mathbf{G})$\n",
    "\n",
    "2. **Diagonal Dominance**: Stronger diagonal dominance leads to faster convergence (smaller spectral radius)\n",
    "\n",
    "3. **Parallelizability**: Each component can be updated independently, making Jacobi suitable for parallel computation\n",
    "\n",
    "4. **Simplicity vs. Speed**: While simple to implement, Jacobi typically converges slower than Gauss-Seidel or SOR methods\n",
    "\n",
    "### Theoretical Complexity\n",
    "\n",
    "- **Per iteration**: $O(n^2)$ for dense matrices, $O(\\text{nnz})$ for sparse\n",
    "- **Total iterations**: $O\\left(\\frac{\\log(\\epsilon)}{\\log(\\rho)}\\right)$ for tolerance $\\epsilon$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
